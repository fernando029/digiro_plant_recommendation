{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5dNVgPEgTRc3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "# Set the seed\n",
        "random.seed(123)\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "N8De_0aMTU99",
        "outputId": "85458313-75f5-44ff-8eb9-0d2b58860e65"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9ec114a6-348a-4d80-886a-d9214556f260\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9ec114a6-348a-4d80-886a-d9214556f260\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving weather_aus.xlsx to weather_aus.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "data = pd.read_excel(io.BytesIO(uploaded['weather_aus.xlsx']))"
      ],
      "metadata": {
        "id": "njDt3oYIUCCf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()\n",
        "data['Humidity'] = (data['9am relative humidity (%)'] + data['3pm relative humidity (%)'])/2\n",
        "# Replace specific value in column 'A'\n",
        "data['9am wind speed (km/h)'] = data['9am wind speed (km/h)'].replace('Calm', '2')\n",
        "data['3pm wind speed (km/h)'] = data['3pm wind speed (km/h)'].replace('Calm', '2')\n",
        "\n",
        "# Convert column 'A' to int type\n",
        "data['9am wind speed (km/h)'] = data['9am wind speed (km/h)'].astype(int)\n",
        "data['3pm wind speed (km/h)'] = data['3pm wind speed (km/h)'].astype(int)\n",
        "\n",
        "data['WindSpeed'] = (data['9am wind speed (km/h)'] + data['3pm wind speed (km/h)'])/2"
      ],
      "metadata": {
        "id": "Bo9mheaGV_NR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datas = data[['Date','Minimum temperature (°C)', 'Maximum temperature (°C)', 'Rainfall (mm)', 'Evaporation (mm)',\n",
        "             'Sunshine (hours)', 'Humidity', 'WindSpeed']]\n",
        "datas.head()\n",
        "datas.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiFJq04IWCCI",
        "outputId": "2b65b435-732c-4b6e-9862-be5239240884"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date                        datetime64[ns]\n",
              "Minimum temperature (°C)           float64\n",
              "Maximum temperature (°C)           float64\n",
              "Rainfall (mm)                      float64\n",
              "Evaporation (mm)                   float64\n",
              "Sunshine (hours)                   float64\n",
              "Humidity                           float64\n",
              "WindSpeed                          float64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datas.set_index('Date', inplace=True)\n",
        "datas = datas.sort_values('Date', ascending=True)\n",
        "datas.head()\n",
        "# Extract the last 90 days as the test set\n",
        "test_set = datas[-60:]\n",
        "\n",
        "# Use the remaining data as the training set\n",
        "train_set = datas[:-60]\n",
        "train_data = train_set\n",
        "test_data = test_set"
      ],
      "metadata": {
        "id": "ov7yNMQPWD32"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install pystan~=2.14\n",
        "#!pip install fbprophet\n",
        "# Following codes will perform different models with cross validation of 4x for 1 month ahead predictions for 7 target variables"
      ],
      "metadata": {
        "id": "3Rsf0mkXXsrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "data = datas\n",
        "# Define the window size\n",
        "window_size = 30\n",
        "# Define the number of predictions to make\n",
        "prediction_steps = 30\n",
        "\n",
        "# Define the variable names\n",
        "variable_names = ['Minimum temperature (°C)', 'Maximum temperature (°C)', 'Rainfall (mm)', 'Evaporation (mm)',\n",
        "                  'Sunshine (hours)', 'Humidity', 'WindSpeed']\n",
        "\n",
        "# Define lists to store accuracy metrics for each iteration\n",
        "mse_lists = []\n",
        "mae_lists = []\n",
        "mape_lists = []\n",
        "\n",
        "# Perform forward chaining\n",
        "for i in range(3):\n",
        "    # Split the data into train and test sets\n",
        "    train_data = data[:window_size + i * prediction_steps]\n",
        "    test_data = data[window_size + i * prediction_steps:window_size + (i+1) * prediction_steps]\n",
        "\n",
        "    # Convert train_data DataFrame to numpy array\n",
        "    train_array = train_data.values\n",
        "\n",
        "    # Reshape the train_data\n",
        "    X_train = train_array.reshape(train_array.shape[0], 1, train_array.shape[1])\n",
        "\n",
        "    # Define the RNN model\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(64, activation='relu', input_shape=(1, train_data.shape[1]), return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(32, activation='relu', return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(train_data.shape[1], activation='linear'))\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    model.fit(X_train, X_train, epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "    # Convert test_data DataFrame to numpy array\n",
        "    test_array = test_data.values\n",
        "\n",
        "    # Reshape the test_data window\n",
        "    X_test_window = test_array[:window_size].reshape(window_size, 1, test_array.shape[1])\n",
        "\n",
        "    # Make predictions on the test data window\n",
        "    predictions = model.predict(X_test_window)\n",
        "\n",
        "    # Reshape the predictions to match the original data shape\n",
        "    predictions = predictions.reshape(window_size, test_data.shape[1])\n",
        "\n",
        "    # Calculate the mean squared error for each variable\n",
        "    mse = mean_squared_error(test_data[:window_size], predictions, multioutput='raw_values')\n",
        "\n",
        "    # Calculate the Mean Absolute Error (MAE) for each variable\n",
        "    mae = mean_absolute_error(test_data[:window_size], predictions, multioutput='raw_values')\n",
        "\n",
        "    # Calculate the Mean Absolute Percentage Error (MAPE) for each variable\n",
        "    mape = mean_absolute_percentage_error(test_data[:window_size], predictions, multioutput='raw_values')\n",
        "\n",
        "    # Append the accuracy metrics to the respective lists\n",
        "    mse_lists.append(mse)\n",
        "    mae_lists.append(mae)\n",
        "    mape_lists.append(mape)\n",
        "\n",
        "# Create DataFrames to store the accuracy results for each iteration\n",
        "accuracy_dfs = []\n",
        "for i in range(3):\n",
        "    accuracy_df = pd.DataFrame({'Variable': variable_names, 'MSE': mse_lists[i],\n",
        "                                'MAE': mae_lists[i], 'MAPE': mape_lists[i]})\n",
        "    accuracy_df['Model'] = 'RNN'\n",
        "    accuracy_dfs.append(accuracy_df)\n",
        "\n",
        "# Print the accuracy results for each iteration\n",
        "for i, accuracy_df in enumerate(accuracy_dfs):\n",
        "    print(f\"Accuracy results for iteration {i+1}:\")\n",
        "    print(accuracy_df)\n",
        "    print()\n",
        "\n",
        "# Calculate the average accuracy across all iterations\n",
        "average_accuracy_df = pd.concat(accuracy_dfs).groupby('Variable').mean().reset_index()\n",
        "average_accuracy_df['Model'] = 'RNN'\n",
        "accuracy_rnn = average_accuracy_df\n",
        "# Print the average accuracy across all iterations\n",
        "print(\"Average accuracy across all iterations:\")\n",
        "print(average_accuracy_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6p2bSxiSs9z",
        "outputId": "886c6a6b-c0a2-42ae-b4df-d5cfb7cadd34"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 277ms/step\n",
            "1/1 [==============================] - 0s 253ms/step\n",
            "1/1 [==============================] - 0s 389ms/step\n",
            "Accuracy results for iteration 1:\n",
            "                   Variable          MSE        MAE          MAPE Model\n",
            "0  Minimum temperature (°C)    38.601167   5.812684  7.486403e-01   RNN\n",
            "1  Maximum temperature (°C)   116.324112  10.608683  6.372567e-01   RNN\n",
            "2             Rainfall (mm)     1.047637   0.738003  1.623491e+15   RNN\n",
            "3          Evaporation (mm)    22.487751   4.576424  8.563205e+14   RNN\n",
            "4          Sunshine (hours)    74.200168   7.862296  1.394028e+15   RNN\n",
            "5                  Humidity  1069.225641  30.596218  4.138883e-01   RNN\n",
            "6                 WindSpeed   234.036254  14.692819  1.717236e+00   RNN\n",
            "\n",
            "Accuracy results for iteration 2:\n",
            "                   Variable        MSE       MAE          MAPE Model\n",
            "0  Minimum temperature (°C)   7.946734  2.276051  3.363428e-01   RNN\n",
            "1  Maximum temperature (°C)  22.821188  4.390131  3.267304e-01   RNN\n",
            "2             Rainfall (mm)   6.111600  1.923276  1.696776e+15   RNN\n",
            "3          Evaporation (mm)   1.489060  1.022960  1.350063e+00   RNN\n",
            "4          Sunshine (hours)   4.849986  1.769070  2.187806e+14   RNN\n",
            "5                  Humidity  84.179281  8.609082  1.142687e-01   RNN\n",
            "6                 WindSpeed  23.384743  3.739787  2.974133e-01   RNN\n",
            "\n",
            "Accuracy results for iteration 3:\n",
            "                   Variable         MSE       MAE          MAPE Model\n",
            "0  Minimum temperature (°C)   12.888504  2.976815  1.016581e+00   RNN\n",
            "1  Maximum temperature (°C)   10.205192  2.782091  2.111349e-01   RNN\n",
            "2             Rainfall (mm)    4.873288  2.014399  5.180990e+15   RNN\n",
            "3          Evaporation (mm)    1.623721  1.096644  1.111923e+15   RNN\n",
            "4          Sunshine (hours)    9.495933  2.545984  4.501449e+14   RNN\n",
            "5                  Humidity  107.199206  9.680771  1.232055e-01   RNN\n",
            "6                 WindSpeed   16.992813  2.688696  2.941754e-01   RNN\n",
            "\n",
            "Average accuracy across all iterations:\n",
            "                   Variable         MSE        MAE          MAPE Model\n",
            "0          Evaporation (mm)    8.533511   2.232010  6.560811e+14   RNN\n",
            "1                  Humidity  420.201376  16.295357  2.171208e-01   RNN\n",
            "2  Maximum temperature (°C)   49.783498   5.926968  3.917073e-01   RNN\n",
            "3  Minimum temperature (°C)   19.812135   3.688517  7.005213e-01   RNN\n",
            "4             Rainfall (mm)    4.010842   1.558560  2.833752e+15   RNN\n",
            "5          Sunshine (hours)   29.515362   4.059117  6.876511e+14   RNN\n",
            "6                 WindSpeed   91.471270   7.040434  7.696083e-01   RNN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-b61b904b8ead>:86: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
            "  average_accuracy_df = pd.concat(accuracy_dfs).groupby('Variable').mean().reset_index()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "\n",
        "\n",
        "# Define the window size\n",
        "window_size = 30\n",
        "# Define the number of predictions to make\n",
        "prediction_steps = 30\n",
        "\n",
        "# Define the variable names\n",
        "variable_names = ['Minimum temperature (°C)', 'Maximum temperature (°C)', 'Rainfall (mm)', 'Evaporation (mm)',\n",
        "                  'Sunshine (hours)', 'Humidity', 'WindSpeed']\n",
        "\n",
        "# Define lists to store accuracy metrics for each iteration\n",
        "mse_lists = []\n",
        "mae_lists = []\n",
        "mape_lists = []\n",
        "\n",
        "# Perform forward chaining\n",
        "for i in range(4):\n",
        "    # Split the data into train and test sets\n",
        "    train_data = data[:window_size + i * prediction_steps]\n",
        "    test_data = data[window_size + i * prediction_steps:window_size + (i+1) * prediction_steps]\n",
        "\n",
        "    # Scale the data\n",
        "    scaler = MinMaxScaler()\n",
        "    train_scaled = scaler.fit_transform(train_data)\n",
        "    test_scaled = scaler.transform(test_data)\n",
        "\n",
        "    # Reshape the data\n",
        "    X_train = train_scaled[:-1].reshape(-1, 1, train_scaled.shape[1])\n",
        "    y_train = train_scaled[1:, :]  # Predict the next step\n",
        "\n",
        "    # Define the RNN model\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(64, activation='relu', input_shape=(1, train_data.shape[1]), return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(32, activation='relu', return_sequences=False))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(train_data.shape[1], activation='linear'))\n",
        "\n",
        "    # Define learning rate schedule\n",
        "    def lr_schedule(epoch):\n",
        "        lr = 0.001\n",
        "        if epoch > 50:\n",
        "            lr *= 0.1\n",
        "        elif epoch > 30:\n",
        "            lr *= 0.5\n",
        "        return lr\n",
        "\n",
        "    optimizer = Adam(learning_rate=lr_schedule(0))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=optimizer, loss='mse')\n",
        "\n",
        "    # Define early stopping\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    # Define learning rate scheduler\n",
        "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1,\n",
        "              validation_split=0.2, callbacks=[early_stopping, lr_scheduler])\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    X_test_window = test_scaled[:window_size].reshape(-1, 1, test_scaled.shape[1])\n",
        "    predictions = model.predict(X_test_window)\n",
        "\n",
        "    # Rescale the predictions to the original scale\n",
        "    predictions = scaler.inverse_transform(predictions)\n",
        "\n",
        "    # Calculate the mean squared error for each variable\n",
        "    mse = mean_squared_error(test_data[:window_size], predictions, multioutput='raw_values')\n",
        "\n",
        "    # Calculate the Mean Absolute Error (MAE) for each variable\n",
        "    mae = mean_absolute_error(test_data[:window_size], predictions, multioutput='raw_values')\n",
        "\n",
        "    # Calculate the Mean Absolute Percentage Error (MAPE) for each variable\n",
        "    mape = mean_absolute_percentage_error(test_data[:window_size], predictions, multioutput='raw_values')\n",
        "\n",
        "    # Store the accuracy metrics for this iteration\n",
        "    mse_lists.append(mse)\n",
        "    mae_lists.append(mae)\n",
        "    mape_lists.append(mape)\n",
        "\n",
        "    # Create a DataFrame to store the accuracy results\n",
        "    accuracy_df = pd.DataFrame({'Variable': variable_names, 'MSE': mse, 'MAE': mae, 'MAPE': mape})\n",
        "\n",
        "    # Add the model name to the DataFrame\n",
        "    accuracy_df['Model'] = 'RNN'\n",
        "\n",
        "    # Print the accuracy results for this iteration\n",
        "    print(f\"Accuracy results for iteration {i+1}:\")\n",
        "    print(accuracy_df)\n",
        "    print()\n",
        "\n",
        "# Calculate the average accuracy across all iterations\n",
        "average_mse = np.mean(mse_lists, axis=0)\n",
        "average_mae = np.mean(mae_lists, axis=0)\n",
        "average_mape = np.mean(mape_lists, axis=0)\n",
        "\n",
        "# Create a DataFrame for the average accuracy results\n",
        "average_accuracy_df = pd.DataFrame({'Variable': variable_names, 'MSE': average_mse, 'MAE': average_mae, 'MAPE': average_mape})\n",
        "\n",
        "# Add the model name to the DataFrame\n",
        "average_accuracy_df['Model'] = 'RNN Tuned'\n",
        "accuracy_rnn_tuned = average_accuracy_df\n",
        "# Print the average accuracy across all iterations\n",
        "print(\"Average accuracy across all iterations:\")\n",
        "print(average_accuracy_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUDamFzfYVmL",
        "outputId": "5526469d-30a2-413f-d8d6-4fd8600e3025"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2184 - val_loss: 0.2238 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2177 - val_loss: 0.2226 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.2161 - val_loss: 0.2213 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.2150 - val_loss: 0.2200 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.2135 - val_loss: 0.2188 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.2125 - val_loss: 0.2174 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2112 - val_loss: 0.2161 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2096 - val_loss: 0.2147 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2085 - val_loss: 0.2133 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2070 - val_loss: 0.2119 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.2062 - val_loss: 0.2105 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2049 - val_loss: 0.2090 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2033 - val_loss: 0.2075 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2014 - val_loss: 0.2060 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2003 - val_loss: 0.2044 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.1993 - val_loss: 0.2029 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1981 - val_loss: 0.2013 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1958 - val_loss: 0.1997 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1942 - val_loss: 0.1980 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1920 - val_loss: 0.1963 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1914 - val_loss: 0.1946 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1883 - val_loss: 0.1928 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1878 - val_loss: 0.1910 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1862 - val_loss: 0.1891 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1833 - val_loss: 0.1872 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1802 - val_loss: 0.1853 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1791 - val_loss: 0.1833 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1777 - val_loss: 0.1813 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1749 - val_loss: 0.1792 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1722 - val_loss: 0.1770 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1721 - val_loss: 0.1749 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1691 - val_loss: 0.1738 - lr: 5.0000e-04\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1687 - val_loss: 0.1726 - lr: 5.0000e-04\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1668 - val_loss: 0.1715 - lr: 5.0000e-04\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1660 - val_loss: 0.1704 - lr: 5.0000e-04\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1611 - val_loss: 0.1692 - lr: 5.0000e-04\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1658 - val_loss: 0.1680 - lr: 5.0000e-04\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1617 - val_loss: 0.1668 - lr: 5.0000e-04\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1604 - val_loss: 0.1656 - lr: 5.0000e-04\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1617 - val_loss: 0.1644 - lr: 5.0000e-04\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1601 - val_loss: 0.1631 - lr: 5.0000e-04\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1571 - val_loss: 0.1619 - lr: 5.0000e-04\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1580 - val_loss: 0.1606 - lr: 5.0000e-04\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1554 - val_loss: 0.1593 - lr: 5.0000e-04\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1510 - val_loss: 0.1580 - lr: 5.0000e-04\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1522 - val_loss: 0.1567 - lr: 5.0000e-04\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.1501 - val_loss: 0.1554 - lr: 5.0000e-04\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1461 - val_loss: 0.1540 - lr: 5.0000e-04\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1467 - val_loss: 0.1527 - lr: 5.0000e-04\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1473 - val_loss: 0.1513 - lr: 5.0000e-04\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1434 - val_loss: 0.1499 - lr: 5.0000e-04\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1421 - val_loss: 0.1496 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.1469 - val_loss: 0.1493 - lr: 1.0000e-04\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1430 - val_loss: 0.1490 - lr: 1.0000e-04\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1393 - val_loss: 0.1487 - lr: 1.0000e-04\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1413 - val_loss: 0.1484 - lr: 1.0000e-04\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1407 - val_loss: 0.1482 - lr: 1.0000e-04\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1431 - val_loss: 0.1479 - lr: 1.0000e-04\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.1407 - val_loss: 0.1476 - lr: 1.0000e-04\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1393 - val_loss: 0.1473 - lr: 1.0000e-04\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1401 - val_loss: 0.1470 - lr: 1.0000e-04\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1374 - val_loss: 0.1467 - lr: 1.0000e-04\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1374 - val_loss: 0.1464 - lr: 1.0000e-04\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1369 - val_loss: 0.1462 - lr: 1.0000e-04\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1353 - val_loss: 0.1459 - lr: 1.0000e-04\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1385 - val_loss: 0.1456 - lr: 1.0000e-04\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1350 - val_loss: 0.1453 - lr: 1.0000e-04\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.1391 - val_loss: 0.1450 - lr: 1.0000e-04\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1366 - val_loss: 0.1447 - lr: 1.0000e-04\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1351 - val_loss: 0.1444 - lr: 1.0000e-04\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1394 - val_loss: 0.1442 - lr: 1.0000e-04\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1403 - val_loss: 0.1439 - lr: 1.0000e-04\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1346 - val_loss: 0.1436 - lr: 1.0000e-04\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1390 - val_loss: 0.1433 - lr: 1.0000e-04\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1343 - val_loss: 0.1430 - lr: 1.0000e-04\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1368 - val_loss: 0.1427 - lr: 1.0000e-04\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1360 - val_loss: 0.1425 - lr: 1.0000e-04\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1377 - val_loss: 0.1422 - lr: 1.0000e-04\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1321 - val_loss: 0.1419 - lr: 1.0000e-04\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1339 - val_loss: 0.1416 - lr: 1.0000e-04\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1352 - val_loss: 0.1413 - lr: 1.0000e-04\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1311 - val_loss: 0.1411 - lr: 1.0000e-04\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1316 - val_loss: 0.1408 - lr: 1.0000e-04\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1350 - val_loss: 0.1405 - lr: 1.0000e-04\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1311 - val_loss: 0.1402 - lr: 1.0000e-04\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1381 - val_loss: 0.1399 - lr: 1.0000e-04\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1349 - val_loss: 0.1396 - lr: 1.0000e-04\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1293 - val_loss: 0.1394 - lr: 1.0000e-04\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1337 - val_loss: 0.1391 - lr: 1.0000e-04\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1295 - val_loss: 0.1388 - lr: 1.0000e-04\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1321 - val_loss: 0.1385 - lr: 1.0000e-04\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1345 - val_loss: 0.1382 - lr: 1.0000e-04\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1292 - val_loss: 0.1379 - lr: 1.0000e-04\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1306 - val_loss: 0.1376 - lr: 1.0000e-04\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1271 - val_loss: 0.1374 - lr: 1.0000e-04\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1333 - val_loss: 0.1371 - lr: 1.0000e-04\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1284 - val_loss: 0.1368 - lr: 1.0000e-04\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1317 - val_loss: 0.1365 - lr: 1.0000e-04\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1283 - val_loss: 0.1362 - lr: 1.0000e-04\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1261 - val_loss: 0.1359 - lr: 1.0000e-04\n",
            "1/1 [==============================] - 0s 243ms/step\n",
            "Accuracy results for iteration 1:\n",
            "                   Variable         MSE        MAE          MAPE Model\n",
            "0  Minimum temperature (°C)    7.476541   2.358831  2.784305e-01   RNN\n",
            "1  Maximum temperature (°C)    5.160882   1.921484  1.202227e-01   RNN\n",
            "2             Rainfall (mm)    6.214657   2.347226  7.692084e+15   RNN\n",
            "3          Evaporation (mm)    1.132144   0.795365  2.312316e+14   RNN\n",
            "4          Sunshine (hours)   18.520625   3.483981  1.763342e+14   RNN\n",
            "5                  Humidity  742.950277  24.882620  3.313938e-01   RNN\n",
            "6                 WindSpeed   30.163644   4.337326  4.144280e-01   RNN\n",
            "\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 2s 320ms/step - loss: 0.2313 - val_loss: 0.1324 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.2286 - val_loss: 0.1307 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.2261 - val_loss: 0.1291 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.2237 - val_loss: 0.1277 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.2210 - val_loss: 0.1262 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.2183 - val_loss: 0.1247 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.2166 - val_loss: 0.1232 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.2137 - val_loss: 0.1216 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.2104 - val_loss: 0.1200 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.2077 - val_loss: 0.1183 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.2049 - val_loss: 0.1165 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.2016 - val_loss: 0.1147 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.1982 - val_loss: 0.1128 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1944 - val_loss: 0.1107 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.1898 - val_loss: 0.1086 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.1864 - val_loss: 0.1064 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.1809 - val_loss: 0.1041 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.1768 - val_loss: 0.1017 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.1704 - val_loss: 0.0991 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.1658 - val_loss: 0.0964 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.1583 - val_loss: 0.0937 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.1546 - val_loss: 0.0908 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.1461 - val_loss: 0.0879 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.1384 - val_loss: 0.0849 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.1334 - val_loss: 0.0819 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.1254 - val_loss: 0.0789 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.1150 - val_loss: 0.0761 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.1078 - val_loss: 0.0734 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.1007 - val_loss: 0.0710 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0930 - val_loss: 0.0691 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0856 - val_loss: 0.0676 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0829 - val_loss: 0.0670 - lr: 5.0000e-04\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0828 - val_loss: 0.0665 - lr: 5.0000e-04\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0752 - val_loss: 0.0660 - lr: 5.0000e-04\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0728 - val_loss: 0.0655 - lr: 5.0000e-04\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0781 - val_loss: 0.0650 - lr: 5.0000e-04\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0706 - val_loss: 0.0644 - lr: 5.0000e-04\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0700 - val_loss: 0.0637 - lr: 5.0000e-04\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0722 - val_loss: 0.0629 - lr: 5.0000e-04\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0657 - val_loss: 0.0620 - lr: 5.0000e-04\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0689 - val_loss: 0.0610 - lr: 5.0000e-04\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0716 - val_loss: 0.0601 - lr: 5.0000e-04\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0669 - val_loss: 0.0590 - lr: 5.0000e-04\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0622 - val_loss: 0.0580 - lr: 5.0000e-04\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0677 - val_loss: 0.0571 - lr: 5.0000e-04\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0638 - val_loss: 0.0562 - lr: 5.0000e-04\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0666 - val_loss: 0.0553 - lr: 5.0000e-04\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0669 - val_loss: 0.0545 - lr: 5.0000e-04\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0662 - val_loss: 0.0538 - lr: 5.0000e-04\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0658 - val_loss: 0.0532 - lr: 5.0000e-04\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0654 - val_loss: 0.0525 - lr: 5.0000e-04\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0651 - val_loss: 0.0524 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0637 - val_loss: 0.0523 - lr: 1.0000e-04\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0608 - val_loss: 0.0522 - lr: 1.0000e-04\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0588 - val_loss: 0.0521 - lr: 1.0000e-04\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0654 - val_loss: 0.0520 - lr: 1.0000e-04\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0626 - val_loss: 0.0520 - lr: 1.0000e-04\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0601 - val_loss: 0.0519 - lr: 1.0000e-04\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0626 - val_loss: 0.0519 - lr: 1.0000e-04\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0661 - val_loss: 0.0518 - lr: 1.0000e-04\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0601 - val_loss: 0.0517 - lr: 1.0000e-04\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0642 - val_loss: 0.0517 - lr: 1.0000e-04\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0629 - val_loss: 0.0516 - lr: 1.0000e-04\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0605 - val_loss: 0.0516 - lr: 1.0000e-04\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0631 - val_loss: 0.0516 - lr: 1.0000e-04\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0656 - val_loss: 0.0515 - lr: 1.0000e-04\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0645 - val_loss: 0.0515 - lr: 1.0000e-04\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0636 - val_loss: 0.0514 - lr: 1.0000e-04\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0634 - val_loss: 0.0514 - lr: 1.0000e-04\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.0569 - val_loss: 0.0513 - lr: 1.0000e-04\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0633 - val_loss: 0.0513 - lr: 1.0000e-04\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0615 - val_loss: 0.0512 - lr: 1.0000e-04\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0610 - val_loss: 0.0512 - lr: 1.0000e-04\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0602 - val_loss: 0.0512 - lr: 1.0000e-04\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0673 - val_loss: 0.0511 - lr: 1.0000e-04\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0637 - val_loss: 0.0511 - lr: 1.0000e-04\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0635 - val_loss: 0.0511 - lr: 1.0000e-04\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0609 - val_loss: 0.0511 - lr: 1.0000e-04\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0642 - val_loss: 0.0510 - lr: 1.0000e-04\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0601 - val_loss: 0.0510 - lr: 1.0000e-04\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0621 - val_loss: 0.0509 - lr: 1.0000e-04\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0637 - val_loss: 0.0509 - lr: 1.0000e-04\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0633 - val_loss: 0.0508 - lr: 1.0000e-04\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0616 - val_loss: 0.0508 - lr: 1.0000e-04\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0600 - val_loss: 0.0507 - lr: 1.0000e-04\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0632 - val_loss: 0.0507 - lr: 1.0000e-04\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0611 - val_loss: 0.0506 - lr: 1.0000e-04\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0641 - val_loss: 0.0506 - lr: 1.0000e-04\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0633 - val_loss: 0.0505 - lr: 1.0000e-04\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0618 - val_loss: 0.0505 - lr: 1.0000e-04\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0619 - val_loss: 0.0504 - lr: 1.0000e-04\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0583 - val_loss: 0.0504 - lr: 1.0000e-04\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0618 - val_loss: 0.0504 - lr: 1.0000e-04\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0614 - val_loss: 0.0504 - lr: 1.0000e-04\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0602 - val_loss: 0.0503 - lr: 1.0000e-04\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0586 - val_loss: 0.0503 - lr: 1.0000e-04\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0632 - val_loss: 0.0503 - lr: 1.0000e-04\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0625 - val_loss: 0.0503 - lr: 1.0000e-04\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0622 - val_loss: 0.0502 - lr: 1.0000e-04\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0659 - val_loss: 0.0502 - lr: 1.0000e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1dc0838430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 238ms/step\n",
            "Accuracy results for iteration 2:\n",
            "                   Variable         MSE        MAE          MAPE Model\n",
            "0  Minimum temperature (°C)    6.536453   2.090597  3.101010e-01   RNN\n",
            "1  Maximum temperature (°C)   16.457952   3.839226  2.878801e-01   RNN\n",
            "2             Rainfall (mm)    9.684213   2.322235  1.875892e+15   RNN\n",
            "3          Evaporation (mm)    1.042058   0.858503  1.149340e+00   RNN\n",
            "4          Sunshine (hours)    3.912084   1.621056  4.160239e+14   RNN\n",
            "5                  Humidity  321.788768  15.624875  2.011678e-01   RNN\n",
            "6                 WindSpeed   27.925182   4.156319  3.092577e-01   RNN\n",
            "\n",
            "Epoch 1/100\n",
            "3/3 [==============================] - 2s 165ms/step - loss: 0.1821 - val_loss: 0.1278 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1788 - val_loss: 0.1249 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1753 - val_loss: 0.1220 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1721 - val_loss: 0.1191 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1689 - val_loss: 0.1160 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1649 - val_loss: 0.1128 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1612 - val_loss: 0.1094 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1570 - val_loss: 0.1059 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1528 - val_loss: 0.1021 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1487 - val_loss: 0.0981 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1433 - val_loss: 0.0938 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1392 - val_loss: 0.0891 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1318 - val_loss: 0.0841 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1258 - val_loss: 0.0787 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1190 - val_loss: 0.0729 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1115 - val_loss: 0.0667 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.1035 - val_loss: 0.0603 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0956 - val_loss: 0.0537 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0874 - val_loss: 0.0471 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0791 - val_loss: 0.0409 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0748 - val_loss: 0.0355 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0663 - val_loss: 0.0313 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0617 - val_loss: 0.0284 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0619 - val_loss: 0.0268 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0578 - val_loss: 0.0265 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0555 - val_loss: 0.0270 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0568 - val_loss: 0.0278 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0537 - val_loss: 0.0289 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0556 - val_loss: 0.0300 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0522 - val_loss: 0.0311 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0509 - val_loss: 0.0321 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0528 - val_loss: 0.0326 - lr: 5.0000e-04\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0540 - val_loss: 0.0328 - lr: 5.0000e-04\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0513 - val_loss: 0.0329 - lr: 5.0000e-04\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0497 - val_loss: 0.0330 - lr: 5.0000e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1dafd66f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 247ms/step\n",
            "Accuracy results for iteration 3:\n",
            "                   Variable         MSE        MAE          MAPE Model\n",
            "0  Minimum temperature (°C)    9.964916   2.356330  9.090145e-01   RNN\n",
            "1  Maximum temperature (°C)    7.273930   2.410475  1.849280e-01   RNN\n",
            "2             Rainfall (mm)    5.170902   2.092654  5.824907e+15   RNN\n",
            "3          Evaporation (mm)    0.673406   0.658064  6.977382e+14   RNN\n",
            "4          Sunshine (hours)    9.509352   2.548129  4.594481e+14   RNN\n",
            "5                  Humidity  180.177606  11.331777  1.406556e-01   RNN\n",
            "6                 WindSpeed   16.217238   2.683677  2.891303e-01   RNN\n",
            "\n",
            "Epoch 1/100\n",
            "3/3 [==============================] - 2s 159ms/step - loss: 0.1783 - val_loss: 0.1392 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1751 - val_loss: 0.1361 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1714 - val_loss: 0.1328 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1678 - val_loss: 0.1294 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1635 - val_loss: 0.1257 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1600 - val_loss: 0.1219 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1552 - val_loss: 0.1178 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1502 - val_loss: 0.1134 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1454 - val_loss: 0.1087 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1394 - val_loss: 0.1036 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1338 - val_loss: 0.0982 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1267 - val_loss: 0.0924 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1196 - val_loss: 0.0862 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1130 - val_loss: 0.0798 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1061 - val_loss: 0.0732 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0983 - val_loss: 0.0665 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0894 - val_loss: 0.0600 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0805 - val_loss: 0.0540 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0732 - val_loss: 0.0487 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0695 - val_loss: 0.0446 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0635 - val_loss: 0.0416 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0620 - val_loss: 0.0396 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0564 - val_loss: 0.0384 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0551 - val_loss: 0.0377 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0541 - val_loss: 0.0373 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0496 - val_loss: 0.0372 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0476 - val_loss: 0.0373 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0463 - val_loss: 0.0376 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0438 - val_loss: 0.0380 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0455 - val_loss: 0.0384 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0416 - val_loss: 0.0387 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0453 - val_loss: 0.0387 - lr: 5.0000e-04\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0446 - val_loss: 0.0387 - lr: 5.0000e-04\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0461 - val_loss: 0.0386 - lr: 5.0000e-04\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0448 - val_loss: 0.0385 - lr: 5.0000e-04\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0457 - val_loss: 0.0385 - lr: 5.0000e-04\n",
            "1/1 [==============================] - 0s 251ms/step\n",
            "Accuracy results for iteration 4:\n",
            "                   Variable         MSE        MAE          MAPE Model\n",
            "0  Minimum temperature (°C)    5.882456   2.011933  3.474575e-01   RNN\n",
            "1  Maximum temperature (°C)    4.413434   1.766761  1.220177e-01   RNN\n",
            "2             Rainfall (mm)    8.000006   1.973999  3.284526e+15   RNN\n",
            "3          Evaporation (mm)    1.776533   1.157056  1.270372e+00   RNN\n",
            "4          Sunshine (hours)    9.198248   2.758183  7.323111e+14   RNN\n",
            "5                  Humidity  168.470762  10.809065  1.681056e-01   RNN\n",
            "6                 WindSpeed   39.746899   4.978731  3.483820e-01   RNN\n",
            "\n",
            "Average accuracy across all iterations:\n",
            "                   Variable         MSE        MAE          MAPE      Model\n",
            "0  Minimum temperature (°C)    7.465091   2.204423  4.612509e-01  RNN Tuned\n",
            "1  Maximum temperature (°C)    8.326550   2.484487  1.787621e-01  RNN Tuned\n",
            "2             Rainfall (mm)    7.267445   2.184029  4.669352e+15  RNN Tuned\n",
            "3          Evaporation (mm)    1.156035   0.867247  2.322424e+14  RNN Tuned\n",
            "4          Sunshine (hours)   10.285077   2.602837  4.460293e+14  RNN Tuned\n",
            "5                  Humidity  353.346853  15.662085  2.103307e-01  RNN Tuned\n",
            "6                 WindSpeed   28.513241   4.039013  3.402995e-01  RNN Tuned\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "average_accuracy_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "O5fkfOENsNN9",
        "outputId": "620fb294-bad8-4ab2-f38b-364eefd641cb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   Variable         MSE        MAE          MAPE      Model\n",
              "0  Minimum temperature (°C)    7.465091   2.204423  4.612509e-01  RNN Tuned\n",
              "1  Maximum temperature (°C)    8.326550   2.484487  1.787621e-01  RNN Tuned\n",
              "2             Rainfall (mm)    7.267445   2.184029  4.669352e+15  RNN Tuned\n",
              "3          Evaporation (mm)    1.156035   0.867247  2.322424e+14  RNN Tuned\n",
              "4          Sunshine (hours)   10.285077   2.602837  4.460293e+14  RNN Tuned\n",
              "5                  Humidity  353.346853  15.662085  2.103307e-01  RNN Tuned\n",
              "6                 WindSpeed   28.513241   4.039013  3.402995e-01  RNN Tuned"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff7e9876-d8a6-460d-a605-ead44acd1029\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Variable</th>\n",
              "      <th>MSE</th>\n",
              "      <th>MAE</th>\n",
              "      <th>MAPE</th>\n",
              "      <th>Model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Minimum temperature (°C)</td>\n",
              "      <td>7.465091</td>\n",
              "      <td>2.204423</td>\n",
              "      <td>4.612509e-01</td>\n",
              "      <td>RNN Tuned</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Maximum temperature (°C)</td>\n",
              "      <td>8.326550</td>\n",
              "      <td>2.484487</td>\n",
              "      <td>1.787621e-01</td>\n",
              "      <td>RNN Tuned</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Rainfall (mm)</td>\n",
              "      <td>7.267445</td>\n",
              "      <td>2.184029</td>\n",
              "      <td>4.669352e+15</td>\n",
              "      <td>RNN Tuned</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Evaporation (mm)</td>\n",
              "      <td>1.156035</td>\n",
              "      <td>0.867247</td>\n",
              "      <td>2.322424e+14</td>\n",
              "      <td>RNN Tuned</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sunshine (hours)</td>\n",
              "      <td>10.285077</td>\n",
              "      <td>2.602837</td>\n",
              "      <td>4.460293e+14</td>\n",
              "      <td>RNN Tuned</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Humidity</td>\n",
              "      <td>353.346853</td>\n",
              "      <td>15.662085</td>\n",
              "      <td>2.103307e-01</td>\n",
              "      <td>RNN Tuned</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>WindSpeed</td>\n",
              "      <td>28.513241</td>\n",
              "      <td>4.039013</td>\n",
              "      <td>3.402995e-01</td>\n",
              "      <td>RNN Tuned</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff7e9876-d8a6-460d-a605-ead44acd1029')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ff7e9876-d8a6-460d-a605-ead44acd1029 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ff7e9876-d8a6-460d-a605-ead44acd1029');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from prophet import Prophet\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Define the window size\n",
        "window_size = 30\n",
        "# Define the number of predictions to make\n",
        "prediction_steps = 30\n",
        "\n",
        "# Define the variable names\n",
        "variable_names = ['Minimum temperature (°C)', 'Maximum temperature (°C)', 'Rainfall (mm)', 'Evaporation (mm)',\n",
        "                  'Sunshine (hours)', 'Humidity', 'WindSpeed']\n",
        "\n",
        "# Define lists to store accuracy metrics for each iteration\n",
        "mse_lists = []\n",
        "mae_lists = []\n",
        "mape_lists = []\n",
        "\n",
        "# Perform forward chaining\n",
        "for i in range(4):\n",
        "    # Split the data into train and test sets\n",
        "    train_data = data[:window_size + i * prediction_steps]\n",
        "    test_data = data[window_size + i * prediction_steps:window_size + (i+1) * prediction_steps]\n",
        "\n",
        "    # Initialize lists to store the results for each variable in this iteration\n",
        "    mse_iteration = []\n",
        "    mae_iteration = []\n",
        "    mape_iteration = []\n",
        "\n",
        "    # Iterate over each variable\n",
        "    for variable in variable_names:\n",
        "        # Prepare the train data for Prophet\n",
        "        train_data_prophet = train_data.reset_index()[['Date', variable]].rename(columns={'Date': 'ds', variable: 'y'})\n",
        "\n",
        "        # Instantiate a new Prophet model\n",
        "        model = Prophet()\n",
        "\n",
        "        # Fit the Prophet model to the training data\n",
        "        model.fit(train_data_prophet)\n",
        "\n",
        "        # Generate future dates for forecasting\n",
        "        future_dates = model.make_future_dataframe(periods=len(test_data))\n",
        "\n",
        "        # Make predictions for the future dates\n",
        "        forecast = model.predict(future_dates)\n",
        "\n",
        "        # Extract the predicted values\n",
        "        predictions = forecast['yhat'].values[-len(test_data):]\n",
        "\n",
        "        # Calculate the mean squared error for the variable\n",
        "        mse = mean_squared_error(test_data[variable], predictions)\n",
        "        mse_iteration.append(mse)\n",
        "\n",
        "        # Calculate the mean absolute error for the variable\n",
        "        mae = mean_absolute_error(test_data[variable], predictions)\n",
        "        mae_iteration.append(mae)\n",
        "\n",
        "        # Calculate the mean absolute percentage error for the variable\n",
        "        mape = mean_absolute_percentage_error(test_data[variable], predictions)\n",
        "        mape_iteration.append(mape)\n",
        "\n",
        "    # Store the accuracy metrics for this iteration\n",
        "    mse_lists.append(mse_iteration)\n",
        "    mae_lists.append(mae_iteration)\n",
        "    mape_lists.append(mape_iteration)\n",
        "\n",
        "    # Create a DataFrame to store the accuracy results\n",
        "    accuracy_df_iteration = pd.DataFrame({'Variable': variable_names, 'MSE': mse_iteration, 'MAE': mae_iteration, 'MAPE': mape_iteration})\n",
        "\n",
        "    # Add the model name to the DataFrame\n",
        "    accuracy_df_iteration['Model'] = 'Prophet'\n",
        "\n",
        "    # Print the accuracy results for this iteration\n",
        "    print(f\"Accuracy results for iteration {i+1}:\")\n",
        "    print(accuracy_df_iteration)\n",
        "    print()\n",
        "\n",
        "# Calculate the average accuracy across all iterations\n",
        "average_mse = np.mean(mse_lists, axis=0)\n",
        "average_mae = np.mean(mae_lists, axis=0)\n",
        "average_mape = np.mean(mape_lists, axis=0)\n",
        "\n",
        "# Create a DataFrame for the average accuracy results\n",
        "average_accuracy_df = pd.DataFrame({'Variable': variable_names, 'MSE': average_mse, 'MAE': average_mae, 'MAPE': average_mape})\n",
        "\n",
        "# Add the model name to the DataFrame\n",
        "average_accuracy_df['Model'] = 'Prophet'\n",
        "accuracy_prophet = average_accuracy_df\n",
        "# Print the average accuracy across all iterations\n",
        "print(\"Average accuracy across all iterations:\")\n",
        "print(average_accuracy_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qj8kxlbgStDl",
        "outputId": "b814bd71-e15b-4fff-90b5-0aca9174bdb0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:prophet:n_changepoints greater than number of observations. Using 23.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/ur4ka76x.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/pxki4_8d.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=49608', 'data', 'file=/tmp/tmpd97zdvrr/ur4ka76x.json', 'init=/tmp/tmpd97zdvrr/pxki4_8d.json', 'output', 'file=/tmp/tmpd97zdvrr/prophet_model8llpcgu0/prophet_model-20230626131451.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:14:51 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:14:51 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:prophet:n_changepoints greater than number of observations. Using 23.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/9pj6pz1l.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/9n_chlmp.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=68867', 'data', 'file=/tmp/tmpd97zdvrr/9pj6pz1l.json', 'init=/tmp/tmpd97zdvrr/9n_chlmp.json', 'output', 'file=/tmp/tmpd97zdvrr/prophet_modelvujbq7sp/prophet_model-20230626131451.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:14:51 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:14:51 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:prophet:n_changepoints greater than number of observations. Using 23.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/8aidch8t.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/9oqzgwpl.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=89964', 'data', 'file=/tmp/tmpd97zdvrr/8aidch8t.json', 'init=/tmp/tmpd97zdvrr/9oqzgwpl.json', 'output', 'file=/tmp/tmpd97zdvrr/prophet_modeltf3oda67/prophet_model-20230626131451.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:14:51 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:14:51 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:prophet:n_changepoints greater than number of observations. Using 23.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/djbc8xm6.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/fnnb2gz4.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=36210', 'data', 'file=/tmp/tmpd97zdvrr/djbc8xm6.json', 'init=/tmp/tmpd97zdvrr/fnnb2gz4.json', 'output', 'file=/tmp/tmpd97zdvrr/prophet_modelm9hj68hq/prophet_model-20230626131451.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:14:51 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:14:52 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:prophet:n_changepoints greater than number of observations. Using 23.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/o9evciyb.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/f7c7p63d.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=43451', 'data', 'file=/tmp/tmpd97zdvrr/o9evciyb.json', 'init=/tmp/tmpd97zdvrr/f7c7p63d.json', 'output', 'file=/tmp/tmpd97zdvrr/prophet_modelef89znns/prophet_model-20230626131452.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:14:52 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:14:52 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:prophet:n_changepoints greater than number of observations. Using 23.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/ke1b__8u.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/3oezcnom.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=45926', 'data', 'file=/tmp/tmpd97zdvrr/ke1b__8u.json', 'init=/tmp/tmpd97zdvrr/3oezcnom.json', 'output', 'file=/tmp/tmpd97zdvrr/prophet_modelfv4v_kjt/prophet_model-20230626131452.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:14:52 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:14:52 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:prophet:n_changepoints greater than number of observations. Using 23.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/0r7pxm6g.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/1i9jpsab.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=41868', 'data', 'file=/tmp/tmpd97zdvrr/0r7pxm6g.json', 'init=/tmp/tmpd97zdvrr/1i9jpsab.json', 'output', 'file=/tmp/tmpd97zdvrr/prophet_modelieuku22c/prophet_model-20230626131452.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:14:52 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:14:52 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/r93uuw84.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/wbo5nupr.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=94405', 'data', 'file=/tmp/tmpd97zdvrr/r93uuw84.json', 'init=/tmp/tmpd97zdvrr/wbo5nupr.json', 'output', 'file=/tmp/tmpd97zdvrr/prophet_modelxqf18d04/prophet_model-20230626131452.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:14:52 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy results for iteration 1:\n",
            "                   Variable         MSE        MAE          MAPE    Model\n",
            "0  Minimum temperature (°C)   10.162924   2.696287  3.671691e-01  Prophet\n",
            "1  Maximum temperature (°C)   22.684516   4.273116  2.726191e-01  Prophet\n",
            "2             Rainfall (mm)   92.191511   9.060998  2.807378e+16  Prophet\n",
            "3          Evaporation (mm)    5.362251   1.998545  3.882539e+14  Prophet\n",
            "4          Sunshine (hours)   12.009355   3.115955  5.067406e+14  Prophet\n",
            "5                  Humidity  215.076392  11.363568  1.487599e-01  Prophet\n",
            "6                 WindSpeed   17.658924   3.402434  5.092523e-01  Prophet\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13:14:53 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/_e6e62ed.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/hnv98l6s.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=39439', 'data', 'file=/tmp/tmpd97zdvrr/_e6e62ed.json', 'init=/tmp/tmpd97zdvrr/hnv98l6s.json', 'output', 'file=/tmp/tmpd97zdvrr/prophet_model_xsh4rnf/prophet_model-20230626131453.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:14:53 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:14:53 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/8az8ol_h.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/3cirtk9i.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=93658', 'data', 'file=/tmp/tmpd97zdvrr/8az8ol_h.json', 'init=/tmp/tmpd97zdvrr/3cirtk9i.json', 'output', 'file=/tmp/tmpd97zdvrr/prophet_modelgckiu7ce/prophet_model-20230626131453.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:14:53 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:14:53 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/gg7q0swj.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/bybf2_pi.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=50791', 'data', 'file=/tmp/tmpd97zdvrr/gg7q0swj.json', 'init=/tmp/tmpd97zdvrr/bybf2_pi.json', 'output', 'file=/tmp/tmpd97zdvrr/prophet_modelwmu24gi7/prophet_model-20230626131453.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:14:53 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:14:53 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/_koeq3kc.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/6yh0j5w9.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=93130', 'data', 'file=/tmp/tmpd97zdvrr/_koeq3kc.json', 'init=/tmp/tmpd97zdvrr/6yh0j5w9.json', 'output', 'file=/tmp/tmpd97zdvrr/prophet_modelex17j9ga/prophet_model-20230626131454.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:14:54 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:14:54 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/u20xwg7t.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/jsn9svnz.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=91546', 'data', 'file=/tmp/tmpd97zdvrr/u20xwg7t.json', 'init=/tmp/tmpd97zdvrr/jsn9svnz.json', 'output', 'file=/tmp/tmpd97zdvrr/prophet_modelv7_zvroy/prophet_model-20230626131454.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:14:54 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:14:54 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/hvhz4tx_.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/kdkr7qbs.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=45775', 'data', 'file=/tmp/tmpd97zdvrr/hvhz4tx_.json', 'init=/tmp/tmpd97zdvrr/kdkr7qbs.json', 'output', 'file=/tmp/tmpd97zdvrr/prophet_modelp2qba1x1/prophet_model-20230626131454.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:14:54 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:14:54 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/yam952db.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/z92mhym2.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=26543', 'data', 'file=/tmp/tmpd97zdvrr/yam952db.json', 'init=/tmp/tmpd97zdvrr/z92mhym2.json', 'output', 'file=/tmp/tmpd97zdvrr/prophet_modelwcyya5v9/prophet_model-20230626131454.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:14:54 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy results for iteration 2:\n",
            "                   Variable        MSE       MAE          MAPE    Model\n",
            "0  Minimum temperature (°C)   9.672027  2.669442  3.074018e-01  Prophet\n",
            "1  Maximum temperature (°C)   5.396755  1.829827  1.288849e-01  Prophet\n",
            "2             Rainfall (mm)  12.254830  2.430203  1.366432e+15  Prophet\n",
            "3          Evaporation (mm)   2.782078  1.340571  7.527297e-01  Prophet\n",
            "4          Sunshine (hours)   3.950902  1.514283  3.651977e+14  Prophet\n",
            "5                  Humidity  97.662440  8.273350  1.156890e-01  Prophet\n",
            "6                 WindSpeed  32.741244  4.304802  3.168732e-01  Prophet\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13:14:54 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/zpfm9sdn.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/lh8one3k.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=17406', 'data', 'file=/tmp/tmpd97zdvrr/zpfm9sdn.json', 'init=/tmp/tmpd97zdvrr/lh8one3k.json', 'output', 'file=/tmp/tmpd97zdvrr/prophet_model8nms5zhc/prophet_model-20230626131454.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:14:54 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:14:55 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/wwwn8ne8.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/pgue7xrp.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=93668', 'data', 'file=/tmp/tmpd97zdvrr/wwwn8ne8.json', 'init=/tmp/tmpd97zdvrr/pgue7xrp.json', 'output', 'file=/tmp/tmpd97zdvrr/prophet_model7tu_hw_8/prophet_model-20230626131455.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:14:55 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:14:55 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/swld9tr_.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/ailh0io2.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=81668', 'data', 'file=/tmp/tmpd97zdvrr/swld9tr_.json', 'init=/tmp/tmpd97zdvrr/ailh0io2.json', 'output', 'file=/tmp/tmpd97zdvrr/prophet_modelcz80c40a/prophet_model-20230626131455.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:14:55 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:14:55 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/dyvx4s1m.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/ievd7i49.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=78851', 'data', 'file=/tmp/tmpd97zdvrr/dyvx4s1m.json', 'init=/tmp/tmpd97zdvrr/ievd7i49.json', 'output', 'file=/tmp/tmpd97zdvrr/prophet_model8j2iq7eg/prophet_model-20230626131455.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:14:55 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:14:55 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/ifo2w35t.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/4ly70djc.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=91499', 'data', 'file=/tmp/tmpd97zdvrr/ifo2w35t.json', 'init=/tmp/tmpd97zdvrr/4ly70djc.json', 'output', 'file=/tmp/tmpd97zdvrr/prophet_modeli7jm55p7/prophet_model-20230626131455.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:14:55 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:14:56 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/7wox0vqp.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/a9x1ppsm.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=59927', 'data', 'file=/tmp/tmpd97zdvrr/7wox0vqp.json', 'init=/tmp/tmpd97zdvrr/a9x1ppsm.json', 'output', 'file=/tmp/tmpd97zdvrr/prophet_model1ruxvk4m/prophet_model-20230626131456.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:14:56 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:14:56 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/he_93u5q.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/y1yhq8r4.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=62708', 'data', 'file=/tmp/tmpd97zdvrr/he_93u5q.json', 'init=/tmp/tmpd97zdvrr/y1yhq8r4.json', 'output', 'file=/tmp/tmpd97zdvrr/prophet_model7ksi5aj7/prophet_model-20230626131456.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:14:56 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:14:56 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/6zyxjf_2.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/7_qcz4zf.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=53304', 'data', 'file=/tmp/tmpd97zdvrr/6zyxjf_2.json', 'init=/tmp/tmpd97zdvrr/7_qcz4zf.json', 'output', 'file=/tmp/tmpd97zdvrr/prophet_modelpx82jt_5/prophet_model-20230626131456.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:14:56 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:14:56 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy results for iteration 3:\n",
            "                   Variable        MSE       MAE          MAPE    Model\n",
            "0  Minimum temperature (°C)   7.554662  2.396779  6.453317e-01  Prophet\n",
            "1  Maximum temperature (°C)  14.806963  3.042899  2.006176e-01  Prophet\n",
            "2             Rainfall (mm)   4.532654  1.583607  3.645113e+15  Prophet\n",
            "3          Evaporation (mm)   1.362991  0.983266  4.830444e+14  Prophet\n",
            "4          Sunshine (hours)  15.660946  3.212404  5.832669e+14  Prophet\n",
            "5                  Humidity  98.196245  8.297045  1.125674e-01  Prophet\n",
            "6                 WindSpeed  21.580867  3.655658  4.378841e-01  Prophet\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/6a0cnhm2.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/aouzmt0n.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=27081', 'data', 'file=/tmp/tmpd97zdvrr/6a0cnhm2.json', 'init=/tmp/tmpd97zdvrr/aouzmt0n.json', 'output', 'file=/tmp/tmpd97zdvrr/prophet_modele3e6da3f/prophet_model-20230626131456.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:14:56 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:14:56 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/bel1hu5a.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/ahaq_vju.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=94735', 'data', 'file=/tmp/tmpd97zdvrr/bel1hu5a.json', 'init=/tmp/tmpd97zdvrr/ahaq_vju.json', 'output', 'file=/tmp/tmpd97zdvrr/prophet_modelj1nht_s5/prophet_model-20230626131456.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:14:56 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:14:56 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/1mm2ch93.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/o0ny3453.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=87232', 'data', 'file=/tmp/tmpd97zdvrr/1mm2ch93.json', 'init=/tmp/tmpd97zdvrr/o0ny3453.json', 'output', 'file=/tmp/tmpd97zdvrr/prophet_modelms279dnd/prophet_model-20230626131457.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:14:57 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:14:57 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/5tbwyu_2.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/6mk90mwx.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=21359', 'data', 'file=/tmp/tmpd97zdvrr/5tbwyu_2.json', 'init=/tmp/tmpd97zdvrr/6mk90mwx.json', 'output', 'file=/tmp/tmpd97zdvrr/prophet_modelvoht097u/prophet_model-20230626131457.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:14:57 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:14:57 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/pa8lvfz7.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpd97zdvrr/fz0hormm.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=78146', 'data', 'file=/tmp/tmpd97zdvrr/pa8lvfz7.json', 'init=/tmp/tmpd97zdvrr/fz0hormm.json', 'output', 'file=/tmp/tmpd97zdvrr/prophet_model1r3ltvvk/prophet_model-20230626131457.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:14:57 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:14:57 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy results for iteration 4:\n",
            "                   Variable         MSE        MAE          MAPE    Model\n",
            "0  Minimum temperature (°C)   18.257357   3.792806  4.889755e-01  Prophet\n",
            "1  Maximum temperature (°C)   10.907582   2.526972  1.504136e-01  Prophet\n",
            "2             Rainfall (mm)    8.137316   1.798478  2.585708e+15  Prophet\n",
            "3          Evaporation (mm)    4.906538   1.735573  6.456854e-01  Prophet\n",
            "4          Sunshine (hours)   11.220272   3.052170  4.758392e+14  Prophet\n",
            "5                  Humidity  284.124520  14.211979  2.367927e-01  Prophet\n",
            "6                 WindSpeed   41.410417   4.985428  3.760263e-01  Prophet\n",
            "\n",
            "Average accuracy across all iterations:\n",
            "                   Variable         MSE        MAE          MAPE    Model\n",
            "0  Minimum temperature (°C)   11.411743   2.888828  4.522195e-01  Prophet\n",
            "1  Maximum temperature (°C)   13.448954   2.918203  1.881338e-01  Prophet\n",
            "2             Rainfall (mm)   29.279078   3.718321  8.917759e+15  Prophet\n",
            "3          Evaporation (mm)    3.603465   1.514489  2.178246e+14  Prophet\n",
            "4          Sunshine (hours)   10.710369   2.723703  4.827611e+14  Prophet\n",
            "5                  Humidity  173.764899  10.536485  1.534522e-01  Prophet\n",
            "6                 WindSpeed   28.347863   4.087080  4.100090e-01  Prophet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "\n",
        "# Define the window size\n",
        "window_size = 60\n",
        "# Define the number of predictions to make\n",
        "prediction_steps = 30\n",
        "\n",
        "# Define the variable names\n",
        "variable_names = ['Minimum temperature (°C)', 'Maximum temperature (°C)', 'Rainfall (mm)', 'Evaporation (mm)',\n",
        "                  'Sunshine (hours)', 'Humidity', 'WindSpeed']\n",
        "\n",
        "# Define lists to store accuracy metrics for each iteration\n",
        "mse_lists = []\n",
        "mae_lists = []\n",
        "mape_lists = []\n",
        "\n",
        "# Define lists to store training accuracy for each iteration\n",
        "train_loss_lists = []\n",
        "\n",
        "# Define lists to store test accuracy for each iteration\n",
        "test_mse_lists = []\n",
        "test_mae_lists = []\n",
        "test_mape_lists = []\n",
        "\n",
        "# Perform forward chaining\n",
        "for i in range(4):\n",
        "    # Split the data into train and test sets\n",
        "    train_data = data[:window_size + i * prediction_steps]\n",
        "    test_data = data[window_size + i * prediction_steps:window_size + (i+1) * prediction_steps]\n",
        "\n",
        "    # Scale the data\n",
        "    scaler = MinMaxScaler()\n",
        "    train_scaled = scaler.fit_transform(train_data)\n",
        "    test_scaled = scaler.transform(test_data)\n",
        "\n",
        "    # Reshape the data\n",
        "    X_train = train_scaled[:-1].reshape(-1, 1, train_scaled.shape[1])\n",
        "    y_train = train_scaled[1:, :]  # Predict the next step\n",
        "\n",
        "    # Define the LSTM model\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(64, activation='relu', input_shape=(1, train_data.shape[1]), return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(32, activation='relu', return_sequences=False))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(train_data.shape[1], activation='linear'))\n",
        "\n",
        "    # Define learning rate schedule\n",
        "    def lr_schedule(epoch):\n",
        "        lr = 0.001\n",
        "        if epoch > 50:\n",
        "            lr *= 0.1\n",
        "        elif epoch > 30:\n",
        "            lr *= 0.5\n",
        "        return lr\n",
        "\n",
        "    optimizer = Adam(learning_rate=lr_schedule(0))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=optimizer, loss='mse')\n",
        "\n",
        "    # Define early stopping\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    # Define learning rate scheduler\n",
        "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    history = model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1,\n",
        "                        validation_split=0.2, callbacks=[early_stopping, lr_scheduler])\n",
        "\n",
        "    # Store the training loss for this iteration\n",
        "    train_loss_lists.append(history.history['loss'])\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    X_test_window = test_scaled[:window_size].reshape(-1, 1, test_scaled.shape[1])\n",
        "    predictions = model.predict(X_test_window)\n",
        "\n",
        "    # Rescale the predictions to the original scale\n",
        "    predictions = scaler.inverse_transform(predictions)\n",
        "\n",
        "    # Calculate the mean squared error for each variable\n",
        "    mse = mean_squared_error(test_data[:window_size], predictions, multioutput='raw_values')\n",
        "\n",
        "    # Calculate the Mean Absolute Error (MAE) for each variable\n",
        "    mae = mean_absolute_error(test_data[:window_size], predictions, multioutput='raw_values')\n",
        "\n",
        "    # Calculate the Mean Absolute Percentage Error (MAPE) for each variable\n",
        "    mape = mean_absolute_percentage_error(test_data[:window_size], predictions, multioutput='raw_values')\n",
        "\n",
        "    # Store the accuracy metrics for this iteration\n",
        "    mse_lists.append(mse)\n",
        "    mae_lists.append(mae)\n",
        "    mape_lists.append(mape)\n",
        "\n",
        "    # Store the test accuracy metrics for this iteration\n",
        "    test_mse_lists.append(mse)\n",
        "    test_mae_lists.append(mae)\n",
        "    test_mape_lists.append(mape)\n",
        "\n",
        "    # Create a DataFrame to store the accuracy results\n",
        "    accuracy_df = pd.DataFrame({'Variable': variable_names, 'MSE': mse, 'MAE': mae, 'MAPE': mape})\n",
        "\n",
        "    # Add the model name to the DataFrame\n",
        "    accuracy_df['Model'] = 'LSTM'\n",
        "\n",
        "    # Print the accuracy results for this iteration\n",
        "    print(f\"Accuracy results for iteration {i+1}:\")\n",
        "    print(accuracy_df)\n",
        "    print()\n",
        "\n",
        "# Calculate the average accuracy across all iterations\n",
        "average_mse = np.mean(mse_lists, axis=0)\n",
        "average_mae = np.mean(mae_lists, axis=0)\n",
        "average_mape = np.mean(mape_lists, axis=0)\n",
        "\n",
        "# Create a DataFrame for the average accuracy results\n",
        "average_accuracy_df = pd.DataFrame({'Variable': variable_names, 'MSE': average_mse, 'MAE': average_mae, 'MAPE': average_mape})\n",
        "\n",
        "# Add the model name to the DataFrame\n",
        "average_accuracy_df['Model'] = 'LSTM'\n",
        "\n",
        "# Print the average accuracy across all iterations\n",
        "print(\"Average accuracy across all iterations:\")\n",
        "print(average_accuracy_df)\n",
        "\n",
        "# Convert the training loss lists to a DataFrame\n",
        "train_loss_df = pd.DataFrame(train_loss_lists).transpose()\n",
        "train_loss_df.columns = [f'Iteration {i+1}' for i in range(len(train_loss_lists))]\n",
        "\n",
        "# Plot the training loss for each iteration\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_loss_df)\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(train_loss_df.columns)\n",
        "plt.show()\n",
        "\n",
        "# Calculate the average test accuracy across all iterations\n",
        "average_test_mse = np.mean(test_mse_lists, axis=0)\n",
        "average_test_mae = np.mean(test_mae_lists, axis=0)\n",
        "average_test_mape = np.mean(test_mape_lists, axis=0)\n",
        "\n",
        "# Create a DataFrame for the average test accuracy results\n",
        "average_test_accuracy_df = pd.DataFrame({'Variable': variable_names, 'MSE': average_test_mse, 'MAE': average_test_mae, 'MAPE': average_test_mape})\n",
        "\n",
        "# Add the model name to the DataFrame\n",
        "average_test_accuracy_df['Model'] = 'LSTM'\n",
        "accuracy_lstm = average_accuracy_df\n",
        "# Print the average test accuracy across all iterations\n",
        "print(\"Average test accuracy across all iterations:\")\n",
        "print(average_test_accuracy_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rYOlZrMgaihn",
        "outputId": "834ad986-fcc9-4e08-e138-2d1f31b80f7a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 2s 321ms/step - loss: 0.2304 - val_loss: 0.1309 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.2276 - val_loss: 0.1290 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.2249 - val_loss: 0.1269 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.2217 - val_loss: 0.1248 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.2183 - val_loss: 0.1227 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.2154 - val_loss: 0.1205 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.2122 - val_loss: 0.1182 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.2093 - val_loss: 0.1159 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2051 - val_loss: 0.1135 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2018 - val_loss: 0.1110 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.1986 - val_loss: 0.1084 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.1946 - val_loss: 0.1058 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.1894 - val_loss: 0.1030 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.1864 - val_loss: 0.1001 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.1807 - val_loss: 0.0971 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.1764 - val_loss: 0.0940 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.1707 - val_loss: 0.0908 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.1650 - val_loss: 0.0874 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.1602 - val_loss: 0.0839 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.1536 - val_loss: 0.0803 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.1473 - val_loss: 0.0766 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.1407 - val_loss: 0.0728 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.1350 - val_loss: 0.0690 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.1299 - val_loss: 0.0652 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.1189 - val_loss: 0.0613 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.1118 - val_loss: 0.0576 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.1076 - val_loss: 0.0541 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0967 - val_loss: 0.0509 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0927 - val_loss: 0.0481 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0853 - val_loss: 0.0459 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0788 - val_loss: 0.0444 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0741 - val_loss: 0.0438 - lr: 5.0000e-04\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0720 - val_loss: 0.0435 - lr: 5.0000e-04\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0762 - val_loss: 0.0434 - lr: 5.0000e-04\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0757 - val_loss: 0.0434 - lr: 5.0000e-04\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0712 - val_loss: 0.0436 - lr: 5.0000e-04\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0694 - val_loss: 0.0438 - lr: 5.0000e-04\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0656 - val_loss: 0.0441 - lr: 5.0000e-04\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.0725 - val_loss: 0.0444 - lr: 5.0000e-04\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0711 - val_loss: 0.0447 - lr: 5.0000e-04\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0652 - val_loss: 0.0451 - lr: 5.0000e-04\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.0631 - val_loss: 0.0454 - lr: 5.0000e-04\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.0662 - val_loss: 0.0457 - lr: 5.0000e-04\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0626 - val_loss: 0.0459 - lr: 5.0000e-04\n",
            "1/1 [==============================] - 0s 237ms/step\n",
            "Accuracy results for iteration 1:\n",
            "                   Variable         MSE        MAE          MAPE Model\n",
            "0  Minimum temperature (°C)    3.259061   1.569974  2.205751e-01  LSTM\n",
            "1  Maximum temperature (°C)   15.770419   3.720841  2.798216e-01  LSTM\n",
            "2             Rainfall (mm)    9.011057   2.317354  2.148031e+15  LSTM\n",
            "3          Evaporation (mm)    1.745364   1.097254  1.471745e+00  LSTM\n",
            "4          Sunshine (hours)    4.221808   1.655119  3.264413e+14  LSTM\n",
            "5                  Humidity  184.874877  10.697827  1.348058e-01  LSTM\n",
            "6                 WindSpeed   37.589240   4.891772  3.586464e-01  LSTM\n",
            "\n",
            "Epoch 1/100\n",
            "3/3 [==============================] - 2s 239ms/step - loss: 0.1817 - val_loss: 0.1275 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.1782 - val_loss: 0.1246 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.1746 - val_loss: 0.1216 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.1706 - val_loss: 0.1186 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.1668 - val_loss: 0.1154 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.1629 - val_loss: 0.1121 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1581 - val_loss: 0.1086 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1540 - val_loss: 0.1050 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.1484 - val_loss: 0.1010 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1435 - val_loss: 0.0968 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1370 - val_loss: 0.0924 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.1314 - val_loss: 0.0875 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.1262 - val_loss: 0.0824 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.1197 - val_loss: 0.0769 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.1100 - val_loss: 0.0712 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.1033 - val_loss: 0.0653 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0940 - val_loss: 0.0595 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0859 - val_loss: 0.0540 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0781 - val_loss: 0.0490 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0705 - val_loss: 0.0449 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0631 - val_loss: 0.0418 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0594 - val_loss: 0.0401 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0569 - val_loss: 0.0397 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0566 - val_loss: 0.0391 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0542 - val_loss: 0.0387 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0581 - val_loss: 0.0380 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0557 - val_loss: 0.0370 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0543 - val_loss: 0.0362 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0520 - val_loss: 0.0353 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0536 - val_loss: 0.0350 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0516 - val_loss: 0.0349 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0532 - val_loss: 0.0349 - lr: 5.0000e-04\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0544 - val_loss: 0.0348 - lr: 5.0000e-04\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0512 - val_loss: 0.0347 - lr: 5.0000e-04\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0494 - val_loss: 0.0347 - lr: 5.0000e-04\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0509 - val_loss: 0.0346 - lr: 5.0000e-04\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0500 - val_loss: 0.0345 - lr: 5.0000e-04\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0483 - val_loss: 0.0344 - lr: 5.0000e-04\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0519 - val_loss: 0.0344 - lr: 5.0000e-04\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0524 - val_loss: 0.0343 - lr: 5.0000e-04\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0531 - val_loss: 0.0343 - lr: 5.0000e-04\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0505 - val_loss: 0.0344 - lr: 5.0000e-04\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0509 - val_loss: 0.0344 - lr: 5.0000e-04\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0516 - val_loss: 0.0345 - lr: 5.0000e-04\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0515 - val_loss: 0.0346 - lr: 5.0000e-04\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0535 - val_loss: 0.0346 - lr: 5.0000e-04\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0554 - val_loss: 0.0346 - lr: 5.0000e-04\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0508 - val_loss: 0.0346 - lr: 5.0000e-04\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0512 - val_loss: 0.0344 - lr: 5.0000e-04\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0490 - val_loss: 0.0343 - lr: 5.0000e-04\n",
            "1/1 [==============================] - 0s 274ms/step\n",
            "Accuracy results for iteration 2:\n",
            "                   Variable         MSE        MAE          MAPE Model\n",
            "0  Minimum temperature (°C)   15.987502   3.348730  1.139606e+00  LSTM\n",
            "1  Maximum temperature (°C)   12.017318   3.153800  2.422860e-01  LSTM\n",
            "2             Rainfall (mm)    3.543550   1.440762  3.135341e+15  LSTM\n",
            "3          Evaporation (mm)    1.055396   0.879863  8.879852e+14  LSTM\n",
            "4          Sunshine (hours)    8.317832   2.379957  5.008853e+14  LSTM\n",
            "5                  Humidity  270.443368  14.101310  1.739588e-01  LSTM\n",
            "6                 WindSpeed   15.510619   2.248638  2.176885e-01  LSTM\n",
            "\n",
            "Epoch 1/100\n",
            "3/3 [==============================] - 2s 158ms/step - loss: 0.1797 - val_loss: 0.1410 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1763 - val_loss: 0.1381 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1725 - val_loss: 0.1351 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1687 - val_loss: 0.1318 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1645 - val_loss: 0.1282 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1602 - val_loss: 0.1244 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1548 - val_loss: 0.1203 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1488 - val_loss: 0.1159 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1439 - val_loss: 0.1111 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1373 - val_loss: 0.1060 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1297 - val_loss: 0.1006 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1222 - val_loss: 0.0949 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1135 - val_loss: 0.0888 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1055 - val_loss: 0.0824 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0968 - val_loss: 0.0759 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0868 - val_loss: 0.0695 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0765 - val_loss: 0.0634 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0689 - val_loss: 0.0582 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0613 - val_loss: 0.0542 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0530 - val_loss: 0.0519 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0498 - val_loss: 0.0510 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0492 - val_loss: 0.0508 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0487 - val_loss: 0.0502 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0499 - val_loss: 0.0485 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0485 - val_loss: 0.0463 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0476 - val_loss: 0.0442 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0468 - val_loss: 0.0425 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0441 - val_loss: 0.0413 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0453 - val_loss: 0.0405 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0431 - val_loss: 0.0398 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0431 - val_loss: 0.0394 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0421 - val_loss: 0.0392 - lr: 5.0000e-04\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0431 - val_loss: 0.0391 - lr: 5.0000e-04\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0423 - val_loss: 0.0390 - lr: 5.0000e-04\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0419 - val_loss: 0.0389 - lr: 5.0000e-04\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0416 - val_loss: 0.0388 - lr: 5.0000e-04\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0410 - val_loss: 0.0388 - lr: 5.0000e-04\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0427 - val_loss: 0.0387 - lr: 5.0000e-04\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0435 - val_loss: 0.0387 - lr: 5.0000e-04\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0403 - val_loss: 0.0387 - lr: 5.0000e-04\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0421 - val_loss: 0.0386 - lr: 5.0000e-04\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0413 - val_loss: 0.0386 - lr: 5.0000e-04\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0430 - val_loss: 0.0385 - lr: 5.0000e-04\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0428 - val_loss: 0.0385 - lr: 5.0000e-04\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0422 - val_loss: 0.0385 - lr: 5.0000e-04\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0413 - val_loss: 0.0384 - lr: 5.0000e-04\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0412 - val_loss: 0.0383 - lr: 5.0000e-04\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0405 - val_loss: 0.0383 - lr: 5.0000e-04\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0424 - val_loss: 0.0382 - lr: 5.0000e-04\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0415 - val_loss: 0.0382 - lr: 5.0000e-04\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0407 - val_loss: 0.0381 - lr: 5.0000e-04\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0415 - val_loss: 0.0381 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0417 - val_loss: 0.0381 - lr: 1.0000e-04\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0403 - val_loss: 0.0381 - lr: 1.0000e-04\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0425 - val_loss: 0.0381 - lr: 1.0000e-04\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0418 - val_loss: 0.0381 - lr: 1.0000e-04\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0412 - val_loss: 0.0380 - lr: 1.0000e-04\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0417 - val_loss: 0.0380 - lr: 1.0000e-04\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0426 - val_loss: 0.0380 - lr: 1.0000e-04\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0411 - val_loss: 0.0381 - lr: 1.0000e-04\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0403 - val_loss: 0.0380 - lr: 1.0000e-04\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0411 - val_loss: 0.0381 - lr: 1.0000e-04\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0423 - val_loss: 0.0381 - lr: 1.0000e-04\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0406 - val_loss: 0.0380 - lr: 1.0000e-04\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0407 - val_loss: 0.0380 - lr: 1.0000e-04\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0418 - val_loss: 0.0380 - lr: 1.0000e-04\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0417 - val_loss: 0.0380 - lr: 1.0000e-04\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0418 - val_loss: 0.0380 - lr: 1.0000e-04\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0432 - val_loss: 0.0380 - lr: 1.0000e-04\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0406 - val_loss: 0.0380 - lr: 1.0000e-04\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0423 - val_loss: 0.0380 - lr: 1.0000e-04\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0404 - val_loss: 0.0380 - lr: 1.0000e-04\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0397 - val_loss: 0.0380 - lr: 1.0000e-04\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0402 - val_loss: 0.0380 - lr: 1.0000e-04\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0398 - val_loss: 0.0380 - lr: 1.0000e-04\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0414 - val_loss: 0.0380 - lr: 1.0000e-04\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0411 - val_loss: 0.0380 - lr: 1.0000e-04\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0419 - val_loss: 0.0380 - lr: 1.0000e-04\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0395 - val_loss: 0.0379 - lr: 1.0000e-04\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0408 - val_loss: 0.0379 - lr: 1.0000e-04\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0397 - val_loss: 0.0379 - lr: 1.0000e-04\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0396 - val_loss: 0.0379 - lr: 1.0000e-04\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0415 - val_loss: 0.0379 - lr: 1.0000e-04\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0403 - val_loss: 0.0379 - lr: 1.0000e-04\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0411 - val_loss: 0.0379 - lr: 1.0000e-04\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0405 - val_loss: 0.0379 - lr: 1.0000e-04\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0390 - val_loss: 0.0379 - lr: 1.0000e-04\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0413 - val_loss: 0.0379 - lr: 1.0000e-04\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0421 - val_loss: 0.0379 - lr: 1.0000e-04\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0420 - val_loss: 0.0379 - lr: 1.0000e-04\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0408 - val_loss: 0.0379 - lr: 1.0000e-04\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0408 - val_loss: 0.0379 - lr: 1.0000e-04\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0422 - val_loss: 0.0378 - lr: 1.0000e-04\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0407 - val_loss: 0.0378 - lr: 1.0000e-04\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0404 - val_loss: 0.0378 - lr: 1.0000e-04\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0419 - val_loss: 0.0378 - lr: 1.0000e-04\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0414 - val_loss: 0.0378 - lr: 1.0000e-04\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0403 - val_loss: 0.0378 - lr: 1.0000e-04\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0418 - val_loss: 0.0377 - lr: 1.0000e-04\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0421 - val_loss: 0.0377 - lr: 1.0000e-04\n",
            "1/1 [==============================] - 0s 245ms/step\n",
            "Accuracy results for iteration 3:\n",
            "                   Variable         MSE       MAE          MAPE Model\n",
            "0  Minimum temperature (°C)    6.882510  2.121844  4.390625e-01  LSTM\n",
            "1  Maximum temperature (°C)    4.852093  1.912817  1.326023e-01  LSTM\n",
            "2             Rainfall (mm)    7.919896  1.850629  2.947228e+15  LSTM\n",
            "3          Evaporation (mm)    1.701152  1.015917  8.504266e-01  LSTM\n",
            "4          Sunshine (hours)   11.469807  3.040294  6.296005e+14  LSTM\n",
            "5                  Humidity  139.609420  9.788759  1.518912e-01  LSTM\n",
            "6                 WindSpeed   35.488078  4.661980  3.353684e-01  LSTM\n",
            "\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 3s 131ms/step - loss: 0.1723 - val_loss: 0.1671 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1680 - val_loss: 0.1630 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1635 - val_loss: 0.1588 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1590 - val_loss: 0.1543 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1545 - val_loss: 0.1494 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1489 - val_loss: 0.1442 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1432 - val_loss: 0.1385 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1363 - val_loss: 0.1321 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1305 - val_loss: 0.1250 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1232 - val_loss: 0.1171 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1142 - val_loss: 0.1082 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1051 - val_loss: 0.0984 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0938 - val_loss: 0.0879 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0810 - val_loss: 0.0770 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0706 - val_loss: 0.0666 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0600 - val_loss: 0.0580 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0526 - val_loss: 0.0521 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.0497 - val_loss: 0.0489 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 0.0475 - val_loss: 0.0469 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.0494 - val_loss: 0.0448 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.0459 - val_loss: 0.0431 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.0453 - val_loss: 0.0424 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.0448 - val_loss: 0.0424 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0433 - val_loss: 0.0427 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0441 - val_loss: 0.0427 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0445 - val_loss: 0.0425 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0432 - val_loss: 0.0424 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0426 - val_loss: 0.0422 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0428 - val_loss: 0.0422 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0403 - val_loss: 0.0421 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0435 - val_loss: 0.0419 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0402 - val_loss: 0.0418 - lr: 5.0000e-04\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0431 - val_loss: 0.0419 - lr: 5.0000e-04\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0416 - val_loss: 0.0420 - lr: 5.0000e-04\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0421 - val_loss: 0.0421 - lr: 5.0000e-04\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0398 - val_loss: 0.0422 - lr: 5.0000e-04\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0421 - val_loss: 0.0422 - lr: 5.0000e-04\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0421 - val_loss: 0.0422 - lr: 5.0000e-04\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0431 - val_loss: 0.0422 - lr: 5.0000e-04\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0423 - val_loss: 0.0422 - lr: 5.0000e-04\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0419 - val_loss: 0.0422 - lr: 5.0000e-04\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0410 - val_loss: 0.0422 - lr: 5.0000e-04\n",
            "1/1 [==============================] - 0s 239ms/step\n",
            "Accuracy results for iteration 4:\n",
            "                   Variable         MSE       MAE          MAPE Model\n",
            "0  Minimum temperature (°C)    3.910363  1.603808  2.294769e-01  LSTM\n",
            "1  Maximum temperature (°C)    4.323598  1.621215  9.880123e-02  LSTM\n",
            "2             Rainfall (mm)    8.782088  2.048013  2.352371e+15  LSTM\n",
            "3          Evaporation (mm)    1.787646  1.013554  9.285002e-01  LSTM\n",
            "4          Sunshine (hours)   12.947218  3.151260  1.885704e+15  LSTM\n",
            "5                  Humidity  103.423744  8.229188  1.282012e-01  LSTM\n",
            "6                 WindSpeed   15.596801  3.027312  2.595170e-01  LSTM\n",
            "\n",
            "Average accuracy across all iterations:\n",
            "                   Variable         MSE        MAE          MAPE Model\n",
            "0  Minimum temperature (°C)    7.509859   2.161089  5.071800e-01  LSTM\n",
            "1  Maximum temperature (°C)    9.240857   2.602168  1.883778e-01  LSTM\n",
            "2             Rainfall (mm)    7.314148   1.914189  2.645743e+15  LSTM\n",
            "3          Evaporation (mm)    1.572390   1.001647  2.219963e+14  LSTM\n",
            "4          Sunshine (hours)    9.239166   2.556658  8.356579e+14  LSTM\n",
            "5                  Humidity  174.587852  10.704271  1.472143e-01  LSTM\n",
            "6                 WindSpeed   26.046185   3.707425  2.928051e-01  LSTM\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average test accuracy across all iterations:\n",
            "                   Variable         MSE        MAE          MAPE Model\n",
            "0  Minimum temperature (°C)    7.509859   2.161089  5.071800e-01  LSTM\n",
            "1  Maximum temperature (°C)    9.240857   2.602168  1.883778e-01  LSTM\n",
            "2             Rainfall (mm)    7.314148   1.914189  2.645743e+15  LSTM\n",
            "3          Evaporation (mm)    1.572390   1.001647  2.219963e+14  LSTM\n",
            "4          Sunshine (hours)    9.239166   2.556658  8.356579e+14  LSTM\n",
            "5                  Humidity  174.587852  10.704271  1.472143e-01  LSTM\n",
            "6                 WindSpeed   26.046185   3.707425  2.928051e-01  LSTM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "\n",
        "# Define the window size\n",
        "window_size = 30\n",
        "# Define the number of predictions to make\n",
        "prediction_steps = 30\n",
        "\n",
        "# Define the variable names\n",
        "variable_names = ['Minimum temperature (°C)', 'Maximum temperature (°C)', 'Rainfall (mm)', 'Evaporation (mm)',\n",
        "                  'Sunshine (hours)', 'Humidity', 'WindSpeed']\n",
        "\n",
        "# Define lists to store accuracy metrics for each iteration\n",
        "mse_lists = []\n",
        "mae_lists = []\n",
        "mape_lists = []\n",
        "\n",
        "# Perform forward chaining\n",
        "for i in range(4):\n",
        "    # Split the data into train and test sets\n",
        "    train_data = data[:window_size + i * prediction_steps]\n",
        "    test_data = data[window_size + i * prediction_steps:window_size + (i+1) * prediction_steps]\n",
        "\n",
        "    # Scale the data\n",
        "    scaler = MinMaxScaler()\n",
        "    train_scaled = scaler.fit_transform(train_data)\n",
        "    test_scaled = scaler.transform(test_data)\n",
        "\n",
        "    # Reshape the data\n",
        "    X_train = train_scaled[:-1]\n",
        "    y_train = train_scaled[1:, :]  # Predict the next step\n",
        "\n",
        "    # Define the feedforward neural network model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(train_data.shape[1], activation='linear'))\n",
        "\n",
        "    # Define learning rate schedule\n",
        "    def lr_schedule(epoch):\n",
        "        lr = 0.001\n",
        "        if epoch > 50:\n",
        "            lr *= 0.1\n",
        "        elif epoch > 30:\n",
        "            lr *= 0.5\n",
        "        return lr\n",
        "\n",
        "    optimizer = Adam(learning_rate=lr_schedule(0))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=optimizer, loss='mse')\n",
        "\n",
        "    # Define early stopping\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    # Define learning rate scheduler\n",
        "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1,\n",
        "              validation_split=0.2, callbacks=[early_stopping, lr_scheduler])\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    predictions = model.predict(test_scaled[:-1])\n",
        "\n",
        "    # Rescale the predictions to the original scale\n",
        "    predictions = scaler.inverse_transform(predictions)\n",
        "\n",
        "    # Calculate the mean squared error for each variable\n",
        "    mse = mean_squared_error(test_data[1:], predictions, multioutput='raw_values')\n",
        "\n",
        "    # Calculate the Mean Absolute Error (MAE) for each variable\n",
        "    mae = mean_absolute_error(test_data[1:], predictions, multioutput='raw_values')\n",
        "\n",
        "    # Calculate the Mean Absolute Percentage Error (MAPE) for each variable\n",
        "    mape = mean_absolute_percentage_error(test_data[1:], predictions, multioutput='raw_values')\n",
        "\n",
        "    # Store the accuracy metrics for this iteration\n",
        "    mse_lists.append(mse)\n",
        "    mae_lists.append(mae)\n",
        "    mape_lists.append(mape)\n",
        "\n",
        "    # Create a DataFrame to store the accuracy results\n",
        "    accuracy_df = pd.DataFrame({'Variable': variable_names, 'MSE': mse, 'MAE': mae, 'MAPE': mape})\n",
        "\n",
        "    # Add the model name to the DataFrame\n",
        "    accuracy_df['Model'] = 'Feedforward Neural Network'\n",
        "\n",
        "    # Print the accuracy results for this iteration\n",
        "    print(f\"Accuracy results for iteration {i+1}:\")\n",
        "    print(accuracy_df)\n",
        "    print()\n",
        "\n",
        "# Calculate the average accuracy across all iterations\n",
        "average_mse = np.mean(mse_lists, axis=0)\n",
        "average_mae = np.mean(mae_lists, axis=0)\n",
        "average_mape = np.mean(mape_lists, axis=0)\n",
        "\n",
        "# Create a DataFrame for the average accuracy results\n",
        "average_accuracy_df = pd.DataFrame({'Variable': variable_names, 'MSE': average_mse, 'MAE': average_mae, 'MAPE': average_mape})\n",
        "\n",
        "# Add the model name to the DataFrame\n",
        "average_accuracy_df['Model'] = 'Feedforward Neural Network'\n",
        "accuracy_fnn = average_accuracy_df\n",
        "# Print the average accuracy across all iterations\n",
        "print(\"Average accuracy across all iterations:\")\n",
        "print(average_accuracy_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dsnTb47lLV9",
        "outputId": "1aa7f809-a899-44dd-ea8c-9bcf5be4d077"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2921 - val_loss: 0.2701 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2786 - val_loss: 0.2619 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2673 - val_loss: 0.2542 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2598 - val_loss: 0.2468 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2541 - val_loss: 0.2398 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2456 - val_loss: 0.2332 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2374 - val_loss: 0.2268 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2255 - val_loss: 0.2209 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.2250 - val_loss: 0.2152 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2156 - val_loss: 0.2098 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.2047 - val_loss: 0.2047 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2063 - val_loss: 0.2000 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2085 - val_loss: 0.1955 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1936 - val_loss: 0.1915 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1936 - val_loss: 0.1875 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1745 - val_loss: 0.1837 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.1708 - val_loss: 0.1802 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1699 - val_loss: 0.1770 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1677 - val_loss: 0.1738 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1573 - val_loss: 0.1707 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1625 - val_loss: 0.1677 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1642 - val_loss: 0.1648 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1584 - val_loss: 0.1621 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1493 - val_loss: 0.1598 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1460 - val_loss: 0.1573 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1473 - val_loss: 0.1546 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1374 - val_loss: 0.1519 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1546 - val_loss: 0.1493 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1349 - val_loss: 0.1468 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1441 - val_loss: 0.1444 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1250 - val_loss: 0.1421 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1243 - val_loss: 0.1410 - lr: 5.0000e-04\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1293 - val_loss: 0.1399 - lr: 5.0000e-04\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1246 - val_loss: 0.1389 - lr: 5.0000e-04\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1223 - val_loss: 0.1379 - lr: 5.0000e-04\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1203 - val_loss: 0.1368 - lr: 5.0000e-04\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1368 - val_loss: 0.1358 - lr: 5.0000e-04\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1166 - val_loss: 0.1347 - lr: 5.0000e-04\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1251 - val_loss: 0.1337 - lr: 5.0000e-04\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1205 - val_loss: 0.1327 - lr: 5.0000e-04\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1197 - val_loss: 0.1316 - lr: 5.0000e-04\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1232 - val_loss: 0.1306 - lr: 5.0000e-04\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1220 - val_loss: 0.1296 - lr: 5.0000e-04\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1135 - val_loss: 0.1287 - lr: 5.0000e-04\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1035 - val_loss: 0.1277 - lr: 5.0000e-04\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1103 - val_loss: 0.1267 - lr: 5.0000e-04\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1083 - val_loss: 0.1258 - lr: 5.0000e-04\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1159 - val_loss: 0.1249 - lr: 5.0000e-04\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1045 - val_loss: 0.1240 - lr: 5.0000e-04\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0962 - val_loss: 0.1230 - lr: 5.0000e-04\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1147 - val_loss: 0.1221 - lr: 5.0000e-04\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1161 - val_loss: 0.1220 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1050 - val_loss: 0.1218 - lr: 1.0000e-04\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1075 - val_loss: 0.1216 - lr: 1.0000e-04\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0982 - val_loss: 0.1214 - lr: 1.0000e-04\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1087 - val_loss: 0.1213 - lr: 1.0000e-04\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1049 - val_loss: 0.1211 - lr: 1.0000e-04\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1043 - val_loss: 0.1209 - lr: 1.0000e-04\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1061 - val_loss: 0.1207 - lr: 1.0000e-04\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1081 - val_loss: 0.1206 - lr: 1.0000e-04\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0963 - val_loss: 0.1204 - lr: 1.0000e-04\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1077 - val_loss: 0.1202 - lr: 1.0000e-04\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.1024 - val_loss: 0.1200 - lr: 1.0000e-04\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1055 - val_loss: 0.1199 - lr: 1.0000e-04\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.1008 - val_loss: 0.1197 - lr: 1.0000e-04\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1062 - val_loss: 0.1195 - lr: 1.0000e-04\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1120 - val_loss: 0.1193 - lr: 1.0000e-04\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1043 - val_loss: 0.1192 - lr: 1.0000e-04\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0997 - val_loss: 0.1190 - lr: 1.0000e-04\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1094 - val_loss: 0.1188 - lr: 1.0000e-04\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1085 - val_loss: 0.1186 - lr: 1.0000e-04\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0957 - val_loss: 0.1185 - lr: 1.0000e-04\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1080 - val_loss: 0.1183 - lr: 1.0000e-04\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0968 - val_loss: 0.1181 - lr: 1.0000e-04\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0979 - val_loss: 0.1179 - lr: 1.0000e-04\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0998 - val_loss: 0.1177 - lr: 1.0000e-04\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0892 - val_loss: 0.1175 - lr: 1.0000e-04\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1042 - val_loss: 0.1173 - lr: 1.0000e-04\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1013 - val_loss: 0.1171 - lr: 1.0000e-04\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0999 - val_loss: 0.1169 - lr: 1.0000e-04\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0956 - val_loss: 0.1168 - lr: 1.0000e-04\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0948 - val_loss: 0.1166 - lr: 1.0000e-04\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0925 - val_loss: 0.1164 - lr: 1.0000e-04\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1066 - val_loss: 0.1162 - lr: 1.0000e-04\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0984 - val_loss: 0.1160 - lr: 1.0000e-04\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1032 - val_loss: 0.1159 - lr: 1.0000e-04\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0985 - val_loss: 0.1157 - lr: 1.0000e-04\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0928 - val_loss: 0.1155 - lr: 1.0000e-04\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0988 - val_loss: 0.1154 - lr: 1.0000e-04\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0908 - val_loss: 0.1152 - lr: 1.0000e-04\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1056 - val_loss: 0.1150 - lr: 1.0000e-04\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0973 - val_loss: 0.1149 - lr: 1.0000e-04\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0873 - val_loss: 0.1147 - lr: 1.0000e-04\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0959 - val_loss: 0.1145 - lr: 1.0000e-04\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0993 - val_loss: 0.1144 - lr: 1.0000e-04\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0945 - val_loss: 0.1142 - lr: 1.0000e-04\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0976 - val_loss: 0.1140 - lr: 1.0000e-04\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1058 - val_loss: 0.1139 - lr: 1.0000e-04\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1006 - val_loss: 0.1137 - lr: 1.0000e-04\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1120 - val_loss: 0.1135 - lr: 1.0000e-04\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "Accuracy results for iteration 1:\n",
            "                   Variable         MSE        MAE          MAPE  \\\n",
            "0  Minimum temperature (°C)    8.471986   2.542680  3.108053e-01   \n",
            "1  Maximum temperature (°C)    7.275790   2.298525  1.462880e-01   \n",
            "2             Rainfall (mm)    1.671764   1.080741  2.553977e+15   \n",
            "3          Evaporation (mm)    2.089610   1.222091  4.175086e+14   \n",
            "4          Sunshine (hours)   13.327845   3.300631  6.848749e+14   \n",
            "5                  Humidity  396.323119  16.546191  2.121608e-01   \n",
            "6                 WindSpeed   20.298227   3.563833  3.950482e-01   \n",
            "\n",
            "                        Model  \n",
            "0  Feedforward Neural Network  \n",
            "1  Feedforward Neural Network  \n",
            "2  Feedforward Neural Network  \n",
            "3  Feedforward Neural Network  \n",
            "4  Feedforward Neural Network  \n",
            "5  Feedforward Neural Network  \n",
            "6  Feedforward Neural Network  \n",
            "\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.2432 - val_loss: 0.1281 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.2337 - val_loss: 0.1216 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.2173 - val_loss: 0.1157 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.2064 - val_loss: 0.1103 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.1879 - val_loss: 0.1050 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.1738 - val_loss: 0.0995 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.1701 - val_loss: 0.0942 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.1563 - val_loss: 0.0890 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.1521 - val_loss: 0.0840 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.1435 - val_loss: 0.0791 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.1225 - val_loss: 0.0744 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.1136 - val_loss: 0.0698 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.1092 - val_loss: 0.0652 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.1065 - val_loss: 0.0611 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0969 - val_loss: 0.0574 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0858 - val_loss: 0.0541 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.1033 - val_loss: 0.0509 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1012 - val_loss: 0.0483 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0841 - val_loss: 0.0464 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0833 - val_loss: 0.0450 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0718 - val_loss: 0.0440 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0857 - val_loss: 0.0432 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0844 - val_loss: 0.0425 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0769 - val_loss: 0.0420 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.0741 - val_loss: 0.0414 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0786 - val_loss: 0.0410 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0764 - val_loss: 0.0408 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.0677 - val_loss: 0.0407 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0843 - val_loss: 0.0405 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0739 - val_loss: 0.0404 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.0639 - val_loss: 0.0401 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0712 - val_loss: 0.0400 - lr: 5.0000e-04\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0761 - val_loss: 0.0398 - lr: 5.0000e-04\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0730 - val_loss: 0.0396 - lr: 5.0000e-04\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0652 - val_loss: 0.0394 - lr: 5.0000e-04\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.0712 - val_loss: 0.0393 - lr: 5.0000e-04\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0707 - val_loss: 0.0391 - lr: 5.0000e-04\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0700 - val_loss: 0.0389 - lr: 5.0000e-04\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0753 - val_loss: 0.0387 - lr: 5.0000e-04\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0735 - val_loss: 0.0386 - lr: 5.0000e-04\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.0795 - val_loss: 0.0385 - lr: 5.0000e-04\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0689 - val_loss: 0.0384 - lr: 5.0000e-04\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0712 - val_loss: 0.0384 - lr: 5.0000e-04\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0630 - val_loss: 0.0384 - lr: 5.0000e-04\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0657 - val_loss: 0.0383 - lr: 5.0000e-04\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0692 - val_loss: 0.0382 - lr: 5.0000e-04\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.0622 - val_loss: 0.0381 - lr: 5.0000e-04\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0593 - val_loss: 0.0380 - lr: 5.0000e-04\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0630 - val_loss: 0.0379 - lr: 5.0000e-04\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.0690 - val_loss: 0.0378 - lr: 5.0000e-04\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.0651 - val_loss: 0.0378 - lr: 5.0000e-04\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.0712 - val_loss: 0.0378 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0713 - val_loss: 0.0378 - lr: 1.0000e-04\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.0719 - val_loss: 0.0377 - lr: 1.0000e-04\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0719 - val_loss: 0.0377 - lr: 1.0000e-04\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.0684 - val_loss: 0.0377 - lr: 1.0000e-04\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.0689 - val_loss: 0.0377 - lr: 1.0000e-04\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0650 - val_loss: 0.0376 - lr: 1.0000e-04\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.0718 - val_loss: 0.0376 - lr: 1.0000e-04\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0646 - val_loss: 0.0376 - lr: 1.0000e-04\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0634 - val_loss: 0.0375 - lr: 1.0000e-04\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.0661 - val_loss: 0.0375 - lr: 1.0000e-04\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0665 - val_loss: 0.0375 - lr: 1.0000e-04\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.0593 - val_loss: 0.0374 - lr: 1.0000e-04\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0738 - val_loss: 0.0374 - lr: 1.0000e-04\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0679 - val_loss: 0.0374 - lr: 1.0000e-04\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.0783 - val_loss: 0.0374 - lr: 1.0000e-04\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.0670 - val_loss: 0.0374 - lr: 1.0000e-04\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.0722 - val_loss: 0.0374 - lr: 1.0000e-04\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.0631 - val_loss: 0.0374 - lr: 1.0000e-04\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.0649 - val_loss: 0.0374 - lr: 1.0000e-04\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0686 - val_loss: 0.0374 - lr: 1.0000e-04\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0715 - val_loss: 0.0374 - lr: 1.0000e-04\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0683 - val_loss: 0.0374 - lr: 1.0000e-04\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0749 - val_loss: 0.0374 - lr: 1.0000e-04\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0634 - val_loss: 0.0374 - lr: 1.0000e-04\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0661 - val_loss: 0.0374 - lr: 1.0000e-04\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0629 - val_loss: 0.0374 - lr: 1.0000e-04\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0687 - val_loss: 0.0374 - lr: 1.0000e-04\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0659 - val_loss: 0.0374 - lr: 1.0000e-04\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0647 - val_loss: 0.0374 - lr: 1.0000e-04\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.0645 - val_loss: 0.0374 - lr: 1.0000e-04\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.0648 - val_loss: 0.0374 - lr: 1.0000e-04\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.0737 - val_loss: 0.0374 - lr: 1.0000e-04\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0575 - val_loss: 0.0374 - lr: 1.0000e-04\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0637 - val_loss: 0.0374 - lr: 1.0000e-04\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0595 - val_loss: 0.0374 - lr: 1.0000e-04\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.0680 - val_loss: 0.0374 - lr: 1.0000e-04\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.0618 - val_loss: 0.0373 - lr: 1.0000e-04\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.0607 - val_loss: 0.0373 - lr: 1.0000e-04\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0680 - val_loss: 0.0373 - lr: 1.0000e-04\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0697 - val_loss: 0.0374 - lr: 1.0000e-04\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.0631 - val_loss: 0.0374 - lr: 1.0000e-04\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0601 - val_loss: 0.0374 - lr: 1.0000e-04\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.0666 - val_loss: 0.0373 - lr: 1.0000e-04\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0649 - val_loss: 0.0373 - lr: 1.0000e-04\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0642 - val_loss: 0.0373 - lr: 1.0000e-04\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0582 - val_loss: 0.0373 - lr: 1.0000e-04\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0630 - val_loss: 0.0373 - lr: 1.0000e-04\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0674 - val_loss: 0.0373 - lr: 1.0000e-04\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "Accuracy results for iteration 2:\n",
            "                   Variable         MSE        MAE          MAPE  \\\n",
            "0  Minimum temperature (°C)    3.585644   1.563552  2.260879e-01   \n",
            "1  Maximum temperature (°C)    6.659384   2.303432  1.728030e-01   \n",
            "2             Rainfall (mm)    8.355606   1.888073  9.379321e+14   \n",
            "3          Evaporation (mm)    0.760018   0.698764  7.444853e-01   \n",
            "4          Sunshine (hours)    5.047235   1.810900  5.868522e+14   \n",
            "5                  Humidity  221.620547  12.075748  1.524186e-01   \n",
            "6                 WindSpeed   39.221920   4.914795  3.687127e-01   \n",
            "\n",
            "                        Model  \n",
            "0  Feedforward Neural Network  \n",
            "1  Feedforward Neural Network  \n",
            "2  Feedforward Neural Network  \n",
            "3  Feedforward Neural Network  \n",
            "4  Feedforward Neural Network  \n",
            "5  Feedforward Neural Network  \n",
            "6  Feedforward Neural Network  \n",
            "\n",
            "Epoch 1/100\n",
            "3/3 [==============================] - 1s 66ms/step - loss: 0.2069 - val_loss: 0.1350 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1817 - val_loss: 0.1197 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1696 - val_loss: 0.1065 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1521 - val_loss: 0.0946 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1363 - val_loss: 0.0838 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1267 - val_loss: 0.0737 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1129 - val_loss: 0.0640 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1050 - val_loss: 0.0554 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0931 - val_loss: 0.0479 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0874 - val_loss: 0.0415 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0783 - val_loss: 0.0365 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0733 - val_loss: 0.0329 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0654 - val_loss: 0.0305 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0608 - val_loss: 0.0292 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0558 - val_loss: 0.0286 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0558 - val_loss: 0.0286 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0608 - val_loss: 0.0286 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0595 - val_loss: 0.0285 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0563 - val_loss: 0.0280 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0581 - val_loss: 0.0279 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0583 - val_loss: 0.0277 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0567 - val_loss: 0.0277 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0565 - val_loss: 0.0279 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0519 - val_loss: 0.0280 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0521 - val_loss: 0.0279 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0547 - val_loss: 0.0277 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0543 - val_loss: 0.0273 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0550 - val_loss: 0.0269 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0506 - val_loss: 0.0265 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0487 - val_loss: 0.0262 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0463 - val_loss: 0.0261 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0535 - val_loss: 0.0260 - lr: 5.0000e-04\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0510 - val_loss: 0.0259 - lr: 5.0000e-04\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0475 - val_loss: 0.0257 - lr: 5.0000e-04\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0518 - val_loss: 0.0256 - lr: 5.0000e-04\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0520 - val_loss: 0.0255 - lr: 5.0000e-04\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0487 - val_loss: 0.0255 - lr: 5.0000e-04\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0568 - val_loss: 0.0254 - lr: 5.0000e-04\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0485 - val_loss: 0.0254 - lr: 5.0000e-04\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0468 - val_loss: 0.0253 - lr: 5.0000e-04\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0519 - val_loss: 0.0252 - lr: 5.0000e-04\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0520 - val_loss: 0.0251 - lr: 5.0000e-04\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0501 - val_loss: 0.0250 - lr: 5.0000e-04\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0473 - val_loss: 0.0248 - lr: 5.0000e-04\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0473 - val_loss: 0.0247 - lr: 5.0000e-04\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0458 - val_loss: 0.0246 - lr: 5.0000e-04\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0440 - val_loss: 0.0246 - lr: 5.0000e-04\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0462 - val_loss: 0.0246 - lr: 5.0000e-04\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0505 - val_loss: 0.0246 - lr: 5.0000e-04\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0472 - val_loss: 0.0246 - lr: 5.0000e-04\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0450 - val_loss: 0.0247 - lr: 5.0000e-04\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0431 - val_loss: 0.0247 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0452 - val_loss: 0.0248 - lr: 1.0000e-04\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0459 - val_loss: 0.0248 - lr: 1.0000e-04\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0533 - val_loss: 0.0248 - lr: 1.0000e-04\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0492 - val_loss: 0.0248 - lr: 1.0000e-04\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0471 - val_loss: 0.0248 - lr: 1.0000e-04\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0478 - val_loss: 0.0248 - lr: 1.0000e-04\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "Accuracy results for iteration 3:\n",
            "                   Variable         MSE       MAE          MAPE  \\\n",
            "0  Minimum temperature (°C)    4.743469  1.644283  6.176907e-01   \n",
            "1  Maximum temperature (°C)    5.795146  2.034555  1.511462e-01   \n",
            "2             Rainfall (mm)    4.840065  1.913022  4.776639e+15   \n",
            "3          Evaporation (mm)    0.558561  0.550919  4.961644e+14   \n",
            "4          Sunshine (hours)    8.433399  2.400804  5.955725e+14   \n",
            "5                  Humidity  116.142526  8.470727  1.067229e-01   \n",
            "6                 WindSpeed   19.951520  2.804735  2.944922e-01   \n",
            "\n",
            "                        Model  \n",
            "0  Feedforward Neural Network  \n",
            "1  Feedforward Neural Network  \n",
            "2  Feedforward Neural Network  \n",
            "3  Feedforward Neural Network  \n",
            "4  Feedforward Neural Network  \n",
            "5  Feedforward Neural Network  \n",
            "6  Feedforward Neural Network  \n",
            "\n",
            "Epoch 1/100\n",
            "3/3 [==============================] - 1s 70ms/step - loss: 0.2451 - val_loss: 0.1633 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1966 - val_loss: 0.1412 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1753 - val_loss: 0.1235 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1543 - val_loss: 0.1090 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1371 - val_loss: 0.0971 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.1224 - val_loss: 0.0868 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.1025 - val_loss: 0.0778 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0972 - val_loss: 0.0700 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0873 - val_loss: 0.0633 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0786 - val_loss: 0.0578 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0775 - val_loss: 0.0528 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0699 - val_loss: 0.0484 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0707 - val_loss: 0.0447 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0625 - val_loss: 0.0416 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0642 - val_loss: 0.0389 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0582 - val_loss: 0.0368 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0580 - val_loss: 0.0353 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0583 - val_loss: 0.0344 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0547 - val_loss: 0.0338 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0530 - val_loss: 0.0336 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0538 - val_loss: 0.0335 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0529 - val_loss: 0.0336 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0523 - val_loss: 0.0337 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0497 - val_loss: 0.0339 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0538 - val_loss: 0.0338 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0492 - val_loss: 0.0335 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0522 - val_loss: 0.0333 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0479 - val_loss: 0.0329 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0496 - val_loss: 0.0325 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0509 - val_loss: 0.0323 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0505 - val_loss: 0.0321 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0450 - val_loss: 0.0320 - lr: 5.0000e-04\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0493 - val_loss: 0.0320 - lr: 5.0000e-04\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0441 - val_loss: 0.0320 - lr: 5.0000e-04\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0469 - val_loss: 0.0320 - lr: 5.0000e-04\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0472 - val_loss: 0.0320 - lr: 5.0000e-04\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0460 - val_loss: 0.0320 - lr: 5.0000e-04\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0462 - val_loss: 0.0320 - lr: 5.0000e-04\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0504 - val_loss: 0.0319 - lr: 5.0000e-04\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0483 - val_loss: 0.0319 - lr: 5.0000e-04\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0469 - val_loss: 0.0319 - lr: 5.0000e-04\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0475 - val_loss: 0.0318 - lr: 5.0000e-04\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0471 - val_loss: 0.0317 - lr: 5.0000e-04\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0461 - val_loss: 0.0316 - lr: 5.0000e-04\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0440 - val_loss: 0.0316 - lr: 5.0000e-04\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0452 - val_loss: 0.0316 - lr: 5.0000e-04\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0431 - val_loss: 0.0316 - lr: 5.0000e-04\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0439 - val_loss: 0.0315 - lr: 5.0000e-04\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0460 - val_loss: 0.0315 - lr: 5.0000e-04\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0455 - val_loss: 0.0314 - lr: 5.0000e-04\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0435 - val_loss: 0.0313 - lr: 5.0000e-04\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0453 - val_loss: 0.0313 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0472 - val_loss: 0.0313 - lr: 1.0000e-04\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0440 - val_loss: 0.0313 - lr: 1.0000e-04\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0459 - val_loss: 0.0312 - lr: 1.0000e-04\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0427 - val_loss: 0.0312 - lr: 1.0000e-04\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0462 - val_loss: 0.0312 - lr: 1.0000e-04\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0434 - val_loss: 0.0312 - lr: 1.0000e-04\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0435 - val_loss: 0.0312 - lr: 1.0000e-04\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0429 - val_loss: 0.0312 - lr: 1.0000e-04\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0432 - val_loss: 0.0312 - lr: 1.0000e-04\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0430 - val_loss: 0.0312 - lr: 1.0000e-04\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0456 - val_loss: 0.0312 - lr: 1.0000e-04\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0433 - val_loss: 0.0312 - lr: 1.0000e-04\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0458 - val_loss: 0.0312 - lr: 1.0000e-04\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0487 - val_loss: 0.0311 - lr: 1.0000e-04\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0482 - val_loss: 0.0311 - lr: 1.0000e-04\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0407 - val_loss: 0.0311 - lr: 1.0000e-04\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0436 - val_loss: 0.0311 - lr: 1.0000e-04\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0431 - val_loss: 0.0310 - lr: 1.0000e-04\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0431 - val_loss: 0.0310 - lr: 1.0000e-04\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0449 - val_loss: 0.0310 - lr: 1.0000e-04\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0437 - val_loss: 0.0310 - lr: 1.0000e-04\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0433 - val_loss: 0.0309 - lr: 1.0000e-04\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0420 - val_loss: 0.0309 - lr: 1.0000e-04\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0434 - val_loss: 0.0309 - lr: 1.0000e-04\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0425 - val_loss: 0.0309 - lr: 1.0000e-04\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0436 - val_loss: 0.0309 - lr: 1.0000e-04\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0447 - val_loss: 0.0309 - lr: 1.0000e-04\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0432 - val_loss: 0.0309 - lr: 1.0000e-04\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0444 - val_loss: 0.0309 - lr: 1.0000e-04\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0441 - val_loss: 0.0308 - lr: 1.0000e-04\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0412 - val_loss: 0.0308 - lr: 1.0000e-04\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0426 - val_loss: 0.0308 - lr: 1.0000e-04\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0460 - val_loss: 0.0308 - lr: 1.0000e-04\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0443 - val_loss: 0.0308 - lr: 1.0000e-04\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0429 - val_loss: 0.0308 - lr: 1.0000e-04\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0411 - val_loss: 0.0308 - lr: 1.0000e-04\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0424 - val_loss: 0.0308 - lr: 1.0000e-04\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0435 - val_loss: 0.0308 - lr: 1.0000e-04\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0467 - val_loss: 0.0308 - lr: 1.0000e-04\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0439 - val_loss: 0.0308 - lr: 1.0000e-04\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0419 - val_loss: 0.0308 - lr: 1.0000e-04\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0442 - val_loss: 0.0308 - lr: 1.0000e-04\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0455 - val_loss: 0.0308 - lr: 1.0000e-04\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0419 - val_loss: 0.0308 - lr: 1.0000e-04\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0417 - val_loss: 0.0308 - lr: 1.0000e-04\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0437 - val_loss: 0.0308 - lr: 1.0000e-04\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0431 - val_loss: 0.0308 - lr: 1.0000e-04\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0416 - val_loss: 0.0308 - lr: 1.0000e-04\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "Accuracy results for iteration 4:\n",
            "                   Variable         MSE       MAE          MAPE  \\\n",
            "0  Minimum temperature (°C)    5.039070  1.889190  3.083750e-01   \n",
            "1  Maximum temperature (°C)    5.329495  1.713647  1.146162e-01   \n",
            "2             Rainfall (mm)    8.498597  1.982259  2.813500e+15   \n",
            "3          Evaporation (mm)    2.042758  1.159242  6.192547e-01   \n",
            "4          Sunshine (hours)   12.822702  3.274569  4.299565e+14   \n",
            "5                  Humidity  126.350198  8.870248  1.407102e-01   \n",
            "6                 WindSpeed   39.045590  4.898949  3.514773e-01   \n",
            "\n",
            "                        Model  \n",
            "0  Feedforward Neural Network  \n",
            "1  Feedforward Neural Network  \n",
            "2  Feedforward Neural Network  \n",
            "3  Feedforward Neural Network  \n",
            "4  Feedforward Neural Network  \n",
            "5  Feedforward Neural Network  \n",
            "6  Feedforward Neural Network  \n",
            "\n",
            "Average accuracy across all iterations:\n",
            "                   Variable         MSE        MAE          MAPE  \\\n",
            "0  Minimum temperature (°C)    5.460042   1.909926  3.657397e-01   \n",
            "1  Maximum temperature (°C)    6.264954   2.087540  1.462133e-01   \n",
            "2             Rainfall (mm)    5.841508   1.716024  2.770512e+15   \n",
            "3          Evaporation (mm)    1.362737   0.907754  2.284182e+14   \n",
            "4          Sunshine (hours)    9.907795   2.696726  5.743140e+14   \n",
            "5                  Humidity  215.109097  11.490728  1.530031e-01   \n",
            "6                 WindSpeed   29.629314   4.045578  3.524326e-01   \n",
            "\n",
            "                        Model  \n",
            "0  Feedforward Neural Network  \n",
            "1  Feedforward Neural Network  \n",
            "2  Feedforward Neural Network  \n",
            "3  Feedforward Neural Network  \n",
            "4  Feedforward Neural Network  \n",
            "5  Feedforward Neural Network  \n",
            "6  Feedforward Neural Network  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the window size\n",
        "window_size = 60\n",
        "# Define the number of predictions to make\n",
        "prediction_steps = 30\n",
        "\n",
        "# Define the variable names\n",
        "variable_names = ['Minimum temperature (°C)', 'Maximum temperature (°C)', 'Rainfall (mm)', 'Evaporation (mm)',\n",
        "                  'Sunshine (hours)', 'Humidity', 'WindSpeed']\n",
        "\n",
        "# Define the GRU model\n",
        "def create_model(units=64, dropout_rate=0.2):\n",
        "    model = Sequential()\n",
        "    model.add(GRU(units, activation='relu', input_shape=(1, train_data.shape[1]), return_sequences=True))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(GRU(units, activation='relu', return_sequences=False))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(train_data.shape[1], activation='linear'))\n",
        "    optimizer = Adam(learning_rate=0.001)\n",
        "    model.compile(optimizer=optimizer, loss='mse')\n",
        "    return model\n",
        "\n",
        "# Create the KerasRegressor wrapper\n",
        "model = KerasRegressor(build_fn=create_model, verbose=0)\n",
        "\n",
        "# Define the hyperparameters grid\n",
        "param_grid = {\n",
        "    'units': [32, 64, 128],\n",
        "    'dropout_rate': [0.2, 0.3, 0.4]\n",
        "}\n",
        "\n",
        "# Create the GridSearchCV instance\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=3)\n",
        "\n",
        "# Perform forward chaining and hyperparameter tuning\n",
        "for i in range(4):\n",
        "    # Split the data into train and test sets\n",
        "    train_data = data[:window_size + i * prediction_steps]\n",
        "    test_data = data[window_size + i * prediction_steps:window_size + (i+1) * prediction_steps]\n",
        "\n",
        "    # Scale the data\n",
        "    scaler = MinMaxScaler()\n",
        "    train_scaled = scaler.fit_transform(train_data)\n",
        "    test_scaled = scaler.transform(test_data)\n",
        "\n",
        "    # Reshape the data\n",
        "    X_train = np.reshape(train_scaled[:-1], (train_scaled[:-1].shape[0], 1, train_scaled[:-1].shape[1]))\n",
        "    y_train = train_scaled[1:, :]  # Predict the next step\n",
        "\n",
        "    # Perform the hyperparameter tuning\n",
        "    grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best model\n",
        "    best_model = grid_result.best_estimator_.model\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    X_test = np.reshape(test_scaled[:-1], (test_scaled[:-1].shape[0], 1, test_scaled[:-1].shape[1]))\n",
        "    predictions = best_model.predict(X_test)\n",
        "\n",
        "    # Rescale the predictions to the original scale\n",
        "    predictions = scaler.inverse_transform(predictions)\n",
        "\n",
        "    # Calculate the mean squared error for each variable\n",
        "    mse = mean_squared_error(test_data[1:], predictions, multioutput='raw_values')\n",
        "\n",
        "    # Calculate the Mean Absolute Error (MAE) for each variable\n",
        "    mae = mean_absolute_error(test_data[1:], predictions, multioutput='raw_values')\n",
        "\n",
        "    # Calculate the Mean Absolute Percentage Error (MAPE) for each variable\n",
        "    mape = mean_absolute_percentage_error(test_data[1:], predictions, multioutput='raw_values')\n",
        "\n",
        "    # Store the accuracy metrics for this iteration\n",
        "    mse_lists.append(mse)\n",
        "    mae_lists.append(mae)\n",
        "    mape_lists.append(mape)\n",
        "\n",
        "    # Create a DataFrame to store the accuracy results\n",
        "    accuracy_df = pd.DataFrame({'Variable': variable_names, 'MSE': mse, 'MAE': mae, 'MAPE': mape})\n",
        "\n",
        "    # Add the model name to the DataFrame\n",
        "    accuracy_df['Model'] = 'GRU'\n",
        "\n",
        "    # Print the accuracy results for this iteration\n",
        "    print(f\"Accuracy results for iteration {i+1}:\")\n",
        "    print(accuracy_df)\n",
        "    print()\n",
        "\n",
        "# Calculate the average accuracy across all iterations\n",
        "average_mse = np.mean(mse_lists, axis=0)\n",
        "average_mae = np.mean(mae_lists, axis=0)\n",
        "average_mape = np.mean(mape_lists, axis=0)\n",
        "\n",
        "# Create a DataFrame for the average accuracy results\n",
        "average_accuracy_df = pd.DataFrame({'Variable': variable_names, 'MSE': average_mse, 'MAE': average_mae, 'MAPE': average_mape})\n",
        "\n",
        "# Add the model name to the DataFrame\n",
        "average_accuracy_df['Model'] = 'GRU'\n",
        "accuracy_gru = average_accuracy_df\n",
        "# Print the average accuracy across all iterations\n",
        "print(\"Average accuracy across all iterations:\")\n",
        "print(average_accuracy_df)\n",
        "\n",
        "# Print the best hyperparameters found during the tuning process\n",
        "print(\"Best hyperparameters found:\")\n",
        "print(grid_result.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vi7zd89n_0E",
        "outputId": "71ee0cc6-bd84-44a8-9f33-e8feeb134870"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-7e4fd3d61646>:33: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasRegressor(build_fn=create_model, verbose=0)\n",
            "WARNING:tensorflow:5 out of the last 307 calls to <function Model.make_train_function.<locals>.train_function at 0x7f1dada5d870> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 309 calls to <function Model.make_train_function.<locals>.train_function at 0x7f1dad0f7250> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 262ms/step\n",
            "Accuracy results for iteration 1:\n",
            "                   Variable          MSE        MAE          MAPE Model\n",
            "0  Minimum temperature (°C)    17.236590   3.660052  4.019534e-01   GRU\n",
            "1  Maximum temperature (°C)     7.146286   2.164405  1.439585e-01   GRU\n",
            "2             Rainfall (mm)     8.775372   1.719241  4.057644e+14   GRU\n",
            "3          Evaporation (mm)     3.404282   1.634061  8.980634e-01   GRU\n",
            "4          Sunshine (hours)    14.756029   3.191099  1.557781e+13   GRU\n",
            "5                  Humidity  1124.733766  32.402654  4.295563e-01   GRU\n",
            "6                 WindSpeed    88.456884   8.491558  6.928154e-01   GRU\n",
            "\n",
            "1/1 [==============================] - 0s 265ms/step\n",
            "Accuracy results for iteration 2:\n",
            "                   Variable          MSE        MAE          MAPE Model\n",
            "0  Minimum temperature (°C)     8.289828   2.544978  6.009413e-01   GRU\n",
            "1  Maximum temperature (°C)     9.479185   2.359983  1.528668e-01   GRU\n",
            "2             Rainfall (mm)     4.815488   1.237440  3.677474e+14   GRU\n",
            "3          Evaporation (mm)     3.038081   1.497638  8.186612e+12   GRU\n",
            "4          Sunshine (hours)    27.742386   4.462775  2.109844e+13   GRU\n",
            "5                  Humidity  1280.426270  34.590483  4.413642e-01   GRU\n",
            "6                 WindSpeed    58.435604   6.339721  6.181475e-01   GRU\n",
            "\n",
            "1/1 [==============================] - 0s 252ms/step\n",
            "Accuracy results for iteration 3:\n",
            "                   Variable         MSE        MAE          MAPE Model\n",
            "0  Minimum temperature (°C)   53.130715   6.906057  8.353174e-01   GRU\n",
            "1  Maximum temperature (°C)   20.616517   4.013672  2.468948e-01   GRU\n",
            "2             Rainfall (mm)    9.701665   1.574289  5.517293e+14   GRU\n",
            "3          Evaporation (mm)    7.539564   2.335500  8.900617e-01   GRU\n",
            "4          Sunshine (hours)   31.481841   4.590802  4.690054e+13   GRU\n",
            "5                  Humidity  694.314231  23.994126  3.372759e-01   GRU\n",
            "6                 WindSpeed  128.349962  10.066442  7.148142e-01   GRU\n",
            "\n",
            "1/1 [==============================] - 0s 281ms/step\n",
            "Accuracy results for iteration 4:\n",
            "                   Variable         MSE        MAE          MAPE Model\n",
            "0  Minimum temperature (°C)   50.877133   6.737737  7.468284e-01   GRU\n",
            "1  Maximum temperature (°C)   31.205473   5.102918  2.967339e-01   GRU\n",
            "2             Rainfall (mm)   10.894172   1.911950  7.590292e+14   GRU\n",
            "3          Evaporation (mm)    7.991685   2.447575  9.705664e-01   GRU\n",
            "4          Sunshine (hours)   31.866776   4.445105  1.280863e+14   GRU\n",
            "5                  Humidity  710.451413  24.253714  3.421667e-01   GRU\n",
            "6                 WindSpeed   72.131302   7.748717  6.186982e-01   GRU\n",
            "\n",
            "Average accuracy across all iterations:\n",
            "                   Variable         MSE        MAE          MAPE Model\n",
            "0  Minimum temperature (°C)   18.921804   3.436066  5.059999e-01   GRU\n",
            "1  Maximum temperature (°C)   11.688409   2.748892  1.781634e-01   GRU\n",
            "2             Rainfall (mm)    7.194091   1.663377  1.645790e+15   GRU\n",
            "3          Evaporation (mm)    3.428070   1.443224  1.152324e+14   GRU\n",
            "4          Sunshine (hours)   18.184777   3.434586  3.136149e+14   GRU\n",
            "5                  Humidity  583.795259  20.150486  2.702969e-01   GRU\n",
            "6                 WindSpeed   58.236376   6.103594  5.067757e-01   GRU\n",
            "Best hyperparameters found:\n",
            "{'dropout_rate': 0.2, 'units': 128}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "\n",
        "# Define the window size\n",
        "window_size = 30\n",
        "# Define the number of predictions to make\n",
        "prediction_steps = 30\n",
        "\n",
        "# Define the variable names\n",
        "variable_names = ['Minimum temperature (°C)', 'Maximum temperature (°C)', 'Rainfall (mm)', 'Evaporation (mm)',\n",
        "                  'Sunshine (hours)', 'Humidity', 'WindSpeed']\n",
        "\n",
        "# Define lists to store accuracy metrics for each iteration\n",
        "mse_lists = []\n",
        "mae_lists = []\n",
        "mape_lists = []\n",
        "\n",
        "# Perform forward chaining\n",
        "for i in range(4):\n",
        "    # Split the data into train and test sets\n",
        "    train_data = data[:window_size + i * prediction_steps]\n",
        "    test_data = data[window_size + i * prediction_steps:window_size + (i+1) * prediction_steps]\n",
        "\n",
        "    # Scale the data\n",
        "    scaler = MinMaxScaler()\n",
        "    train_scaled = scaler.fit_transform(train_data)\n",
        "    test_scaled = scaler.transform(test_data)\n",
        "\n",
        "    # Reshape the data for CNN input\n",
        "    X_train = train_scaled[:-1]\n",
        "    y_train = train_scaled[1:, :]  # Predict the next step\n",
        "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "\n",
        "    # Define the CNN model\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(train_data.shape[1], 1)))\n",
        "    model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(train_data.shape[1], activation='linear'))\n",
        "\n",
        "    # Define learning rate schedule\n",
        "    def lr_schedule(epoch):\n",
        "        lr = 0.001\n",
        "        if epoch > 50:\n",
        "            lr *= 0.1\n",
        "        elif epoch > 30:\n",
        "            lr *= 0.5\n",
        "        return lr\n",
        "\n",
        "    optimizer = Adam(learning_rate=lr_schedule(0))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=optimizer, loss='mse')\n",
        "\n",
        "    # Define early stopping\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    # Define learning rate scheduler\n",
        "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1,\n",
        "              validation_split=0.2, callbacks=[early_stopping, lr_scheduler])\n",
        "\n",
        "    # Prepare the test data for prediction\n",
        "    X_test = test_scaled[:-1]\n",
        "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    # Rescale the predictions to the original scale\n",
        "    predictions = scaler.inverse_transform(predictions)\n",
        "\n",
        "    # Calculate the mean squared error for each variable\n",
        "    mse = mean_squared_error(test_data[1:], predictions, multioutput='raw_values')\n",
        "\n",
        "    # Calculate the Mean Absolute Error (MAE) for each variable\n",
        "    mae = mean_absolute_error(test_data[1:], predictions, multioutput='raw_values')\n",
        "\n",
        "    # Calculate the Mean Absolute Percentage Error (MAPE) for each variable\n",
        "    mape = mean_absolute_percentage_error(test_data[1:], predictions, multioutput='raw_values')\n",
        "\n",
        "    # Store the accuracy metrics for this iteration\n",
        "    mse_lists.append(mse)\n",
        "    mae_lists.append(mae)\n",
        "    mape_lists.append(mape)\n",
        "\n",
        "    # Create a DataFrame to store the accuracy results\n",
        "    accuracy_df = pd.DataFrame({'Variable': variable_names, 'MSE': mse, 'MAE': mae, 'MAPE': mape})\n",
        "\n",
        "    # Add the model name to the DataFrame\n",
        "    accuracy_df['Model'] = 'Convolutional Neural Network'\n",
        "\n",
        "    # Print the accuracy results for this iteration\n",
        "    print(f\"Accuracy results for iteration {i+1}:\")\n",
        "    print(accuracy_df)\n",
        "    print()\n",
        "\n",
        "# Calculate the average accuracy across all iterations\n",
        "average_mse = np.mean(mse_lists, axis=0)\n",
        "average_mae = np.mean(mae_lists, axis=0)\n",
        "average_mape = np.mean(mape_lists, axis=0)\n",
        "\n",
        "# Create a DataFrame for the average accuracy results\n",
        "average_accuracy_df = pd.DataFrame({'Variable': variable_names, 'MSE': average_mse, 'MAE': average_mae, 'MAPE': average_mape})\n",
        "\n",
        "# Add the model name to the DataFrame\n",
        "average_accuracy_df['Model'] = 'Convolutional Neural Network'\n",
        "accuracy_cnn = average_accuracy_df\n",
        "\n",
        "# Print the average accuracy across all iterations\n",
        "print(\"Average accuracy across all iterations:\")\n",
        "print(average_accuracy_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZS_CDOA2x91Z",
        "outputId": "85f36042-c6a5-496d-b77e-37722e305119"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 854ms/step - loss: 0.2509 - val_loss: 0.2286 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2330 - val_loss: 0.2163 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2171 - val_loss: 0.2055 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2029 - val_loss: 0.1955 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1900 - val_loss: 0.1864 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1784 - val_loss: 0.1777 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1678 - val_loss: 0.1692 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1579 - val_loss: 0.1608 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1483 - val_loss: 0.1526 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1390 - val_loss: 0.1445 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1299 - val_loss: 0.1365 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1211 - val_loss: 0.1288 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1127 - val_loss: 0.1214 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1048 - val_loss: 0.1143 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0974 - val_loss: 0.1079 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0907 - val_loss: 0.1020 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0847 - val_loss: 0.0968 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0795 - val_loss: 0.0923 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0752 - val_loss: 0.0886 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0720 - val_loss: 0.0857 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0697 - val_loss: 0.0837 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0684 - val_loss: 0.0826 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0679 - val_loss: 0.0820 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0680 - val_loss: 0.0820 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0684 - val_loss: 0.0821 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0688 - val_loss: 0.0824 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0691 - val_loss: 0.0825 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0691 - val_loss: 0.0825 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0687 - val_loss: 0.0823 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0679 - val_loss: 0.0821 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0668 - val_loss: 0.0817 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0655 - val_loss: 0.0815 - lr: 5.0000e-04\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0648 - val_loss: 0.0812 - lr: 5.0000e-04\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0641 - val_loss: 0.0810 - lr: 5.0000e-04\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0634 - val_loss: 0.0807 - lr: 5.0000e-04\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0626 - val_loss: 0.0804 - lr: 5.0000e-04\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0619 - val_loss: 0.0802 - lr: 5.0000e-04\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0613 - val_loss: 0.0800 - lr: 5.0000e-04\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0607 - val_loss: 0.0797 - lr: 5.0000e-04\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0601 - val_loss: 0.0795 - lr: 5.0000e-04\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0596 - val_loss: 0.0793 - lr: 5.0000e-04\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0591 - val_loss: 0.0791 - lr: 5.0000e-04\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0587 - val_loss: 0.0789 - lr: 5.0000e-04\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0584 - val_loss: 0.0788 - lr: 5.0000e-04\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0580 - val_loss: 0.0786 - lr: 5.0000e-04\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0577 - val_loss: 0.0785 - lr: 5.0000e-04\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0575 - val_loss: 0.0783 - lr: 5.0000e-04\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0572 - val_loss: 0.0782 - lr: 5.0000e-04\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0570 - val_loss: 0.0780 - lr: 5.0000e-04\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0568 - val_loss: 0.0778 - lr: 5.0000e-04\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0566 - val_loss: 0.0776 - lr: 5.0000e-04\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0563 - val_loss: 0.0776 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0563 - val_loss: 0.0776 - lr: 1.0000e-04\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0562 - val_loss: 0.0775 - lr: 1.0000e-04\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0562 - val_loss: 0.0775 - lr: 1.0000e-04\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0561 - val_loss: 0.0774 - lr: 1.0000e-04\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0561 - val_loss: 0.0774 - lr: 1.0000e-04\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0560 - val_loss: 0.0774 - lr: 1.0000e-04\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0559 - val_loss: 0.0773 - lr: 1.0000e-04\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0559 - val_loss: 0.0773 - lr: 1.0000e-04\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0558 - val_loss: 0.0772 - lr: 1.0000e-04\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0558 - val_loss: 0.0772 - lr: 1.0000e-04\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0557 - val_loss: 0.0771 - lr: 1.0000e-04\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0556 - val_loss: 0.0771 - lr: 1.0000e-04\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0556 - val_loss: 0.0770 - lr: 1.0000e-04\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0555 - val_loss: 0.0770 - lr: 1.0000e-04\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0554 - val_loss: 0.0769 - lr: 1.0000e-04\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0554 - val_loss: 0.0769 - lr: 1.0000e-04\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0553 - val_loss: 0.0769 - lr: 1.0000e-04\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0553 - val_loss: 0.0768 - lr: 1.0000e-04\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0552 - val_loss: 0.0768 - lr: 1.0000e-04\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0551 - val_loss: 0.0767 - lr: 1.0000e-04\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0551 - val_loss: 0.0767 - lr: 1.0000e-04\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0550 - val_loss: 0.0766 - lr: 1.0000e-04\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0550 - val_loss: 0.0766 - lr: 1.0000e-04\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0549 - val_loss: 0.0765 - lr: 1.0000e-04\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0548 - val_loss: 0.0765 - lr: 1.0000e-04\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0548 - val_loss: 0.0765 - lr: 1.0000e-04\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0547 - val_loss: 0.0764 - lr: 1.0000e-04\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0547 - val_loss: 0.0764 - lr: 1.0000e-04\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0546 - val_loss: 0.0764 - lr: 1.0000e-04\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0545 - val_loss: 0.0763 - lr: 1.0000e-04\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0545 - val_loss: 0.0763 - lr: 1.0000e-04\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0544 - val_loss: 0.0762 - lr: 1.0000e-04\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0544 - val_loss: 0.0762 - lr: 1.0000e-04\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0543 - val_loss: 0.0762 - lr: 1.0000e-04\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0543 - val_loss: 0.0761 - lr: 1.0000e-04\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0542 - val_loss: 0.0761 - lr: 1.0000e-04\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0542 - val_loss: 0.0761 - lr: 1.0000e-04\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0541 - val_loss: 0.0760 - lr: 1.0000e-04\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0540 - val_loss: 0.0760 - lr: 1.0000e-04\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0540 - val_loss: 0.0760 - lr: 1.0000e-04\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0539 - val_loss: 0.0759 - lr: 1.0000e-04\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0539 - val_loss: 0.0759 - lr: 1.0000e-04\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0538 - val_loss: 0.0759 - lr: 1.0000e-04\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0538 - val_loss: 0.0759 - lr: 1.0000e-04\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0537 - val_loss: 0.0758 - lr: 1.0000e-04\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0537 - val_loss: 0.0758 - lr: 1.0000e-04\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0536 - val_loss: 0.0758 - lr: 1.0000e-04\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0535 - val_loss: 0.0757 - lr: 1.0000e-04\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "Accuracy results for iteration 1:\n",
            "                   Variable         MSE        MAE          MAPE  \\\n",
            "0  Minimum temperature (°C)   12.304018   2.888967  4.119485e-01   \n",
            "1  Maximum temperature (°C)   15.255096   3.343372  2.156542e-01   \n",
            "2             Rainfall (mm)    1.133799   0.843602  2.163438e+15   \n",
            "3          Evaporation (mm)    1.752599   1.059163  4.820637e+14   \n",
            "4          Sunshine (hours)   12.648354   3.185609  6.226981e+14   \n",
            "5                  Humidity  212.458268  11.837086  1.524378e-01   \n",
            "6                 WindSpeed   14.788616   3.109152  4.096991e-01   \n",
            "\n",
            "                          Model  \n",
            "0  Convolutional Neural Network  \n",
            "1  Convolutional Neural Network  \n",
            "2  Convolutional Neural Network  \n",
            "3  Convolutional Neural Network  \n",
            "4  Convolutional Neural Network  \n",
            "5  Convolutional Neural Network  \n",
            "6  Convolutional Neural Network  \n",
            "\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 208ms/step - loss: 0.2594 - val_loss: 0.1449 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2372 - val_loss: 0.1330 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2172 - val_loss: 0.1222 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.1977 - val_loss: 0.1119 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1798 - val_loss: 0.1024 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.1619 - val_loss: 0.0937 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.1452 - val_loss: 0.0856 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.1289 - val_loss: 0.0781 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.1122 - val_loss: 0.0713 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0975 - val_loss: 0.0661 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0846 - val_loss: 0.0627 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0746 - val_loss: 0.0612 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0671 - val_loss: 0.0613 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0614 - val_loss: 0.0618 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0593 - val_loss: 0.0626 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0587 - val_loss: 0.0626 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0584 - val_loss: 0.0609 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0577 - val_loss: 0.0582 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0570 - val_loss: 0.0546 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0556 - val_loss: 0.0514 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0550 - val_loss: 0.0487 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0535 - val_loss: 0.0471 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0527 - val_loss: 0.0460 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0519 - val_loss: 0.0456 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0516 - val_loss: 0.0456 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0509 - val_loss: 0.0460 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0504 - val_loss: 0.0468 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0498 - val_loss: 0.0476 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0492 - val_loss: 0.0481 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0490 - val_loss: 0.0484 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0484 - val_loss: 0.0479 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0480 - val_loss: 0.0475 - lr: 5.0000e-04\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.0478 - val_loss: 0.0472 - lr: 5.0000e-04\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0476 - val_loss: 0.0469 - lr: 5.0000e-04\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0474 - val_loss: 0.0467 - lr: 5.0000e-04\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Accuracy results for iteration 2:\n",
            "                   Variable         MSE        MAE          MAPE  \\\n",
            "0  Minimum temperature (°C)    5.336787   1.800244  2.728078e-01   \n",
            "1  Maximum temperature (°C)   10.083431   2.894268  2.170403e-01   \n",
            "2             Rainfall (mm)    6.383092   1.960091  1.383233e+15   \n",
            "3          Evaporation (mm)    1.224438   0.890063  1.292424e+00   \n",
            "4          Sunshine (hours)    4.815951   1.847219  4.575452e+14   \n",
            "5                  Humidity  181.248982  10.794285  1.359476e-01   \n",
            "6                 WindSpeed   28.740596   4.062583  3.081987e-01   \n",
            "\n",
            "                          Model  \n",
            "0  Convolutional Neural Network  \n",
            "1  Convolutional Neural Network  \n",
            "2  Convolutional Neural Network  \n",
            "3  Convolutional Neural Network  \n",
            "4  Convolutional Neural Network  \n",
            "5  Convolutional Neural Network  \n",
            "6  Convolutional Neural Network  \n",
            "\n",
            "Epoch 1/100\n",
            "3/3 [==============================] - 1s 79ms/step - loss: 0.1768 - val_loss: 0.1113 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1454 - val_loss: 0.0932 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1174 - val_loss: 0.0768 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0952 - val_loss: 0.0626 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0749 - val_loss: 0.0516 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0610 - val_loss: 0.0452 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0539 - val_loss: 0.0434 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0532 - val_loss: 0.0430 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0537 - val_loss: 0.0410 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0523 - val_loss: 0.0377 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0490 - val_loss: 0.0350 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0472 - val_loss: 0.0333 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0457 - val_loss: 0.0325 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0455 - val_loss: 0.0316 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0452 - val_loss: 0.0305 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0445 - val_loss: 0.0296 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0435 - val_loss: 0.0289 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0428 - val_loss: 0.0287 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0421 - val_loss: 0.0291 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0415 - val_loss: 0.0295 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0410 - val_loss: 0.0296 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0405 - val_loss: 0.0293 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0400 - val_loss: 0.0288 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0396 - val_loss: 0.0284 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0392 - val_loss: 0.0277 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0388 - val_loss: 0.0274 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0384 - val_loss: 0.0271 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0381 - val_loss: 0.0269 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0378 - val_loss: 0.0268 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0375 - val_loss: 0.0271 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0373 - val_loss: 0.0271 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0371 - val_loss: 0.0268 - lr: 5.0000e-04\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0368 - val_loss: 0.0263 - lr: 5.0000e-04\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0366 - val_loss: 0.0258 - lr: 5.0000e-04\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0364 - val_loss: 0.0254 - lr: 5.0000e-04\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0363 - val_loss: 0.0251 - lr: 5.0000e-04\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0361 - val_loss: 0.0249 - lr: 5.0000e-04\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0362 - val_loss: 0.0248 - lr: 5.0000e-04\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0360 - val_loss: 0.0248 - lr: 5.0000e-04\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0359 - val_loss: 0.0249 - lr: 5.0000e-04\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0358 - val_loss: 0.0249 - lr: 5.0000e-04\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0355 - val_loss: 0.0249 - lr: 5.0000e-04\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0354 - val_loss: 0.0250 - lr: 5.0000e-04\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0353 - val_loss: 0.0249 - lr: 5.0000e-04\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0352 - val_loss: 0.0248 - lr: 5.0000e-04\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0351 - val_loss: 0.0245 - lr: 5.0000e-04\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0350 - val_loss: 0.0244 - lr: 5.0000e-04\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0349 - val_loss: 0.0243 - lr: 5.0000e-04\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0349 - val_loss: 0.0245 - lr: 5.0000e-04\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0348 - val_loss: 0.0245 - lr: 5.0000e-04\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0347 - val_loss: 0.0244 - lr: 5.0000e-04\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0346 - val_loss: 0.0244 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0346 - val_loss: 0.0243 - lr: 1.0000e-04\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0345 - val_loss: 0.0243 - lr: 1.0000e-04\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0345 - val_loss: 0.0243 - lr: 1.0000e-04\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0345 - val_loss: 0.0243 - lr: 1.0000e-04\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0344 - val_loss: 0.0243 - lr: 1.0000e-04\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0344 - val_loss: 0.0243 - lr: 1.0000e-04\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0344 - val_loss: 0.0243 - lr: 1.0000e-04\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0344 - val_loss: 0.0243 - lr: 1.0000e-04\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0344 - val_loss: 0.0243 - lr: 1.0000e-04\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0343 - val_loss: 0.0243 - lr: 1.0000e-04\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0343 - val_loss: 0.0242 - lr: 1.0000e-04\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0343 - val_loss: 0.0242 - lr: 1.0000e-04\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0343 - val_loss: 0.0242 - lr: 1.0000e-04\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0343 - val_loss: 0.0242 - lr: 1.0000e-04\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0343 - val_loss: 0.0242 - lr: 1.0000e-04\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0342 - val_loss: 0.0242 - lr: 1.0000e-04\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0342 - val_loss: 0.0243 - lr: 1.0000e-04\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0342 - val_loss: 0.0243 - lr: 1.0000e-04\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0342 - val_loss: 0.0244 - lr: 1.0000e-04\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0342 - val_loss: 0.0245 - lr: 1.0000e-04\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0342 - val_loss: 0.0245 - lr: 1.0000e-04\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0342 - val_loss: 0.0244 - lr: 1.0000e-04\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Accuracy results for iteration 3:\n",
            "                   Variable         MSE       MAE          MAPE  \\\n",
            "0  Minimum temperature (°C)    6.338461  1.964714  7.286408e-01   \n",
            "1  Maximum temperature (°C)    7.450567  2.359061  1.775255e-01   \n",
            "2             Rainfall (mm)    2.807578  1.263342  2.810004e+15   \n",
            "3          Evaporation (mm)    0.721011  0.587216  6.642817e+14   \n",
            "4          Sunshine (hours)    8.355165  2.394526  6.332140e+14   \n",
            "5                  Humidity  131.505087  9.136715  1.135963e-01   \n",
            "6                 WindSpeed   19.522270  2.744303  2.768679e-01   \n",
            "\n",
            "                          Model  \n",
            "0  Convolutional Neural Network  \n",
            "1  Convolutional Neural Network  \n",
            "2  Convolutional Neural Network  \n",
            "3  Convolutional Neural Network  \n",
            "4  Convolutional Neural Network  \n",
            "5  Convolutional Neural Network  \n",
            "6  Convolutional Neural Network  \n",
            "\n",
            "Epoch 1/100\n",
            "3/3 [==============================] - 1s 76ms/step - loss: 0.1575 - val_loss: 0.1100 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1330 - val_loss: 0.0898 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1088 - val_loss: 0.0713 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0866 - val_loss: 0.0564 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0667 - val_loss: 0.0466 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0536 - val_loss: 0.0429 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0475 - val_loss: 0.0442 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0449 - val_loss: 0.0455 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0440 - val_loss: 0.0452 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0423 - val_loss: 0.0431 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0406 - val_loss: 0.0410 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0394 - val_loss: 0.0395 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0386 - val_loss: 0.0381 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0378 - val_loss: 0.0371 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0371 - val_loss: 0.0362 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0367 - val_loss: 0.0354 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0361 - val_loss: 0.0349 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0354 - val_loss: 0.0344 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0347 - val_loss: 0.0340 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0343 - val_loss: 0.0339 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0337 - val_loss: 0.0336 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0335 - val_loss: 0.0334 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0331 - val_loss: 0.0331 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0328 - val_loss: 0.0328 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0325 - val_loss: 0.0325 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0321 - val_loss: 0.0323 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0318 - val_loss: 0.0319 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0316 - val_loss: 0.0317 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0313 - val_loss: 0.0316 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0311 - val_loss: 0.0314 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0309 - val_loss: 0.0314 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0307 - val_loss: 0.0312 - lr: 5.0000e-04\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0306 - val_loss: 0.0312 - lr: 5.0000e-04\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0305 - val_loss: 0.0312 - lr: 5.0000e-04\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0304 - val_loss: 0.0311 - lr: 5.0000e-04\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0304 - val_loss: 0.0311 - lr: 5.0000e-04\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0303 - val_loss: 0.0310 - lr: 5.0000e-04\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0302 - val_loss: 0.0310 - lr: 5.0000e-04\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0301 - val_loss: 0.0309 - lr: 5.0000e-04\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0300 - val_loss: 0.0308 - lr: 5.0000e-04\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0300 - val_loss: 0.0307 - lr: 5.0000e-04\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0299 - val_loss: 0.0307 - lr: 5.0000e-04\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0298 - val_loss: 0.0307 - lr: 5.0000e-04\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0297 - val_loss: 0.0306 - lr: 5.0000e-04\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0297 - val_loss: 0.0306 - lr: 5.0000e-04\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0296 - val_loss: 0.0306 - lr: 5.0000e-04\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0295 - val_loss: 0.0305 - lr: 5.0000e-04\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0295 - val_loss: 0.0304 - lr: 5.0000e-04\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0294 - val_loss: 0.0305 - lr: 5.0000e-04\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0294 - val_loss: 0.0305 - lr: 5.0000e-04\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0293 - val_loss: 0.0304 - lr: 5.0000e-04\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0292 - val_loss: 0.0304 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0292 - val_loss: 0.0304 - lr: 1.0000e-04\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0292 - val_loss: 0.0304 - lr: 1.0000e-04\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0292 - val_loss: 0.0304 - lr: 1.0000e-04\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0292 - val_loss: 0.0303 - lr: 1.0000e-04\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0292 - val_loss: 0.0303 - lr: 1.0000e-04\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0291 - val_loss: 0.0303 - lr: 1.0000e-04\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0291 - val_loss: 0.0303 - lr: 1.0000e-04\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0291 - val_loss: 0.0303 - lr: 1.0000e-04\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0291 - val_loss: 0.0303 - lr: 1.0000e-04\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0291 - val_loss: 0.0303 - lr: 1.0000e-04\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0291 - val_loss: 0.0303 - lr: 1.0000e-04\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0291 - val_loss: 0.0303 - lr: 1.0000e-04\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0291 - val_loss: 0.0303 - lr: 1.0000e-04\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0291 - val_loss: 0.0303 - lr: 1.0000e-04\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0290 - val_loss: 0.0303 - lr: 1.0000e-04\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0290 - val_loss: 0.0303 - lr: 1.0000e-04\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0290 - val_loss: 0.0303 - lr: 1.0000e-04\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0290 - val_loss: 0.0302 - lr: 1.0000e-04\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0290 - val_loss: 0.0303 - lr: 1.0000e-04\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0290 - val_loss: 0.0302 - lr: 1.0000e-04\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0290 - val_loss: 0.0302 - lr: 1.0000e-04\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0290 - val_loss: 0.0302 - lr: 1.0000e-04\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0289 - val_loss: 0.0302 - lr: 1.0000e-04\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0289 - val_loss: 0.0302 - lr: 1.0000e-04\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0289 - val_loss: 0.0302 - lr: 1.0000e-04\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0289 - val_loss: 0.0302 - lr: 1.0000e-04\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0289 - val_loss: 0.0302 - lr: 1.0000e-04\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0289 - val_loss: 0.0302 - lr: 1.0000e-04\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0289 - val_loss: 0.0302 - lr: 1.0000e-04\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0289 - val_loss: 0.0302 - lr: 1.0000e-04\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0289 - val_loss: 0.0302 - lr: 1.0000e-04\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0289 - val_loss: 0.0302 - lr: 1.0000e-04\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0288 - val_loss: 0.0302 - lr: 1.0000e-04\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0288 - val_loss: 0.0302 - lr: 1.0000e-04\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0288 - val_loss: 0.0302 - lr: 1.0000e-04\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0288 - val_loss: 0.0302 - lr: 1.0000e-04\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0288 - val_loss: 0.0302 - lr: 1.0000e-04\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0288 - val_loss: 0.0302 - lr: 1.0000e-04\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0288 - val_loss: 0.0302 - lr: 1.0000e-04\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0288 - val_loss: 0.0302 - lr: 1.0000e-04\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0287 - val_loss: 0.0301 - lr: 1.0000e-04\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0287 - val_loss: 0.0301 - lr: 1.0000e-04\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0287 - val_loss: 0.0301 - lr: 1.0000e-04\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0287 - val_loss: 0.0301 - lr: 1.0000e-04\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0287 - val_loss: 0.0301 - lr: 1.0000e-04\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0287 - val_loss: 0.0301 - lr: 1.0000e-04\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0287 - val_loss: 0.0301 - lr: 1.0000e-04\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0287 - val_loss: 0.0301 - lr: 1.0000e-04\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "Accuracy results for iteration 4:\n",
            "                   Variable         MSE       MAE          MAPE  \\\n",
            "0  Minimum temperature (°C)    4.267557  1.888713  2.810486e-01   \n",
            "1  Maximum temperature (°C)    4.766039  1.607779  1.075467e-01   \n",
            "2             Rainfall (mm)    7.055549  1.781135  2.878002e+15   \n",
            "3          Evaporation (mm)    1.341802  0.931757  5.944426e-01   \n",
            "4          Sunshine (hours)   12.363288  3.224459  5.415614e+14   \n",
            "5                  Humidity  119.862340  9.127882  1.454413e-01   \n",
            "6                 WindSpeed   41.564127  4.997518  3.673001e-01   \n",
            "\n",
            "                          Model  \n",
            "0  Convolutional Neural Network  \n",
            "1  Convolutional Neural Network  \n",
            "2  Convolutional Neural Network  \n",
            "3  Convolutional Neural Network  \n",
            "4  Convolutional Neural Network  \n",
            "5  Convolutional Neural Network  \n",
            "6  Convolutional Neural Network  \n",
            "\n",
            "Average accuracy across all iterations:\n",
            "                   Variable         MSE        MAE          MAPE  \\\n",
            "0  Minimum temperature (°C)    7.061706   2.135660  4.236114e-01   \n",
            "1  Maximum temperature (°C)    9.388784   2.551120  1.794417e-01   \n",
            "2             Rainfall (mm)    4.345005   1.462042  2.308669e+15   \n",
            "3          Evaporation (mm)    1.259963   0.867050  2.865864e+14   \n",
            "4          Sunshine (hours)    9.545690   2.662953  5.637547e+14   \n",
            "5                  Humidity  161.268669  10.223992  1.368558e-01   \n",
            "6                 WindSpeed   26.153902   3.728389  3.405164e-01   \n",
            "\n",
            "                          Model  \n",
            "0  Convolutional Neural Network  \n",
            "1  Convolutional Neural Network  \n",
            "2  Convolutional Neural Network  \n",
            "3  Convolutional Neural Network  \n",
            "4  Convolutional Neural Network  \n",
            "5  Convolutional Neural Network  \n",
            "6  Convolutional Neural Network  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_fnn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "5UxE6KOe_wqh",
        "outputId": "87ecc4dd-34eb-4646-a29c-e974c9492c36"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   Variable         MSE        MAE          MAPE  \\\n",
              "0  Minimum temperature (°C)    5.460042   1.909926  3.657397e-01   \n",
              "1  Maximum temperature (°C)    6.264954   2.087540  1.462133e-01   \n",
              "2             Rainfall (mm)    5.841508   1.716024  2.770512e+15   \n",
              "3          Evaporation (mm)    1.362737   0.907754  2.284182e+14   \n",
              "4          Sunshine (hours)    9.907795   2.696726  5.743140e+14   \n",
              "5                  Humidity  215.109097  11.490728  1.530031e-01   \n",
              "6                 WindSpeed   29.629314   4.045578  3.524326e-01   \n",
              "\n",
              "                        Model  \n",
              "0  Feedforward Neural Network  \n",
              "1  Feedforward Neural Network  \n",
              "2  Feedforward Neural Network  \n",
              "3  Feedforward Neural Network  \n",
              "4  Feedforward Neural Network  \n",
              "5  Feedforward Neural Network  \n",
              "6  Feedforward Neural Network  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a4e905cf-d7b5-463c-84ab-b085fe40ffa2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Variable</th>\n",
              "      <th>MSE</th>\n",
              "      <th>MAE</th>\n",
              "      <th>MAPE</th>\n",
              "      <th>Model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Minimum temperature (°C)</td>\n",
              "      <td>5.460042</td>\n",
              "      <td>1.909926</td>\n",
              "      <td>3.657397e-01</td>\n",
              "      <td>Feedforward Neural Network</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Maximum temperature (°C)</td>\n",
              "      <td>6.264954</td>\n",
              "      <td>2.087540</td>\n",
              "      <td>1.462133e-01</td>\n",
              "      <td>Feedforward Neural Network</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Rainfall (mm)</td>\n",
              "      <td>5.841508</td>\n",
              "      <td>1.716024</td>\n",
              "      <td>2.770512e+15</td>\n",
              "      <td>Feedforward Neural Network</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Evaporation (mm)</td>\n",
              "      <td>1.362737</td>\n",
              "      <td>0.907754</td>\n",
              "      <td>2.284182e+14</td>\n",
              "      <td>Feedforward Neural Network</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sunshine (hours)</td>\n",
              "      <td>9.907795</td>\n",
              "      <td>2.696726</td>\n",
              "      <td>5.743140e+14</td>\n",
              "      <td>Feedforward Neural Network</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Humidity</td>\n",
              "      <td>215.109097</td>\n",
              "      <td>11.490728</td>\n",
              "      <td>1.530031e-01</td>\n",
              "      <td>Feedforward Neural Network</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>WindSpeed</td>\n",
              "      <td>29.629314</td>\n",
              "      <td>4.045578</td>\n",
              "      <td>3.524326e-01</td>\n",
              "      <td>Feedforward Neural Network</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4e905cf-d7b5-463c-84ab-b085fe40ffa2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a4e905cf-d7b5-463c-84ab-b085fe40ffa2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a4e905cf-d7b5-463c-84ab-b085fe40ffa2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy comparison to choose the best model\n",
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame to store the accuracy results\n",
        "accuracy_results = pd.DataFrame(columns=['Model', 'Variable', 'MSE', 'MAE', 'MAPE'])\n",
        "\n",
        "# Iterate over the accuracy results from each model\n",
        "accuracy_results_per_model = [accuracy_fnn, accuracy_gru, accuracy_rnn, accuracy_rnn_tuned, accuracy_prophet, accuracy_cnn]\n",
        "\n",
        "# Concatenate the accuracy dataframes into a single dataframe\n",
        "combined_df = pd.concat(accuracy_results_per_model)\n",
        "\n",
        "# Pivot the data frame to reshape it\n",
        "pivoted_df = combined_df.pivot(index='Variable', columns='Model', values='MAE')\n",
        "\n",
        "# Reset the index\n",
        "pivoted_df.reset_index(inplace=True)\n",
        "\n",
        "# Find the model with the lowest MAE per variable\n",
        "best_model_per_variable = pivoted_df.iloc[:, 1:].idxmin(axis=1)\n",
        "\n",
        "# Create the final data frame\n",
        "final_df = pd.DataFrame({'Variable': pivoted_df['Variable'], 'Best Model': best_model_per_variable, 'MAE': pivoted_df.lookup(pivoted_df.index, best_model_per_variable)})\n",
        "\n",
        "\n",
        "# Print the pivoted data frame\n",
        "print(\"Compiled data frame:\")\n",
        "pivoted_df\n",
        "final_df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "0tWBWW0dsBCs",
        "outputId": "2d0fb67f-8fae-4d03-c61e-0a536d5202c6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compiled data frame:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-7de13423ee2a>:22: FutureWarning: The 'lookup' method is deprecated and will be removed in a future version. You can use DataFrame.melt and DataFrame.loc as a substitute.\n",
            "  final_df = pd.DataFrame({'Variable': pivoted_df['Variable'], 'Best Model': best_model_per_variable, 'MAE': pivoted_df.lookup(pivoted_df.index, best_model_per_variable)})\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   Variable                    Best Model        MAE\n",
              "0          Evaporation (mm)  Convolutional Neural Network   0.867050\n",
              "1                  Humidity  Convolutional Neural Network  10.223992\n",
              "2  Maximum temperature (°C)    Feedforward Neural Network   2.087540\n",
              "3  Minimum temperature (°C)    Feedforward Neural Network   1.909926\n",
              "4             Rainfall (mm)  Convolutional Neural Network   1.462042\n",
              "5          Sunshine (hours)                     RNN Tuned   2.602837\n",
              "6                 WindSpeed  Convolutional Neural Network   3.728389"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a5f56da4-3623-4ca1-b6aa-06a54921b8fe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Variable</th>\n",
              "      <th>Best Model</th>\n",
              "      <th>MAE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Evaporation (mm)</td>\n",
              "      <td>Convolutional Neural Network</td>\n",
              "      <td>0.867050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Humidity</td>\n",
              "      <td>Convolutional Neural Network</td>\n",
              "      <td>10.223992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Maximum temperature (°C)</td>\n",
              "      <td>Feedforward Neural Network</td>\n",
              "      <td>2.087540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Minimum temperature (°C)</td>\n",
              "      <td>Feedforward Neural Network</td>\n",
              "      <td>1.909926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Rainfall (mm)</td>\n",
              "      <td>Convolutional Neural Network</td>\n",
              "      <td>1.462042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Sunshine (hours)</td>\n",
              "      <td>RNN Tuned</td>\n",
              "      <td>2.602837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>WindSpeed</td>\n",
              "      <td>Convolutional Neural Network</td>\n",
              "      <td>3.728389</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5f56da4-3623-4ca1-b6aa-06a54921b8fe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a5f56da4-3623-4ca1-b6aa-06a54921b8fe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a5f56da4-3623-4ca1-b6aa-06a54921b8fe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0\tEvaporation (mm)\tConvolutional Neural Network\t0.863278\n",
        "# 1\tHumidity\tConvolutional Neural Network\t10.220949\n",
        "# 2\tMaximum temperature (°C)\tFeedforward Neural Network\t2.193937\n",
        "# 3\tMinimum temperature (°C)\tFeedforward Neural Network\t1.903626\n",
        "# 4\tRainfall (mm)\tConvolutional Neural Network\t1.449125\n",
        "# 5\tSunshine (hours)\tRNN Tuned\t2.605465\n",
        "# 6\tWindSpeed\tConvolutional Neural Network\t3.739441"
      ],
      "metadata": {
        "id": "_yxMlZokwPcw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Define the window size\n",
        "window_size = 30\n",
        "\n",
        "# Define the variable names\n",
        "variable_names = ['Minimum temperature (°C)', 'Maximum temperature (°C)', 'Rainfall (mm)', 'Evaporation (mm)',\n",
        "                  'Sunshine (hours)', 'Humidity', 'WindSpeed']\n",
        "\n",
        "# Split the data into train and test sets\n",
        "train_data = data[:window_size]\n",
        "test_data = data[window_size:]\n",
        "\n",
        "# Scale the data\n",
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train_data)\n",
        "test_scaled = scaler.transform(test_data)\n",
        "\n",
        "# Reshape the data\n",
        "X_train = train_scaled[:-1].reshape(-1, 1, train_scaled.shape[1])\n",
        "y_train = train_scaled[1:, :]  # Predict the next step\n",
        "\n",
        "# Define the RNN model\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, activation='relu', input_shape=(1, train_data.shape[1]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(32, activation='relu', return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(train_data.shape[1], activation='linear'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Fit the model to the training data\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1)\n",
        "\n",
        "# Make predictions on the test data\n",
        "X_test_window = test_scaled[:window_size].reshape(-1, 1, test_scaled.shape[1])\n",
        "predictions = model.predict(X_test_window)\n",
        "\n",
        "# Rescale the predictions to the original scale\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "\n",
        "# Create a DataFrame to store the predictions for each target variable\n",
        "predictions_df = pd.DataFrame(predictions, columns=variable_names)\n",
        "rnn_tuned_pred = predictions_df\n",
        "# Print the predictions DataFrame\n",
        "print(\"Predictions:\")\n",
        "print(predictions_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUt63icq0lQ5",
        "outputId": "a6f70ff2-ae43-4ff2-eee3-5c6da98dca5e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2218\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2208\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2198\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2187\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2177\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2166\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2154\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2144\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2137\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2122\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2110\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2095\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2089\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2075\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2064\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2054\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2041\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2027\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2018\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2002\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1990\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1979\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1969\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1952\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1940\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1913\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1898\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1879\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1872\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1858\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1845\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1830\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1810\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1786\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1753\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1750\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1729\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1688\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1675\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1666\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1629\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1599\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1575\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1544\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1517\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1481\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1498\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1453\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1430\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1375\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1343\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1314\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1281\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1261\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1255\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1256\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1236\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1137\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1089\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1104\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1048\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1014\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0998\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0993\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0940\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0874\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0908\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0893\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0921\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0839\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0842\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0850\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0758\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0819\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0850\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0810\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0840\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0766\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0843\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0748\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0761\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0816\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0804\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0789\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0776\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0753\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0789\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0786\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0757\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0686\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0746\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0739\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0738\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0765\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0695\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0750\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0748\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0771\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0706\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0691\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Predictions:\n",
            "    Minimum temperature (°C)  Maximum temperature (°C)  Rainfall (mm)  \\\n",
            "0                  12.239758                 20.338369       2.025027   \n",
            "1                  12.649544                 20.747162       2.256147   \n",
            "2                  13.214915                 21.244549       2.191854   \n",
            "3                  10.993376                 19.102839       1.945139   \n",
            "4                  10.606568                 18.973454       0.917146   \n",
            "5                  10.879086                 19.276176       0.762906   \n",
            "6                  11.242032                 19.362955       1.634822   \n",
            "7                  11.191068                 19.318344       1.816294   \n",
            "8                  11.118015                 19.444834       1.377785   \n",
            "9                  11.402794                 19.824749       1.170204   \n",
            "10                 10.708426                 18.946711       1.630074   \n",
            "11                 11.421982                 19.569592       2.184394   \n",
            "12                 11.505038                 19.631939       2.373241   \n",
            "13                 12.636383                 20.475739       2.646600   \n",
            "14                 13.587308                 21.581863       2.585805   \n",
            "15                 11.647107                 19.765371       1.970864   \n",
            "16                 11.172978                 19.390324       1.409736   \n",
            "17                 11.058612                 19.356230       1.263203   \n",
            "18                 10.420127                 18.634649       1.373416   \n",
            "19                 10.595279                 18.793095       1.490912   \n",
            "20                 10.948341                 19.406757       0.777951   \n",
            "21                 10.598831                 18.955362       1.115319   \n",
            "22                 11.492242                 19.859426       1.243567   \n",
            "23                 11.709829                 20.101377       1.273594   \n",
            "24                 11.073657                 19.319992       1.464064   \n",
            "25                 11.254551                 19.370693       1.851541   \n",
            "26                 11.260738                 19.484140       1.926613   \n",
            "27                 10.510590                 18.916416       1.082451   \n",
            "28                 11.272137                 19.551147       1.236877   \n",
            "29                  9.920409                 18.269503       1.014998   \n",
            "\n",
            "    Evaporation (mm)  Sunshine (hours)   Humidity  WindSpeed  \n",
            "0           3.169352          3.892065  61.212803   9.109571  \n",
            "1           3.389192          4.226113  62.869240   9.555516  \n",
            "2           3.688435          4.744773  65.030258  10.045140  \n",
            "3           2.523043          2.740126  56.400253   7.930269  \n",
            "4           2.360340          2.747109  54.966709   7.545920  \n",
            "5           2.507631          3.064807  56.038605   7.816990  \n",
            "6           2.652625          3.034597  57.188492   8.096046  \n",
            "7           2.610019          2.938732  57.062531   8.088938  \n",
            "8           2.568206          3.106364  57.043514   8.006333  \n",
            "9           2.731296          3.491981  58.271637   8.288343  \n",
            "10          2.325675          2.583138  55.203625   7.597415  \n",
            "11          2.664299          3.111340  58.268490   8.327988  \n",
            "12          2.676066          3.132860  58.757786   8.439551  \n",
            "13          3.325960          3.942285  62.645687   9.483537  \n",
            "14          3.866803          4.985604  66.597878  10.460145  \n",
            "15          2.843119          3.375197  58.991508   8.527974  \n",
            "16          2.658362          3.089230  57.069061   8.077953  \n",
            "17          2.597070          3.040788  56.783051   8.022087  \n",
            "18          2.241589          2.350645  54.006306   7.324062  \n",
            "19          2.333393          2.470151  54.711578   7.520420  \n",
            "20          2.497859          3.165255  56.472374   7.873044  \n",
            "21          2.306856          2.682829  54.975506   7.499648  \n",
            "22          2.747706          3.522374  58.554329   8.362164  \n",
            "23          2.897826          3.736376  59.363491   8.577948  \n",
            "24          2.577413          2.983534  56.539043   7.936935  \n",
            "25          2.610760          2.991864  57.287868   8.101344  \n",
            "26          2.620178          3.059003  57.727978   8.199530  \n",
            "27          2.266477          2.633770  54.762550   7.442822  \n",
            "28          2.662123          3.255102  57.441883   8.136607  \n",
            "29          1.953295          2.027576  52.263313   6.845030  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define the window size\n",
        "window_size = 30\n",
        "\n",
        "# Define the variable names\n",
        "variable_names = ['Minimum temperature (°C)', 'Maximum temperature (°C)', 'Rainfall (mm)', 'Evaporation (mm)',\n",
        "                  'Sunshine (hours)', 'Humidity', 'WindSpeed']\n",
        "\n",
        "# Split the data into train and test sets\n",
        "train_data = data[:window_size]\n",
        "test_data = data[window_size:]\n",
        "\n",
        "# Scale the data\n",
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train_data)\n",
        "test_scaled = scaler.transform(test_data)\n",
        "\n",
        "# Reshape the data\n",
        "X_train = train_scaled[:-1]\n",
        "y_train = train_scaled[1:, :]  # Predict the next step\n",
        "\n",
        "# Define the feedforward neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(train_data.shape[1], activation='linear'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Fit the model to the training data\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.predict(test_scaled[:-1])\n",
        "\n",
        "# Rescale the predictions to the original scale\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "\n",
        "# Create a DataFrame to store the predictions for each target variable\n",
        "predictions_df = pd.DataFrame(predictions, columns=variable_names)\n",
        "fnn_pred = predictions_df\n",
        "# Print the predictions DataFrame\n",
        "print(\"Predictions:\")\n",
        "print(predictions_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hz5mxwo6C9G1",
        "outputId": "3d0800c0-54e7-4588-dc63-5ad1b994af2a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.2450\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2305\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2238\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2140\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2018\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1966\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1906\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1745\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1764\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1892\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1636\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1565\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1641\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1564\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1593\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1418\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1424\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1395\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1334\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1230\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1224\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1253\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1179\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1217\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1222\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1188\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1191\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1091\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1019\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1050\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1095\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0976\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0964\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0979\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0984\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1014\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0947\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0945\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0856\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0926\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0927\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0890\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0789\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0796\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0916\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0774\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0820\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0826\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0712\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0931\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0877\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0816\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0854\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0724\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0830\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0857\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0834\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0783\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0834\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0795\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0683\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0798\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0795\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0689\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0771\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0704\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0735\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0735\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0766\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0788\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0692\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0658\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0826\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0674\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0752\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0696\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0772\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0707\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0737\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0678\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0633\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0635\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0709\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0702\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0714\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0686\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0668\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0704\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0648\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0620\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0621\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0654\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0618\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0709\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0742\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0624\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0700\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0759\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0600\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0618\n",
            "13/13 [==============================] - 0s 1ms/step\n",
            "Predictions:\n",
            "     Minimum temperature (°C)  Maximum temperature (°C)  Rainfall (mm)  \\\n",
            "0                   11.479848                 20.895336       1.178997   \n",
            "1                   12.365689                 21.735481       1.707623   \n",
            "2                   12.344216                 22.222755       1.642303   \n",
            "3                   11.912178                 18.101139       2.294970   \n",
            "4                    8.757357                 19.754608      -1.717508   \n",
            "..                        ...                       ...            ...   \n",
            "389                 12.063169                 19.128836       2.025832   \n",
            "390                  9.234193                 19.834217      -1.007146   \n",
            "391                 10.324456                 19.293739       0.227096   \n",
            "392                 11.480647                 19.615362       3.258461   \n",
            "393                 10.305767                 20.520479       0.991759   \n",
            "\n",
            "     Evaporation (mm)  Sunshine (hours)   Humidity  WindSpeed  \n",
            "0            3.396421          4.506161  58.773014   9.469510  \n",
            "1            4.147024          4.889978  58.852085   9.421436  \n",
            "2            4.636154          5.480916  60.759125  10.083775  \n",
            "3            2.194097          2.230977  61.468636   8.010620  \n",
            "4            1.857029          4.772020  55.101433   8.196639  \n",
            "..                ...               ...        ...        ...  \n",
            "389          2.869055          3.269714  60.287392   9.589694  \n",
            "390          1.763256          4.539143  54.697598   8.512794  \n",
            "391          2.535240          3.530619  55.734760   8.564412  \n",
            "392          1.145945          2.886495  64.649261   9.631326  \n",
            "393          2.446033          4.291173  56.443367   9.187361  \n",
            "\n",
            "[394 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define the window size\n",
        "window_size = 30\n",
        "\n",
        "# Define the variable names\n",
        "variable_names = ['Minimum temperature (°C)', 'Maximum temperature (°C)', 'Rainfall (mm)', 'Evaporation (mm)',\n",
        "                  'Sunshine (hours)', 'Humidity', 'WindSpeed']\n",
        "\n",
        "# Scale the data\n",
        "scaler = MinMaxScaler()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "# Reshape the data for CNN input\n",
        "X = data_scaled[:-1]\n",
        "y = data_scaled[1:, :]  # Predict the next step\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "\n",
        "# Define lists to store predictions for each variable\n",
        "predictions_list = []\n",
        "\n",
        "# Perform forecasting for each variable\n",
        "for i in range(data.shape[1]):\n",
        "    # Define the CNN model\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(data.shape[1], 1)))\n",
        "    model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    # Compile the model\n",
        "    optimizer = Adam(learning_rate=0.001)\n",
        "    model.compile(optimizer=optimizer, loss='mse')\n",
        "\n",
        "    # Fit the model to the data\n",
        "    model.fit(X, y[:, i], epochs=100, batch_size=32, verbose=1)\n",
        "\n",
        "    # Make predictions on the data\n",
        "    predictions = model.predict(X)\n",
        "\n",
        "    # Append the predictions to the list\n",
        "    predictions_list.append(predictions)\n",
        "\n",
        "# Concatenate the predictions for each variable horizontally\n",
        "predictions_array = np.hstack(predictions_list)\n",
        "\n",
        "# Rescale the predictions to the original scale\n",
        "predictions_rescaled = scaler.inverse_transform(predictions_array)\n",
        "\n",
        "# Create a DataFrame to store the predictions\n",
        "predictions_df = pd.DataFrame(predictions_rescaled, columns=variable_names)\n",
        "cnn_pred = predictions_df\n",
        "# Print the predictions\n",
        "print(\"Predictions:\")\n",
        "print(predictions_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GT9yr2xoA_j5",
        "outputId": "9f05f255-93aa-40ca-b8f2-ec2a5818d477"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.1355\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0209\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0145\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0119\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0105\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0097\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0090\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0084\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0079\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0075\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0071\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0069\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0068\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0064\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0064\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0064\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0062\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0063\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0061\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0062\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0064\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0061\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0061\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0060\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0060\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0059\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0060\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0059\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0061\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0059\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0059\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0059\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0058\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0059\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0059\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0059\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0059\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0057\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0058\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0057\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0058\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0057\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0058\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0058\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0057\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0057\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0057\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0057\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0058\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0058\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0057\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0057\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0061\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0057\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0056\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0059\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0060\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0061\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0057\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0058\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0059\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0056\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0056\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0058\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0056\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0056\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0055\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0059\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0056\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0056\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0056\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0055\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0057\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0054\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0055\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0055\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0054\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0054\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0056\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0056\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0055\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0058\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0055\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0055\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0057\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0054\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0053\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0054\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0054\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0053\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0054\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0058\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0058\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0054\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0054\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0056\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0056\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0054\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0057\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0055\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "Epoch 1/100\n",
            "14/14 [==============================] - 1s 2ms/step - loss: 0.0455\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0199\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0164\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0152\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0145\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0142\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0137\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0134\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0132\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0130\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0128\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0126\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0127\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0126\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0129\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0126\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0123\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0122\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0121\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0121\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0120\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0121\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0119\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0120\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0118\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0119\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0118\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0117\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0117\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0118\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0118\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0122\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0126\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0123\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0118\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0118\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0115\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0119\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0124\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0117\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0113\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0114\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0114\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0113\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0111\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0114\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0113\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0112\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0115\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0111\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0111\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0110\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0111\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0115\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0122\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0114\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0111\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0111\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0113\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0111\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0112\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0114\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0111\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0109\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0108\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0108\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0109\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0108\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0111\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0112\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0108\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0107\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0108\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0111\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0119\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0108\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0106\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0106\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0105\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0107\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0110\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0113\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0113\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0113\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0108\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0105\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0107\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0106\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0105\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0105\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0105\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0103\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0104\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0107\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0104\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0103\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0107\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0105\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0103\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0102\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "Epoch 1/100\n",
            "14/14 [==============================] - 1s 2ms/step - loss: 0.0139\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0119\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0114\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0110\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0106\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0106\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0104\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0104\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0102\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0101\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0100\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0101\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0101\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0103\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0099\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0100\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0102\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0098\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0097\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0100\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0099\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0097\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0095\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0097\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0099\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0095\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0094\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0093\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0095\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0095\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0093\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0091\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0091\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0092\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0090\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0090\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0091\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0089\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0090\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0090\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0089\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0091\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0091\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0089\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0094\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0090\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0089\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0089\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0090\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0089\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0087\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0086\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0086\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0086\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0088\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0088\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0087\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0086\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0085\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0084\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0087\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0084\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0084\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0085\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0085\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0085\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0084\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0085\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0083\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0083\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0081\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0083\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0083\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0082\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0080\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0080\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0080\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0081\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0085\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0083\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0079\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0079\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0079\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0077\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0077\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0076\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0078\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0077\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0078\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0076\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0080\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0079\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0083\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0080\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0075\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0075\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0077\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0078\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0076\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0074\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "Epoch 1/100\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.0248\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0114\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0084\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0074\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0069\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0065\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0065\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0064\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0062\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0061\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0061\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0062\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0060\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0059\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0059\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0058\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0059\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0058\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0058\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0059\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0059\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0058\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0057\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0057\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0056\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0057\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0057\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0057\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0057\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0056\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0058\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0056\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0059\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0056\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0057\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0056\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0058\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0059\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0055\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0055\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0060\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0055\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0057\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0058\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0054\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0054\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0055\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0054\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0054\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0053\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0055\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0054\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0053\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0054\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0056\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0053\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0053\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0053\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0055\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0055\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0053\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0053\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0052\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0054\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0052\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0052\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0052\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0052\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0052\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0054\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0053\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0052\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0053\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0052\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0054\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0055\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0051\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0053\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0055\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0054\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0058\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0057\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0051\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0051\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0052\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0051\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0051\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0051\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0051\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0051\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0049\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0051\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0050\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0050\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0050\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0049\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0049\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0048\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0052\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0051\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "Epoch 1/100\n",
            "14/14 [==============================] - 1s 2ms/step - loss: 0.1222\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0767\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0698\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0693\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0682\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0677\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0679\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0670\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0670\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0666\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0664\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0659\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0653\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0654\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0647\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0645\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0641\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0642\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0640\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0642\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0635\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0633\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0652\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0631\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0631\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0628\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0632\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0625\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0624\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0630\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0667\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0634\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0632\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0628\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0616\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0615\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0611\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0612\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0610\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0606\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0607\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0605\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0604\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0606\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0604\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0604\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0598\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0604\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0596\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0597\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0594\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0595\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0592\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0596\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0593\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0594\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0596\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0586\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0588\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0599\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0591\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0585\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0598\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0590\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0587\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0578\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0577\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0594\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0599\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0581\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0577\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0575\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0577\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0578\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0581\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0599\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0571\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0568\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0572\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0571\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0561\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0574\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0565\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0566\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0578\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0566\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0568\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0565\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0565\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0562\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0559\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0566\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0558\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0555\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0551\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0559\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0553\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "Epoch 1/100\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.1837\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0434\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0319\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0238\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0216\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0210\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0210\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0201\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0202\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0198\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0196\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0197\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0195\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0192\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0194\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0191\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0194\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0193\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0192\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0192\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0188\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0189\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0194\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0199\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0198\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0190\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0185\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0185\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0185\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0186\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0187\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0185\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0185\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0184\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0185\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0181\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0185\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0185\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0183\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0181\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0183\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0181\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0182\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0184\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0185\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0186\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0179\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0182\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0178\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0178\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0182\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0182\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0181\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0176\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0176\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0180\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0176\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0181\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0181\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0179\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0175\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0176\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0180\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0174\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0178\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0182\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0177\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0173\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0174\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0173\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0175\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0173\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0175\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0174\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0174\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0176\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0174\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0181\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0171\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0172\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0178\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0170\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0173\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0170\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0178\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0170\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0175\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0169\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0175\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0174\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0173\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0179\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0171\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0171\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0169\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0168\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "Epoch 1/100\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.0865\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0362\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0303\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0291\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0290\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0283\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0283\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0285\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0282\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0283\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0274\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0270\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0272\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0271\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0272\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0268\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0267\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0268\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0266\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0265\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0266\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0267\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0264\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0266\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0263\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0262\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0263\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0269\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0263\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0267\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0259\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0261\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0261\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0262\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0264\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0266\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0258\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0258\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0260\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0255\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0263\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0258\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0258\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0256\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0255\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0255\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0255\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0253\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0257\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0265\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0258\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0255\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0255\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0255\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0254\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0254\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0252\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0252\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0255\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0253\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0254\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0251\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0257\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0250\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0250\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0251\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0253\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0251\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0248\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0251\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0252\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0250\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0249\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0251\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0247\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0253\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0254\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0251\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0246\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0247\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0247\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0244\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0249\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0249\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0255\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0247\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0243\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0243\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0247\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0245\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0246\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0248\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0246\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0245\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0243\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0241\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0243\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0246\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0242\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0242\n",
            "14/14 [==============================] - 0s 3ms/step\n",
            "Predictions:\n",
            "     Minimum temperature (°C)  Maximum temperature (°C)  Rainfall (mm)  \\\n",
            "0                   12.643188                 20.658270      -0.260973   \n",
            "1                   13.313573                 19.230715       3.249990   \n",
            "2                   13.590748                 19.165522       4.850351   \n",
            "3                   12.544363                 19.601967      -0.689414   \n",
            "4                   12.183671                 19.311897       2.587312   \n",
            "..                        ...                       ...            ...   \n",
            "419                  9.870977                 16.694664       6.577484   \n",
            "420                  7.561992                 13.812006       1.151546   \n",
            "421                  9.974520                 16.079075       1.331179   \n",
            "422                 10.296424                 16.699421       6.893641   \n",
            "423                 10.181731                 15.998187       2.830070   \n",
            "\n",
            "     Evaporation (mm)  Sunshine (hours)   Humidity  WindSpeed  \n",
            "0            5.471969          8.384753  58.303997  11.728765  \n",
            "1            2.112429          5.284621  67.920212   9.912387  \n",
            "2            1.674787          4.883007  71.107040   9.577780  \n",
            "3            2.274189          4.984979  65.938812  10.471246  \n",
            "4            3.278453          4.901415  67.075516  10.720478  \n",
            "..                ...               ...        ...        ...  \n",
            "419          1.973167          6.515362  66.054443  11.859123  \n",
            "420          2.129961          4.771864  67.901749  11.121782  \n",
            "421          2.282837          5.098263  66.384468  11.173075  \n",
            "422          1.832880          3.977004  70.649605  10.447880  \n",
            "423          2.836814          4.167356  66.799713  11.081756  \n",
            "\n",
            "[424 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# combining predictions result from different models\n",
        "rnn = rnn_tuned_pred[['Sunshine (hours)']]\n",
        "fnn = fnn_pred[['Minimum temperature (°C)', 'Maximum temperature (°C)']]\n",
        "cnn = cnn_pred[['Evaporation (mm)', 'Humidity', 'Rainfall (mm)','WindSpeed']]\n",
        "\n",
        "predictions_df = pd.concat([rnn, fnn, cnn], axis=1)"
      ],
      "metadata": {
        "id": "dhgzJSIf2S3H"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = predictions_df\n",
        "result\n",
        "# result.agg({'Minimum temperature (°C)':'Maximum temperature (°C)','Rainfall (mm)', 'Evaporation (mm)'\n",
        "#             , 'Humidity', 'WindSpeed':['min','max','mean','mean','mean','mean'])\n",
        "agg=result.agg({'Minimum temperature (°C)':'min','Maximum temperature (°C)':'max','Sunshine (hours)':'mean','Rainfall (mm)':'mean',\n",
        "                'Evaporation (mm)':'mean'\n",
        "            , 'Humidity':'mean', 'WindSpeed':'mean'})\n",
        "agg = pd.DataFrame(agg)\n",
        "agg = agg.transpose()\n",
        "\n",
        "# agg.rename(columns=agg.iloc[0])\n",
        "agg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "lkQuFPVtl1Qg",
        "outputId": "f4ab3685-1d0f-403f-fd17-78bbb11c3f49"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Minimum temperature (°C)  Maximum temperature (°C)  Sunshine (hours)  \\\n",
              "0                  8.554278                 26.363726          3.204186   \n",
              "\n",
              "   Rainfall (mm)  Evaporation (mm)   Humidity  WindSpeed  \n",
              "0       1.794452          3.931512  64.848198  10.826262  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df593cb6-ce38-447c-b713-7d1dd649c7c6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Minimum temperature (°C)</th>\n",
              "      <th>Maximum temperature (°C)</th>\n",
              "      <th>Sunshine (hours)</th>\n",
              "      <th>Rainfall (mm)</th>\n",
              "      <th>Evaporation (mm)</th>\n",
              "      <th>Humidity</th>\n",
              "      <th>WindSpeed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.554278</td>\n",
              "      <td>26.363726</td>\n",
              "      <td>3.204186</td>\n",
              "      <td>1.794452</td>\n",
              "      <td>3.931512</td>\n",
              "      <td>64.848198</td>\n",
              "      <td>10.826262</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df593cb6-ce38-447c-b713-7d1dd649c7c6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-df593cb6-ce38-447c-b713-7d1dd649c7c6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-df593cb6-ce38-447c-b713-7d1dd649c7c6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "bsoLxd-Ll1gl",
        "outputId": "8a849736-14b3-4f65-c9f4-abe330b5b4ad"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bdec2c81-8765-4b8b-b930-38c005911370\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bdec2c81-8765-4b8b-b930-38c005911370\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving usda_plant_database.csv to usda_plant_database.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "usda = pd.read_csv(io.BytesIO(uploaded['usda_plant_database.csv']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeQvvkLImMtu",
        "outputId": "0f9ae61a-be4e-486d-82d5-718640b08eb6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-8a47f8b3ef80>:2: DtypeWarning: Columns (2,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  usda = pd.read_csv(io.BytesIO(uploaded['usda_plant_database.csv']))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "usda.fillna({'FertilityRequirement':'Unknown', 'NurseryStockProduct':'Unknown', 'LowGrowingGrass':'Unknown',\n",
        "             'PalatableHuman':'Unknown'\n",
        "              , 'AdaptedCoarseSoils': 'Unknown', 'AdaptedMediumSoils': 'Unknown', 'AdaptedFineSoils': 'Unknown'\n",
        "            , 'Toxicity': 'Unknown' , 'FruitSeedAbundance': 'Unknown' , 'FruitSeedPersistence': 'Unknown'\n",
        "            , 'SeddlingVigor': 'Unknown', 'VegetativeSpreadRate': 'Unknown', 'KnownAllelopath': 'Unknown'\n",
        "            , 'GrowthRate': 'Unknown', 'CoppicePotential': 'Unknown', 'PostProduct': 'Unknown'\n",
        "            , 'AdaptedCoarseSoils': 'Unknown', 'AdaptedMediumSoils': 'Unknown', 'AdaptedFineSoils': 'Unknown'\n",
        "            , 'Propogated_by_BareRoot': 'Unknown', 'Propogated_by_Bulbs': 'Unknown', 'Propogated_by_Container': 'Unknown'\n",
        "            , 'Propogated_by_Corms': 'Unknown', 'Propogated_by_Cuttings': 'Unknown', 'Propogated_by_Seed': 'Unknown'\n",
        "            , 'Propogated_by_Sod': 'Unknown', 'Propogated_by_Sprigs': 'Unknown', 'Propogated_by_Tubers': 'Unknown'}, inplace=True)"
      ],
      "metadata": {
        "id": "bs-yTI4-ntCz"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "usda = usda[['FertilityRequirement','NurseryStockProduct', 'LowGrowingGrass',\n",
        "             'PalatableHuman', 'ScientificName', 'CommonName',\n",
        "             'Toxicity' , 'FruitSeedAbundance', 'FruitSeedPersistence'\n",
        "            , 'SeedlingVigor', 'VegetativeSpreadRate', 'KnownAllelopath'\n",
        "            , 'GrowthRate', 'CoppicePotential', 'PostProduct'\n",
        "            , 'AdaptedCoarseSoils', 'AdaptedMediumSoils', 'AdaptedFineSoils'\n",
        "            , 'Propogated_by_BareRoot', 'Propogated_by_Bulbs', 'Propogated_by_Container'\n",
        "            , 'Propogated_by_Corms', 'Propogated_by_Cuttings', 'Propogated_by_Seed'\n",
        "            , 'Propogated_by_Sod', 'Propogated_by_Sprigs', 'Propogated_by_Tubers'\n",
        "            ,'DroughtTolerance','ShadeTolerance', 'TemperatureMinimum', 'ChristmasTreeProduct', 'ProteinPotential']]\n",
        "usda.head()\n",
        "usda2 = usda"
      ],
      "metadata": {
        "id": "Ib8fRBTVnxWa"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "usda2 = usda\n",
        "# Applying hard scoring on each variable\n",
        "usda2['FertilityRequirement'] = np.where(usda2['FertilityRequirement'] == 'Low', 1,\n",
        "                   np.where(usda2['FertilityRequirement'] == 'Medium', 0.5,\n",
        "                            np.where(usda2['FertilityRequirement'] == 'High', 0, 0)))\n",
        "\n",
        "usda2['ChristmasTreeProduct'] = np.where(usda2['ChristmasTreeProduct'] == 'Yes', 1,\n",
        "                   np.where(usda2['ChristmasTreeProduct'] == 'No', 0,\n",
        "                            np.where(usda2['ChristmasTreeProduct'] == 'Unknown', 0, 0)))\n",
        "\n",
        "usda2['NurseryStockProduct'] = np.where(usda2['NurseryStockProduct'] == 'Yes', 1,\n",
        "                   np.where(usda2['NurseryStockProduct'] == 'No', 0,\n",
        "                            np.where(usda2['NurseryStockProduct'] == 'Unknown', 0, 0)))\n",
        "\n",
        "usda2['PalatableHuman'] = np.where(usda2['PalatableHuman'] == 'Yes', 1,\n",
        "                   np.where(usda2['PalatableHuman'] == 'No', 0,\n",
        "                            np.where(usda2['PalatableHuman'] == 'Unknown', 0, 0)))\n",
        "\n",
        "usda2['ProteinPotential'] = np.where(usda2['ProteinPotential'] == 'Yes', 1,\n",
        "                   np.where(usda2['ProteinPotential'] == 'No', 0,\n",
        "                            np.where(usda2['ProteinPotential'] == 'Unknown', 0, 0)))\n",
        "\n",
        "usda2['LowGrowingGrass'] = np.where(usda2['LowGrowingGrass'] == 'Yes', 0,\n",
        "                   np.where(usda2['LowGrowingGrass'] == 'No', 1,\n",
        "                            np.where(usda2['LowGrowingGrass'] == 'Unknown', 0, 0)))\n",
        "\n",
        "usda2['AdaptedCoarseSoils'] = np.where(usda2['AdaptedCoarseSoils'] == 'Yes', 1,\n",
        "                   np.where(usda2['AdaptedCoarseSoils'] == 'No', 0,\n",
        "                            np.where(usda2['AdaptedCoarseSoils'] == 'Unknown', 0, 0)))\n",
        "\n",
        "usda2['AdaptedMediumSoils'] = np.where(usda2['AdaptedMediumSoils'] == 'Yes', 1,\n",
        "                   np.where(usda2['AdaptedMediumSoils'] == 'No', 0,\n",
        "                            np.where(usda2['AdaptedMediumSoils'] == 'Unknown', 0, 0)))\n",
        "\n",
        "usda2['AdaptedFineSoils'] = np.where(usda2['AdaptedFineSoils'] == 'Yes', 1,\n",
        "                   np.where(usda2['AdaptedFineSoils'] == 'No', 0,\n",
        "                            np.where(usda2['AdaptedFineSoils'] == 'Unknown', 0, 0)))\n",
        "\n",
        "usda2['Toxicity'] = np.where(usda2['Toxicity'] == 'Severe', -50,\n",
        "                   np.where(usda2['Toxicity'] == 'Moderate', -20,\n",
        "                            np.where(usda2['Toxicity'] == 'Slight', 0,\n",
        "                            np.where(usda2['Toxicity'] == 'None', 1, 0))))\n",
        "\n",
        "usda2['FruitSeedAbundance'] = np.where(usda2['FruitSeedAbundance'] == 'High', 1,\n",
        "                   np.where(usda2['FruitSeedAbundance'] == 'Medium', 0.5,\n",
        "                            np.where(usda2['FruitSeedAbundance'] == 'Low', 0, 0)))\n",
        "\n",
        "usda2['FruitSeedPersistence'] = np.where(usda2['FruitSeedPersistence'] == 'Yes', 1,\n",
        "                   np.where(usda2['FruitSeedPersistence'] == 'No', 0,\n",
        "                            np.where(usda2['FruitSeedPersistence'] == 'Unknown', 0, 0)))\n",
        "\n",
        "usda2['SeedlingVigor'] = np.where(usda2['SeedlingVigor'] == 'High', 1,\n",
        "                   np.where(usda2['SeedlingVigor'] == 'Medium', 0.5,\n",
        "                            np.where(usda2['SeedlingVigor'] == 'Low', 0, 0)))\n",
        "\n",
        "usda2['VegetativeSpreadRate'] = np.where(usda2['VegetativeSpreadRate'] == 'Rapid', 1,\n",
        "                   np.where(usda2['VegetativeSpreadRate'] == 'Moderate', 0.5,\n",
        "                            np.where(usda2['VegetativeSpreadRate'] == 'Slow', 0, 0)))\n",
        "\n",
        "usda2['KnownAllelopath'] = np.where(usda2['KnownAllelopath'] == 'Yes', 1,\n",
        "                   np.where(usda2['KnownAllelopath'] == 'No', 0,\n",
        "                            np.where(usda2['KnownAllelopath'] == 'Unknown', 0, 0)))\n",
        "\n",
        "usda2['GrowthRate'] = np.where(usda2['GrowthRate'] == 'Rapid', 1,\n",
        "                   np.where(usda2['GrowthRate'] == 'Moderate', 0.5,\n",
        "                            np.where(usda2['GrowthRate'] == 'Slow', 0, 0)))\n",
        "\n",
        "usda2['CoppicePotential'] = np.where(usda2['CoppicePotential'] == 'Yes', 1,\n",
        "                   np.where(usda2['CoppicePotential'] == 'No', 0,\n",
        "                            np.where(usda2['CoppicePotential'] == 'Unknown', 0, 0)))\n",
        "\n",
        "usda2['PostProduct'] = np.where(usda2['PostProduct'] == 'Yes', 1,\n",
        "                   np.where(usda2['PostProduct'] == 'No', 0,\n",
        "                            np.where(usda2['PostProduct'] == 'Unknown', 0, 0)))\n",
        "\n",
        "usda2['Propogated_by_Seed'] = np.where(usda2['Propogated_by_Seed'] == 'Yes', 0.9,\n",
        "                   np.where(usda2['Propogated_by_Seed'] == 'No', 0,\n",
        "                            np.where(usda2['Propogated_by_Seed'] == 'Unknown', 0, 0)))\n",
        "\n",
        "usda2['Propogated_by_Cuttings'] = np.where(usda2['Propogated_by_Cuttings'] == 'Yes', 0.8,\n",
        "                   np.where(usda2['Propogated_by_Cuttings'] == 'No', 0,\n",
        "                            np.where(usda2['Propogated_by_Cuttings'] == 'Unknown', 0, 0)))\n",
        "\n",
        "usda2['Propogated_by_BareRoot'] = np.where(usda2['Propogated_by_BareRoot'] == 'Yes', 0.7,\n",
        "                   np.where(usda2['Propogated_by_BareRoot'] == 'No', 0,\n",
        "                            np.where(usda2['Propogated_by_BareRoot'] == 'Unknown', 0, 0)))\n",
        "\n",
        "usda2['Propogated_by_Container'] = np.where(usda2['Propogated_by_Container'] == 'Yes', 0.6,\n",
        "                   np.where(usda2['Propogated_by_Container'] == 'No', 0,\n",
        "                            np.where(usda2['Propogated_by_Container'] == 'Unknown', 0, 0)))\n",
        "\n",
        "usda2['Propogated_by_Bulbs'] = np.where(usda2['Propogated_by_Bulbs'] == 'Yes', 0.5,\n",
        "                   np.where(usda2['Propogated_by_Bulbs'] == 'No', 0,\n",
        "                            np.where(usda2['Propogated_by_Bulbs'] == 'Unknown', 0, 0)))\n",
        "\n",
        "usda2['Propogated_by_Corms'] = np.where(usda2['Propogated_by_Corms'] == 'Yes', 0.4,\n",
        "                   np.where(usda2['Propogated_by_Corms'] == 'No', 0,\n",
        "                            np.where(usda2['Propogated_by_Corms'] == 'Unknown', 0, 0)))\n",
        "\n",
        "usda2['Propogated_by_Sod'] = np.where(usda2['Propogated_by_Sod'] == 'Yes', 0.3,\n",
        "                   np.where(usda2['Propogated_by_Sod'] == 'No', 0,\n",
        "                            np.where(usda2['Propogated_by_Sod'] == 'Unknown', 0, 0)))\n",
        "\n",
        "usda2['Propogated_by_Sprigs'] = np.where(usda2['Propogated_by_Sprigs'] == 'Yes', 0.2,\n",
        "                   np.where(usda2['Propogated_by_Sprigs'] == 'No', 0,\n",
        "                            np.where(usda2['Propogated_by_Sprigs'] == 'Unknown', 0, 0)))\n",
        "\n",
        "usda2['Propogated_by_Tubers'] = np.where(usda2['Propogated_by_Tubers'] == 'Yes', 0.1,\n",
        "                   np.where(usda2['Propogated_by_Tubers'] == 'No', 0,\n",
        "                            np.where(usda2['Propogated_by_Tubers'] == 'Unknown', 0, 0)))\n",
        "\n",
        "usda2['ShadeTolerance'] = np.where(usda2['ShadeTolerance'] == 'Tolerant', 2,\n",
        "                   np.where(usda2['ShadeTolerance'] == 'Intermediate', 1,\n",
        "                            np.where(usda2['ShadeTolerance'] == 'Intolerant', 0, 0)))\n",
        "\n",
        "usda2['DroughtTolerance'] = np.where(usda2['DroughtTolerance'] == 'High', 2,\n",
        "                   np.where(usda2['DroughtTolerance'] == 'Medium', 1,\n",
        "                            np.where(usda2['DroughtTolerance'] == 'Low', 0, 0)))"
      ],
      "metadata": {
        "id": "tPfkMRoCny94"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# result2 = result.reset_index()\n",
        "\n",
        "agg['key'] = 0\n",
        "usda2['key'] = 0\n",
        "\n",
        "m = agg.merge(usda2, on='key', how='outer')"
      ],
      "metadata": {
        "id": "RkzlsXVzn1XQ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing hard categorization\n",
        "m['HumidityCategory'] = np.select(\n",
        "    [\n",
        "        m['Humidity'].between(0, 30.000, inclusive=True),\n",
        "        m['Humidity'].between(30.001, 70.000, inclusive=True)\n",
        "    ],\n",
        "    [\n",
        "        'Low',\n",
        "        'Medium'\n",
        "    ],\n",
        "    default='High'\n",
        ")\n",
        "\n",
        "m['SunshineCategory'] = np.select(\n",
        "    [\n",
        "        m['Sunshine (hours)'].between(0, 2.999999, inclusive=True),\n",
        "        m['Sunshine (hours)'].between(3, 6, inclusive=True)\n",
        "    ],\n",
        "    [\n",
        "        'Low',\n",
        "        'Medium'\n",
        "    ],\n",
        "    default='High'\n",
        ")\n",
        "\n",
        "m['WindSpeedCategory'] = np.select(\n",
        "    [\n",
        "        m['WindSpeed'].between(0, 3.999999, inclusive=True),\n",
        "        m['WindSpeed'].between(4, 5.999999, inclusive=True),\n",
        "        m['WindSpeed'].between(6, 8.999999, inclusive=True),\n",
        "    ],\n",
        "    [\n",
        "        'Low',\n",
        "        'Medium',\n",
        "        'Strong'\n",
        "\n",
        "    ],\n",
        "    default='Severely Strong'\n",
        ")\n",
        "\n",
        "m['Rainfall (mm)'] = np.select(\n",
        "    [\n",
        "        m['Rainfall (mm)'].between(0, 50, inclusive=True),\n",
        "        m['Rainfall (mm)'].between(50.000001, 100, inclusive=True),\n",
        "    ],\n",
        "    [\n",
        "        'Low',\n",
        "        'Medium'\n",
        "\n",
        "    ],\n",
        "    default='High'\n",
        ")\n",
        "\n",
        "m['Evaporation (mm)'] = np.select(\n",
        "    [\n",
        "        m['Evaporation (mm)'].between(0, 3, inclusive=True),\n",
        "        m['Evaporation (mm)'].between(3.000001, 6, inclusive=True),\n",
        "    ],\n",
        "    [\n",
        "        'Low',\n",
        "        'Medium'\n",
        "\n",
        "    ],\n",
        "    default='High'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmA6Da8Mn8Rc",
        "outputId": "1bce801f-352f-4127-817f-7404c0207bf9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-16640b64ddf9>:3: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated in favour of `both` or `neither`.\n",
            "  m['Humidity'].between(0, 30.000, inclusive=True),\n",
            "<ipython-input-29-16640b64ddf9>:4: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated in favour of `both` or `neither`.\n",
            "  m['Humidity'].between(30.001, 70.000, inclusive=True)\n",
            "<ipython-input-29-16640b64ddf9>:15: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated in favour of `both` or `neither`.\n",
            "  m['Sunshine (hours)'].between(0, 2.999999, inclusive=True),\n",
            "<ipython-input-29-16640b64ddf9>:16: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated in favour of `both` or `neither`.\n",
            "  m['Sunshine (hours)'].between(3, 6, inclusive=True)\n",
            "<ipython-input-29-16640b64ddf9>:27: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated in favour of `both` or `neither`.\n",
            "  m['WindSpeed'].between(0, 3.999999, inclusive=True),\n",
            "<ipython-input-29-16640b64ddf9>:28: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated in favour of `both` or `neither`.\n",
            "  m['WindSpeed'].between(4, 5.999999, inclusive=True),\n",
            "<ipython-input-29-16640b64ddf9>:29: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated in favour of `both` or `neither`.\n",
            "  m['WindSpeed'].between(6, 8.999999, inclusive=True),\n",
            "<ipython-input-29-16640b64ddf9>:42: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated in favour of `both` or `neither`.\n",
            "  m['Rainfall (mm)'].between(0, 50, inclusive=True),\n",
            "<ipython-input-29-16640b64ddf9>:43: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated in favour of `both` or `neither`.\n",
            "  m['Rainfall (mm)'].between(50.000001, 100, inclusive=True),\n",
            "<ipython-input-29-16640b64ddf9>:55: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated in favour of `both` or `neither`.\n",
            "  m['Evaporation (mm)'].between(0, 3, inclusive=True),\n",
            "<ipython-input-29-16640b64ddf9>:56: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated in favour of `both` or `neither`.\n",
            "  m['Evaporation (mm)'].between(3.000001, 6, inclusive=True),\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m['EvaporationCategory'] = np.where(m['Evaporation (mm)'] == 'High', 2,\n",
        "                   np.where(m['Evaporation (mm)'] == 'Medium', 1,\n",
        "                            np.where(m['Evaporation (mm)'] == 'Low', 0, 0)))\n",
        "\n",
        "m['RainfallCategory'] = np.where(m['Rainfall (mm)'] == 'High', 2,\n",
        "                   np.where(m['Rainfall (mm)'] == 'Medium', 1,\n",
        "                            np.where(m['Rainfall (mm)'] == 'Low', 0, 0)))\n",
        "\n",
        "m['HumidityCategory'] = np.where(m['HumidityCategory'] == 'High', 2,\n",
        "                   np.where(m['HumidityCategory'] == 'Medium', 1,\n",
        "                            np.where(m['HumidityCategory'] == 'Low', 0, 0)))\n",
        "\n",
        "m['SunshineCategory'] = np.where(m['SunshineCategory'] == 'High', 2,\n",
        "                   np.where(m['SunshineCategory'] == 'Medium', 1,\n",
        "                            np.where(m['SunshineCategory'] == 'Low', 0, 0)))\n",
        "\n",
        "m['WindSpeedCategory'] = np.where(m['WindSpeedCategory'] == 'Strong', 2,\n",
        "                   np.where(m['WindSpeedCategory'] == 'Medium', 1,\n",
        "                            np.where(m['WindSpeedCategory'] == 'Low', 0, 0)))\n",
        "\n",
        "\n",
        "m.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "G4qUWIO4n99V",
        "outputId": "5fc96077-fc1e-4acb-9418-48da4cb97ac4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Minimum temperature (°C)  Maximum temperature (°C)  Sunshine (hours)  \\\n",
              "0                  8.554278                 26.363726          3.204186   \n",
              "1                  8.554278                 26.363726          3.204186   \n",
              "2                  8.554278                 26.363726          3.204186   \n",
              "3                  8.554278                 26.363726          3.204186   \n",
              "4                  8.554278                 26.363726          3.204186   \n",
              "\n",
              "  Rainfall (mm) Evaporation (mm)   Humidity  WindSpeed  key  \\\n",
              "0           Low           Medium  64.848198  10.826262    0   \n",
              "1           Low           Medium  64.848198  10.826262    0   \n",
              "2           Low           Medium  64.848198  10.826262    0   \n",
              "3           Low           Medium  64.848198  10.826262    0   \n",
              "4           Low           Medium  64.848198  10.826262    0   \n",
              "\n",
              "   FertilityRequirement  NurseryStockProduct  ...  DroughtTolerance  \\\n",
              "0                   0.5                    0  ...                 1   \n",
              "1                   0.5                    0  ...                 1   \n",
              "2                   1.0                    0  ...                 0   \n",
              "3                   0.5                    1  ...                 0   \n",
              "4                   0.5                    1  ...                 1   \n",
              "\n",
              "   ShadeTolerance TemperatureMinimum ChristmasTreeProduct  ProteinPotential  \\\n",
              "0               0                0.0                    0                 0   \n",
              "1               0                0.0                    0                 0   \n",
              "2               2                7.0                    0                 0   \n",
              "3               2              -43.0                    1                 0   \n",
              "4               2              -38.0                    1                 0   \n",
              "\n",
              "   HumidityCategory  SunshineCategory  WindSpeedCategory  EvaporationCategory  \\\n",
              "0                 1                 1                  0                    1   \n",
              "1                 1                 1                  0                    1   \n",
              "2                 1                 1                  0                    1   \n",
              "3                 1                 1                  0                    1   \n",
              "4                 1                 1                  0                    1   \n",
              "\n",
              "   RainfallCategory  \n",
              "0                 0  \n",
              "1                 0  \n",
              "2                 0  \n",
              "3                 0  \n",
              "4                 0  \n",
              "\n",
              "[5 rows x 45 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0601a310-b345-43fb-876c-6da2ed88afe5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Minimum temperature (°C)</th>\n",
              "      <th>Maximum temperature (°C)</th>\n",
              "      <th>Sunshine (hours)</th>\n",
              "      <th>Rainfall (mm)</th>\n",
              "      <th>Evaporation (mm)</th>\n",
              "      <th>Humidity</th>\n",
              "      <th>WindSpeed</th>\n",
              "      <th>key</th>\n",
              "      <th>FertilityRequirement</th>\n",
              "      <th>NurseryStockProduct</th>\n",
              "      <th>...</th>\n",
              "      <th>DroughtTolerance</th>\n",
              "      <th>ShadeTolerance</th>\n",
              "      <th>TemperatureMinimum</th>\n",
              "      <th>ChristmasTreeProduct</th>\n",
              "      <th>ProteinPotential</th>\n",
              "      <th>HumidityCategory</th>\n",
              "      <th>SunshineCategory</th>\n",
              "      <th>WindSpeedCategory</th>\n",
              "      <th>EvaporationCategory</th>\n",
              "      <th>RainfallCategory</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.554278</td>\n",
              "      <td>26.363726</td>\n",
              "      <td>3.204186</td>\n",
              "      <td>Low</td>\n",
              "      <td>Medium</td>\n",
              "      <td>64.848198</td>\n",
              "      <td>10.826262</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.554278</td>\n",
              "      <td>26.363726</td>\n",
              "      <td>3.204186</td>\n",
              "      <td>Low</td>\n",
              "      <td>Medium</td>\n",
              "      <td>64.848198</td>\n",
              "      <td>10.826262</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.554278</td>\n",
              "      <td>26.363726</td>\n",
              "      <td>3.204186</td>\n",
              "      <td>Low</td>\n",
              "      <td>Medium</td>\n",
              "      <td>64.848198</td>\n",
              "      <td>10.826262</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.554278</td>\n",
              "      <td>26.363726</td>\n",
              "      <td>3.204186</td>\n",
              "      <td>Low</td>\n",
              "      <td>Medium</td>\n",
              "      <td>64.848198</td>\n",
              "      <td>10.826262</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>-43.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8.554278</td>\n",
              "      <td>26.363726</td>\n",
              "      <td>3.204186</td>\n",
              "      <td>Low</td>\n",
              "      <td>Medium</td>\n",
              "      <td>64.848198</td>\n",
              "      <td>10.826262</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 45 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0601a310-b345-43fb-876c-6da2ed88afe5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0601a310-b345-43fb-876c-6da2ed88afe5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0601a310-b345-43fb-876c-6da2ed88afe5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m['DroughtFactor'] = m['HumidityCategory'] + m['RainfallCategory'] + m['EvaporationCategory']\n",
        "m['Bonus'] = m.apply(lambda row: 1 if row['WindSpeedCategory'] >= 1 and row['Propogated_by_Seed'] > 0 else 0, axis=1)\n",
        "m.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "l1sb7WM4oCRj",
        "outputId": "f87caa56-eab1-40fc-dd7e-ee47b629e11c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Minimum temperature (°C)  Maximum temperature (°C)  Sunshine (hours)  \\\n",
              "0                  8.554278                 26.363726          3.204186   \n",
              "1                  8.554278                 26.363726          3.204186   \n",
              "2                  8.554278                 26.363726          3.204186   \n",
              "3                  8.554278                 26.363726          3.204186   \n",
              "4                  8.554278                 26.363726          3.204186   \n",
              "\n",
              "  Rainfall (mm) Evaporation (mm)   Humidity  WindSpeed  key  \\\n",
              "0           Low           Medium  64.848198  10.826262    0   \n",
              "1           Low           Medium  64.848198  10.826262    0   \n",
              "2           Low           Medium  64.848198  10.826262    0   \n",
              "3           Low           Medium  64.848198  10.826262    0   \n",
              "4           Low           Medium  64.848198  10.826262    0   \n",
              "\n",
              "   FertilityRequirement  NurseryStockProduct  ...  TemperatureMinimum  \\\n",
              "0                   0.5                    0  ...                 0.0   \n",
              "1                   0.5                    0  ...                 0.0   \n",
              "2                   1.0                    0  ...                 7.0   \n",
              "3                   0.5                    1  ...               -43.0   \n",
              "4                   0.5                    1  ...               -38.0   \n",
              "\n",
              "   ChristmasTreeProduct ProteinPotential HumidityCategory  SunshineCategory  \\\n",
              "0                     0                0                1                 1   \n",
              "1                     0                0                1                 1   \n",
              "2                     0                0                1                 1   \n",
              "3                     1                0                1                 1   \n",
              "4                     1                0                1                 1   \n",
              "\n",
              "   WindSpeedCategory  EvaporationCategory  RainfallCategory  DroughtFactor  \\\n",
              "0                  0                    1                 0              2   \n",
              "1                  0                    1                 0              2   \n",
              "2                  0                    1                 0              2   \n",
              "3                  0                    1                 0              2   \n",
              "4                  0                    1                 0              2   \n",
              "\n",
              "   Bonus  \n",
              "0      0  \n",
              "1      0  \n",
              "2      0  \n",
              "3      0  \n",
              "4      0  \n",
              "\n",
              "[5 rows x 47 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c2608e8b-1c25-4b4f-8cd5-d3026284d2c2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Minimum temperature (°C)</th>\n",
              "      <th>Maximum temperature (°C)</th>\n",
              "      <th>Sunshine (hours)</th>\n",
              "      <th>Rainfall (mm)</th>\n",
              "      <th>Evaporation (mm)</th>\n",
              "      <th>Humidity</th>\n",
              "      <th>WindSpeed</th>\n",
              "      <th>key</th>\n",
              "      <th>FertilityRequirement</th>\n",
              "      <th>NurseryStockProduct</th>\n",
              "      <th>...</th>\n",
              "      <th>TemperatureMinimum</th>\n",
              "      <th>ChristmasTreeProduct</th>\n",
              "      <th>ProteinPotential</th>\n",
              "      <th>HumidityCategory</th>\n",
              "      <th>SunshineCategory</th>\n",
              "      <th>WindSpeedCategory</th>\n",
              "      <th>EvaporationCategory</th>\n",
              "      <th>RainfallCategory</th>\n",
              "      <th>DroughtFactor</th>\n",
              "      <th>Bonus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.554278</td>\n",
              "      <td>26.363726</td>\n",
              "      <td>3.204186</td>\n",
              "      <td>Low</td>\n",
              "      <td>Medium</td>\n",
              "      <td>64.848198</td>\n",
              "      <td>10.826262</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.554278</td>\n",
              "      <td>26.363726</td>\n",
              "      <td>3.204186</td>\n",
              "      <td>Low</td>\n",
              "      <td>Medium</td>\n",
              "      <td>64.848198</td>\n",
              "      <td>10.826262</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.554278</td>\n",
              "      <td>26.363726</td>\n",
              "      <td>3.204186</td>\n",
              "      <td>Low</td>\n",
              "      <td>Medium</td>\n",
              "      <td>64.848198</td>\n",
              "      <td>10.826262</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.554278</td>\n",
              "      <td>26.363726</td>\n",
              "      <td>3.204186</td>\n",
              "      <td>Low</td>\n",
              "      <td>Medium</td>\n",
              "      <td>64.848198</td>\n",
              "      <td>10.826262</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>-43.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8.554278</td>\n",
              "      <td>26.363726</td>\n",
              "      <td>3.204186</td>\n",
              "      <td>Low</td>\n",
              "      <td>Medium</td>\n",
              "      <td>64.848198</td>\n",
              "      <td>10.826262</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>-38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 47 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2608e8b-1c25-4b4f-8cd5-d3026284d2c2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c2608e8b-1c25-4b4f-8cd5-d3026284d2c2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c2608e8b-1c25-4b4f-8cd5-d3026284d2c2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m_df = m[m['Minimum temperature (°C)'] > m['TemperatureMinimum']]\n",
        "m_df = m_df[(m_df['ShadeTolerance'] + m_df['SunshineCategory']) > 0]\n",
        "m_df = m_df[(m_df['DroughtTolerance'] + m_df['DroughtFactor']) > 2]"
      ],
      "metadata": {
        "id": "v8mH_al_oEG_"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#OVERALL SCORING\n",
        "m_df['Score'] = m_df['FertilityRequirement'] + m_df['NurseryStockProduct'] + m_df['LowGrowingGrass'] + m_df['PalatableHuman'] + m_df['Toxicity'] + m_df['FruitSeedAbundance'] + m_df['FruitSeedPersistence'] + m_df['SeedlingVigor']+ m_df['VegetativeSpreadRate'] + m_df['KnownAllelopath']+ m_df['GrowthRate'] + m_df['CoppicePotential']+ m_df['PostProduct'] + m_df['AdaptedCoarseSoils']+ m_df['AdaptedMediumSoils'] + m_df['AdaptedFineSoils']+ m_df['Propogated_by_BareRoot'] + m_df['Propogated_by_Bulbs']+ m_df['Propogated_by_Container'] + m_df['Propogated_by_Corms']+ m_df['Propogated_by_Cuttings'] + m_df['Propogated_by_Seed']+ m_df['Propogated_by_Sod'] + m_df['Propogated_by_Sprigs']+ m_df['Propogated_by_Cuttings'] + m_df['Propogated_by_Seed']+ m_df['Propogated_by_Tubers'] + m_df['ChristmasTreeProduct']+ m_df['ProteinPotential'] + m_df['Bonus']"
      ],
      "metadata": {
        "id": "qZBZeaKjoGcY"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final = m_df[['CommonName','ScientificName','Score','FertilityRequirement','NurseryStockProduct',\n",
        "             'PalatableHuman', 'AdaptedCoarseSoils', 'AdaptedMediumSoils', 'AdaptedFineSoils',\n",
        "             'Toxicity', 'FruitSeedAbundance', 'FruitSeedPersistence'\n",
        "            , 'SeedlingVigor', 'VegetativeSpreadRate', 'KnownAllelopath'\n",
        "            , 'GrowthRate', 'PostProduct'\n",
        "            ,'ProteinPotential']]"
      ],
      "metadata": {
        "id": "zKWP897WoJIK"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final = final.sort_values(by='Score', ascending=False)\n",
        "final = final[final['Score'] > 0]\n",
        "# Take the top 100 rows\n",
        "top_100 = final.head(100)\n",
        "top_100"
      ],
      "metadata": {
        "id": "3zHW0_UVoK-8",
        "outputId": "927195bd-6495-4336-83ed-2f18b2e7314f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                CommonName                       ScientificName  Score  \\\n",
              "721     screwbean mesquite                   Prosopis pubescens   18.7   \n",
              "24390  California wildrose                     Rosa californica   18.7   \n",
              "720         honey mesquite  Prosopis glandulosa var. glandulosa   17.7   \n",
              "805          black locust                  Robinia pseudoacacia   17.7   \n",
              "227      netleaf hackberry                              Celtis    16.7   \n",
              "...                    ...                                  ...    ...   \n",
              "9183        Missouri gourd               Cucurbita foetidissima   13.1   \n",
              "24594      sweetbriar rose                      Rosa eglanteria   13.1   \n",
              "42832      goldenrain tree              Koelreuteria paniculata   13.1   \n",
              "44600       Nanking cherry                     Prunus tomentosa   13.1   \n",
              "40844         Utah juniper                Juniperus osteosperma   13.1   \n",
              "\n",
              "       FertilityRequirement  NurseryStockProduct  PalatableHuman  \\\n",
              "721                     1.0                    1               1   \n",
              "24390                   1.0                    1               1   \n",
              "720                     1.0                    1               1   \n",
              "805                     1.0                    1               0   \n",
              "227                     1.0                    1               1   \n",
              "...                     ...                  ...             ...   \n",
              "9183                    1.0                    0               1   \n",
              "24594                   0.5                    1               0   \n",
              "42832                   1.0                    1               0   \n",
              "44600                   0.5                    1               1   \n",
              "40844                   1.0                    1               0   \n",
              "\n",
              "       AdaptedCoarseSoils  AdaptedMediumSoils  AdaptedFineSoils  Toxicity  \\\n",
              "721                     1                   1                 1         1   \n",
              "24390                   1                   1                 1         1   \n",
              "720                     1                   1                 1         1   \n",
              "805                     1                   1                 1         1   \n",
              "227                     1                   1                 0         1   \n",
              "...                   ...                 ...               ...       ...   \n",
              "9183                    1                   1                 1         1   \n",
              "24594                   1                   1                 1         1   \n",
              "42832                   1                   1                 1         1   \n",
              "44600                   1                   1                 0         1   \n",
              "40844                   1                   1                 0         1   \n",
              "\n",
              "       FruitSeedAbundance  FruitSeedPersistence  SeedlingVigor  \\\n",
              "721                   1.0                     1            1.0   \n",
              "24390                 1.0                     1            1.0   \n",
              "720                   1.0                     0            1.0   \n",
              "805                   0.5                     1            1.0   \n",
              "227                   1.0                     1            1.0   \n",
              "...                   ...                   ...            ...   \n",
              "9183                  1.0                     0            1.0   \n",
              "24594                 1.0                     1            0.5   \n",
              "42832                 1.0                     1            1.0   \n",
              "44600                 0.5                     1            0.5   \n",
              "40844                 1.0                     1            0.0   \n",
              "\n",
              "       VegetativeSpreadRate  KnownAllelopath  GrowthRate  PostProduct  \\\n",
              "721                     0.0                0         1.0            1   \n",
              "24390                   1.0                0         1.0            0   \n",
              "720                     0.0                0         1.0            1   \n",
              "805                     0.5                0         1.0            1   \n",
              "227                     0.0                0         1.0            0   \n",
              "...                     ...              ...         ...          ...   \n",
              "9183                    0.0                0         1.0            0   \n",
              "24594                   0.5                0         0.5            0   \n",
              "42832                   0.0                0         0.0            0   \n",
              "44600                   0.0                0         0.5            0   \n",
              "40844                   0.0                1         0.0            1   \n",
              "\n",
              "       ProteinPotential  \n",
              "721                   0  \n",
              "24390                 0  \n",
              "720                   0  \n",
              "805                   0  \n",
              "227                   0  \n",
              "...                 ...  \n",
              "9183                  0  \n",
              "24594                 0  \n",
              "42832                 0  \n",
              "44600                 0  \n",
              "40844                 0  \n",
              "\n",
              "[100 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-efc05250-0576-4e73-9ae4-3fe46d58da29\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CommonName</th>\n",
              "      <th>ScientificName</th>\n",
              "      <th>Score</th>\n",
              "      <th>FertilityRequirement</th>\n",
              "      <th>NurseryStockProduct</th>\n",
              "      <th>PalatableHuman</th>\n",
              "      <th>AdaptedCoarseSoils</th>\n",
              "      <th>AdaptedMediumSoils</th>\n",
              "      <th>AdaptedFineSoils</th>\n",
              "      <th>Toxicity</th>\n",
              "      <th>FruitSeedAbundance</th>\n",
              "      <th>FruitSeedPersistence</th>\n",
              "      <th>SeedlingVigor</th>\n",
              "      <th>VegetativeSpreadRate</th>\n",
              "      <th>KnownAllelopath</th>\n",
              "      <th>GrowthRate</th>\n",
              "      <th>PostProduct</th>\n",
              "      <th>ProteinPotential</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>721</th>\n",
              "      <td>screwbean mesquite</td>\n",
              "      <td>Prosopis pubescens</td>\n",
              "      <td>18.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24390</th>\n",
              "      <td>California wildrose</td>\n",
              "      <td>Rosa californica</td>\n",
              "      <td>18.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>720</th>\n",
              "      <td>honey mesquite</td>\n",
              "      <td>Prosopis glandulosa var. glandulosa</td>\n",
              "      <td>17.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>805</th>\n",
              "      <td>black locust</td>\n",
              "      <td>Robinia pseudoacacia</td>\n",
              "      <td>17.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>netleaf hackberry</td>\n",
              "      <td>Celtis</td>\n",
              "      <td>16.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9183</th>\n",
              "      <td>Missouri gourd</td>\n",
              "      <td>Cucurbita foetidissima</td>\n",
              "      <td>13.1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24594</th>\n",
              "      <td>sweetbriar rose</td>\n",
              "      <td>Rosa eglanteria</td>\n",
              "      <td>13.1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42832</th>\n",
              "      <td>goldenrain tree</td>\n",
              "      <td>Koelreuteria paniculata</td>\n",
              "      <td>13.1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44600</th>\n",
              "      <td>Nanking cherry</td>\n",
              "      <td>Prunus tomentosa</td>\n",
              "      <td>13.1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40844</th>\n",
              "      <td>Utah juniper</td>\n",
              "      <td>Juniperus osteosperma</td>\n",
              "      <td>13.1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-efc05250-0576-4e73-9ae4-3fe46d58da29')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-efc05250-0576-4e73-9ae4-3fe46d58da29 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-efc05250-0576-4e73-9ae4-3fe46d58da29');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ]
}